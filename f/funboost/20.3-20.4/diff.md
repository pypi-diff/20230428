# Comparing `tmp/funboost-20.3-py3-none-any.whl.zip` & `tmp/funboost-20.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,14 +1,14 @@
-Zip file size: 1870122 bytes, number of entries: 212
--rw-rw-rw-  2.0 fat    20766 b- defN 23-Apr-04 03:51 funboost/__init__.py
--rw-rw-rw-  2.0 fat     5627 b- defN 22-Oct-29 03:02 funboost/constant.py
--rw-rw-rw-  2.0 fat     6660 b- defN 23-Mar-28 07:01 funboost/funboost_config_deafult.py
--rw-rw-rw-  2.0 fat    14104 b- defN 23-Mar-31 02:55 funboost/helpers.py
--rw-rw-rw-  2.0 fat     9134 b- defN 22-Sep-17 06:13 funboost/set_frame_config.py
--rw-rw-rw-  2.0 fat     2858 b- defN 22-Nov-29 09:00 funboost/assist/user_custom_broker_register.py
+Zip file size: 1878653 bytes, number of entries: 216
+-rw-rw-rw-  2.0 fat    21053 b- defN 23-Apr-26 11:46 funboost/__init__.py
+-rw-rw-rw-  2.0 fat     5910 b- defN 23-Apr-28 02:46 funboost/constant.py
+-rw-rw-rw-  2.0 fat     7100 b- defN 23-Apr-27 08:42 funboost/funboost_config_deafult.py
+-rw-rw-rw-  2.0 fat    14104 b- defN 23-Apr-14 00:56 funboost/helpers.py
+-rw-rw-rw-  2.0 fat     9149 b- defN 23-Apr-13 09:47 funboost/set_frame_config.py
+-rw-rw-rw-  2.0 fat     4734 b- defN 23-Apr-28 02:48 funboost/assist/user_custom_broker_register.py
 -rw-rw-rw-  2.0 fat     3930 b- defN 22-Sep-17 06:12 funboost/beggar_version_implementation/beggar_redis_consumer.py
 -rw-rw-rw-  2.0 fat      759 b- defN 22-Dec-19 11:45 funboost/concurrent_pool/__init__.py
 -rw-rw-rw-  2.0 fat     3256 b- defN 21-Dec-27 01:40 funboost/concurrent_pool/async_helper.py
 -rw-rw-rw-  2.0 fat     7227 b- defN 23-Mar-23 05:32 funboost/concurrent_pool/async_pool_executor.py
 -rw-rw-rw-  2.0 fat     4723 b- defN 23-Mar-23 05:32 funboost/concurrent_pool/bounded_processpoolexcutor_gt_py37.py
 -rw-rw-rw-  2.0 fat     3011 b- defN 23-Mar-23 05:32 funboost/concurrent_pool/bounded_processpoolexcutor_py36.py
 -rw-rw-rw-  2.0 fat     1571 b- defN 23-Mar-23 05:32 funboost/concurrent_pool/bounded_threadpoolexcutor.py
@@ -19,53 +19,55 @@
 -rw-rw-rw-  2.0 fat     9317 b- defN 21-Dec-27 01:40 funboost/concurrent_pool/custom_threadpool_executor000.py
 -rw-rw-rw-  2.0 fat      373 b- defN 21-Dec-27 01:40 funboost/concurrent_pool/single_thread_executor.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Feb-24 11:39 funboost/concurrent_pool/backup/__init__.py
 -rw-rw-rw-  2.0 fat     9548 b- defN 23-Mar-23 05:32 funboost/concurrent_pool/backup/async_pool_executor0223.py
 -rw-rw-rw-  2.0 fat     9568 b- defN 23-Mar-23 05:32 funboost/concurrent_pool/backup/async_pool_executor_back.py
 -rw-rw-rw-  2.0 fat     5728 b- defN 23-Mar-23 05:32 funboost/concurrent_pool/backup/async_pool_executor_janus.py
 -rw-rw-rw-  2.0 fat      126 b- defN 22-Sep-17 06:12 funboost/consumers/__init__.py
--rw-rw-rw-  2.0 fat    93969 b- defN 23-Apr-10 06:05 funboost/consumers/base_consumer.py
+-rw-rw-rw-  2.0 fat    94018 b- defN 23-Apr-26 10:59 funboost/consumers/base_consumer.py
+-rw-rw-rw-  2.0 fat     4574 b- defN 23-Apr-27 08:51 funboost/consumers/celery_consumer.py
 -rw-rw-rw-  2.0 fat     5877 b- defN 23-Mar-29 02:19 funboost/consumers/confirm_mixin.py
 -rw-rw-rw-  2.0 fat     2045 b- defN 23-Mar-23 05:32 funboost/consumers/http_consumer.py
 -rw-rw-rw-  2.0 fat     4463 b- defN 22-Sep-17 06:12 funboost/consumers/http_consumer000.py
 -rw-rw-rw-  2.0 fat     1058 b- defN 22-Sep-17 06:12 funboost/consumers/httpsqs_consumer.py
--rw-rw-rw-  2.0 fat     4295 b- defN 23-Mar-31 08:57 funboost/consumers/kafka_consumer.py
--rw-rw-rw-  2.0 fat     6586 b- defN 22-May-26 12:02 funboost/consumers/kafka_consumer_manually_commit.py
--rw-rw-rw-  2.0 fat     5082 b- defN 23-Mar-23 05:32 funboost/consumers/kombu_consumer.py
+-rw-rw-rw-  2.0 fat     4196 b- defN 23-Apr-21 02:38 funboost/consumers/kafka_consumer.py
+-rw-rw-rw-  2.0 fat     6536 b- defN 23-Apr-21 02:47 funboost/consumers/kafka_consumer_manually_commit.py
+-rw-rw-rw-  2.0 fat    10168 b- defN 23-Apr-26 05:47 funboost/consumers/kombu_consumer.py
 -rw-rw-rw-  2.0 fat     1272 b- defN 22-Sep-17 06:12 funboost/consumers/local_python_queue_consumer.py
 -rw-rw-rw-  2.0 fat     1069 b- defN 22-Sep-17 06:12 funboost/consumers/mongomq_consumer.py
 -rw-rw-rw-  2.0 fat     2208 b- defN 22-Sep-17 06:12 funboost/consumers/mqtt_consumer.py
+-rw-rw-rw-  2.0 fat     2154 b- defN 23-Apr-28 09:20 funboost/consumers/nameko_consumer.py
 -rw-rw-rw-  2.0 fat     1054 b- defN 21-Dec-27 01:40 funboost/consumers/nats_consumer.py
 -rw-rw-rw-  2.0 fat     1440 b- defN 22-Sep-17 06:12 funboost/consumers/nsq_consumer.py
 -rw-rw-rw-  2.0 fat     1218 b- defN 23-Mar-29 02:34 funboost/consumers/peewee_conusmer.py
 -rw-rw-rw-  2.0 fat      982 b- defN 22-Sep-17 06:12 funboost/consumers/persist_queue_consumer.py
--rw-rw-rw-  2.0 fat     1791 b- defN 23-Apr-10 07:14 funboost/consumers/pulsar_consumer.py
--rw-rw-rw-  2.0 fat     1698 b- defN 23-Mar-23 05:32 funboost/consumers/rabbitmq_amqpstorm_consumer.py
+-rw-rw-rw-  2.0 fat     2394 b- defN 23-Apr-21 02:47 funboost/consumers/pulsar_consumer.py
+-rw-rw-rw-  2.0 fat     1700 b- defN 23-Apr-14 09:24 funboost/consumers/rabbitmq_amqpstorm_consumer.py
 -rw-rw-rw-  2.0 fat     5412 b- defN 22-Sep-17 06:12 funboost/consumers/rabbitmq_pika_consumer.py
 -rw-rw-rw-  2.0 fat     4653 b- defN 22-Sep-17 06:12 funboost/consumers/rabbitmq_pika_consumerv0.py
 -rw-rw-rw-  2.0 fat     1239 b- defN 22-Sep-17 06:12 funboost/consumers/rabbitmq_rabbitpy_consumer.py
 -rw-rw-rw-  2.0 fat     3011 b- defN 22-Sep-17 06:12 funboost/consumers/redis_brpoplpush_consumer.py
--rw-rw-rw-  2.0 fat     2762 b- defN 22-Sep-17 06:12 funboost/consumers/redis_consumer.py
+-rw-rw-rw-  2.0 fat     2808 b- defN 23-Apr-21 02:57 funboost/consumers/redis_consumer.py
 -rw-rw-rw-  2.0 fat     7560 b- defN 22-Sep-17 06:12 funboost/consumers/redis_consumer_ack_able.py
--rw-rw-rw-  2.0 fat      899 b- defN 22-Dec-22 06:21 funboost/consumers/redis_consumer_simple.py
+-rw-rw-rw-  2.0 fat      899 b- defN 23-Apr-28 03:12 funboost/consumers/redis_consumer_simple.py
 -rw-rw-rw-  2.0 fat     7135 b- defN 22-Sep-17 06:12 funboost/consumers/redis_filter.py
 -rw-rw-rw-  2.0 fat     1184 b- defN 22-Sep-17 06:12 funboost/consumers/redis_pubsub_consumer.py
 -rw-rw-rw-  2.0 fat     6304 b- defN 21-Dec-27 03:47 funboost/consumers/redis_stream_consumer.py
 -rw-rw-rw-  2.0 fat     1633 b- defN 23-Mar-23 05:32 funboost/consumers/rocketmq_consumer.py
 -rw-rw-rw-  2.0 fat     1289 b- defN 22-Sep-17 06:12 funboost/consumers/sqlachemy_consumer.py
 -rw-rw-rw-  2.0 fat     2025 b- defN 22-Sep-17 06:12 funboost/consumers/tcp_consumer.py
 -rw-rw-rw-  2.0 fat     1322 b- defN 22-Sep-17 08:52 funboost/consumers/txt_file_consumer.py
 -rw-rw-rw-  2.0 fat     1625 b- defN 22-Sep-17 06:12 funboost/consumers/udp_consumer.py
 -rw-rw-rw-  2.0 fat     4137 b- defN 23-Mar-23 05:34 funboost/consumers/zeromq_consumer.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Dec-05 10:31 funboost/contrib/__init__.py
 -rw-rw-rw-  2.0 fat     4703 b- defN 23-Mar-29 03:02 funboost/contrib/queue2queue.py
 -rw-rw-rw-  2.0 fat     1817 b- defN 23-Mar-22 02:09 funboost/contrib/redis_consume_latest_msg_broker.py
 -rw-rw-rw-  2.0 fat      178 b- defN 22-Sep-17 06:12 funboost/factories/__init__.py
--rw-rw-rw-  2.0 fat     3218 b- defN 22-Dec-05 11:50 funboost/factories/consumer_factory.py
--rw-rw-rw-  2.0 fat     4589 b- defN 23-Mar-17 04:18 funboost/factories/publisher_factotry.py
+-rw-rw-rw-  2.0 fat     3357 b- defN 23-Apr-28 02:46 funboost/factories/consumer_factory.py
+-rw-rw-rw-  2.0 fat     4587 b- defN 23-Apr-28 01:33 funboost/factories/publisher_factotry.py
 -rw-rw-rw-  2.0 fat     4841 b- defN 22-Sep-17 06:12 funboost/function_result_web/app.py
 -rw-rw-rw-  2.0 fat     7345 b- defN 23-Mar-08 10:19 funboost/function_result_web/functions.py
 -rw-rw-rw-  2.0 fat     4045 b- defN 22-Feb-21 07:34 funboost/function_result_web/__pycache__/app.cpython-37.pyc
 -rw-rw-rw-  2.0 fat     3921 b- defN 22-Mar-30 13:56 funboost/function_result_web/__pycache__/functions.cpython-37.pyc
 -rw-rw-rw-  2.0 fat     7674 b- defN 21-Dec-27 01:40 funboost/function_result_web/static/assets/css/custom.css
 -rw-rw-rw-  2.0 fat    42839 b- defN 21-Dec-27 01:40 funboost/function_result_web/static/assets/css/jquery.mCustomScrollbar.min.css
 -rw-rw-rw-  2.0 fat    23610 b- defN 21-Dec-27 01:40 funboost/function_result_web/static/assets/img/user.jpg
@@ -76,35 +78,37 @@
 -rw-rw-rw-  2.0 fat      546 b- defN 21-Dec-27 01:40 funboost/function_result_web/static/images/password.png
 -rw-rw-rw-  2.0 fat     2912 b- defN 21-Dec-27 01:40 funboost/function_result_web/static/images/tick.png
 -rw-rw-rw-  2.0 fat      622 b- defN 21-Dec-27 01:40 funboost/function_result_web/static/images/user.png
 -rw-rw-rw-  2.0 fat    96383 b- defN 21-Dec-27 01:40 funboost/function_result_web/static/js/jquery-1.11.0.min.js
 -rw-rw-rw-  2.0 fat    19501 b- defN 22-Feb-21 12:32 funboost/function_result_web/templates/index.html
 -rw-rw-rw-  2.0 fat     2007 b- defN 21-Dec-27 01:40 funboost/function_result_web/templates/login.html
 -rw-rw-rw-  2.0 fat      131 b- defN 22-Sep-17 06:12 funboost/publishers/__init__.py
--rw-rw-rw-  2.0 fat    15024 b- defN 23-Mar-31 02:58 funboost/publishers/base_publisher.py
+-rw-rw-rw-  2.0 fat    14894 b- defN 23-Apr-21 09:06 funboost/publishers/base_publisher.py
+-rw-rw-rw-  2.0 fat     3897 b- defN 23-Apr-28 09:23 funboost/publishers/celery_publisher.py
 -rw-rw-rw-  2.0 fat     3541 b- defN 23-Mar-23 05:32 funboost/publishers/confluent_kafka_publisher.py
 -rw-rw-rw-  2.0 fat      777 b- defN 22-Sep-17 06:12 funboost/publishers/http_publisher.py
 -rw-rw-rw-  2.0 fat     2783 b- defN 22-Sep-17 06:12 funboost/publishers/httpsqs_publisher.py
 -rw-rw-rw-  2.0 fat     2160 b- defN 23-Apr-03 10:55 funboost/publishers/kafka_publisher.py
--rw-rw-rw-  2.0 fat     4567 b- defN 22-Nov-04 01:42 funboost/publishers/kombu_publisher.py
+-rw-rw-rw-  2.0 fat     5246 b- defN 23-Apr-21 09:40 funboost/publishers/kombu_publisher.py
 -rw-rw-rw-  2.0 fat     1365 b- defN 22-Sep-17 06:12 funboost/publishers/local_python_queue_publisher.py
 -rw-rw-rw-  2.0 fat     1874 b- defN 23-Mar-14 02:56 funboost/publishers/mongomq_publisher.py
 -rw-rw-rw-  2.0 fat     3050 b- defN 22-Sep-17 06:12 funboost/publishers/mqtt_publisher.py
 -rw-rw-rw-  2.0 fat     7782 b- defN 23-Mar-31 03:13 funboost/publishers/msg_result_getter.py
+-rw-rw-rw-  2.0 fat     2147 b- defN 23-Apr-28 06:21 funboost/publishers/nameko_publisher.py
 -rw-rw-rw-  2.0 fat      776 b- defN 21-Dec-27 01:40 funboost/publishers/nats_publisher.py
 -rw-rw-rw-  2.0 fat     1302 b- defN 22-Sep-17 06:12 funboost/publishers/nsq_publisher.py
 -rw-rw-rw-  2.0 fat     1095 b- defN 22-Sep-17 06:12 funboost/publishers/peewee_publisher.py
 -rw-rw-rw-  2.0 fat     2540 b- defN 22-Sep-17 06:12 funboost/publishers/persist_queue_publisher.py
--rw-rw-rw-  2.0 fat     1085 b- defN 22-Dec-05 11:45 funboost/publishers/pulsar_publisher.py
--rw-rw-rw-  2.0 fat     2687 b- defN 23-Apr-12 00:44 funboost/publishers/rabbitmq_amqpstorm_publisher.py
+-rw-rw-rw-  2.0 fat     1238 b- defN 23-Apr-13 03:56 funboost/publishers/pulsar_publisher.py
+-rw-rw-rw-  2.0 fat     2725 b- defN 23-Apr-17 07:35 funboost/publishers/rabbitmq_amqpstorm_publisher.py
 -rw-rw-rw-  2.0 fat     2343 b- defN 22-Sep-17 06:12 funboost/publishers/rabbitmq_pika_publisher.py
 -rw-rw-rw-  2.0 fat     1953 b- defN 22-Sep-17 06:12 funboost/publishers/rabbitmq_rabbitpy_publisher.py
--rw-rw-rw-  2.0 fat     3933 b- defN 22-Sep-17 06:12 funboost/publishers/redis_publisher.py
+-rw-rw-rw-  2.0 fat     3929 b- defN 23-Apr-21 02:47 funboost/publishers/redis_publisher.py
 -rw-rw-rw-  2.0 fat      278 b- defN 22-Sep-17 06:12 funboost/publishers/redis_publisher_lpush.py
--rw-rw-rw-  2.0 fat      872 b- defN 22-Sep-17 06:12 funboost/publishers/redis_publisher_simple.py
+-rw-rw-rw-  2.0 fat      872 b- defN 23-Apr-28 03:12 funboost/publishers/redis_publisher_simple.py
 -rw-rw-rw-  2.0 fat      721 b- defN 22-Sep-17 06:12 funboost/publishers/redis_pubsub_publisher.py
 -rw-rw-rw-  2.0 fat     2037 b- defN 21-Dec-27 01:40 funboost/publishers/redis_stream_publisher.py
 -rw-rw-rw-  2.0 fat     2343 b- defN 23-Mar-23 05:32 funboost/publishers/rocketmq_publisher.py
 -rw-rw-rw-  2.0 fat     1215 b- defN 22-Sep-17 06:12 funboost/publishers/sqla_queue_publisher.py
 -rw-rw-rw-  2.0 fat     1359 b- defN 22-Sep-17 06:12 funboost/publishers/tcp_publisher.py
 -rw-rw-rw-  2.0 fat     1380 b- defN 22-Sep-17 08:52 funboost/publishers/txt_file_publisher.py
 -rw-rw-rw-  2.0 fat     1218 b- defN 22-Sep-17 06:12 funboost/publishers/udp_publisher.py
@@ -202,13 +206,13 @@
 -rw-rw-rw-  2.0 fat      303 b- defN 23-Mar-13 01:28 funboost/utils/dependency_packages_in_pythonpath/func_timeout/__pycache__/py3_raise.cpython-37.pyc
 -rw-rw-rw-  2.0 fat      311 b- defN 23-Mar-21 10:43 funboost/utils/dependency_packages_in_pythonpath/func_timeout/__pycache__/py3_raise.cpython-39.pyc
 -rw-rw-rw-  2.0 fat      909 b- defN 21-Dec-27 01:40 funboost/utils/pysnooper_ydf/__init__.py
 -rw-rw-rw-  2.0 fat     2243 b- defN 21-Dec-27 01:40 funboost/utils/pysnooper_ydf/pycompat.py
 -rw-rw-rw-  2.0 fat    19131 b- defN 23-Mar-23 05:34 funboost/utils/pysnooper_ydf/tracer.py
 -rw-rw-rw-  2.0 fat     2753 b- defN 23-Mar-23 05:34 funboost/utils/pysnooper_ydf/utils.py
 -rw-rw-rw-  2.0 fat     3693 b- defN 23-Mar-23 05:34 funboost/utils/pysnooper_ydf/variables.py
--rw-rw-rw-  2.0 fat    11558 b- defN 23-Apr-12 09:55 funboost-20.3.dist-info/LICENSE
--rw-rw-rw-  2.0 fat    24416 b- defN 23-Apr-12 09:55 funboost-20.3.dist-info/METADATA
--rw-rw-rw-  2.0 fat       97 b- defN 23-Apr-12 09:55 funboost-20.3.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        9 b- defN 23-Apr-12 09:55 funboost-20.3.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat    23464 b- defN 23-Apr-12 09:55 funboost-20.3.dist-info/RECORD
-212 files, 3199500 bytes uncompressed, 1831066 bytes compressed:  42.8%
+-rw-rw-rw-  2.0 fat    11558 b- defN 23-Apr-28 10:43 funboost-20.4.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat    24442 b- defN 23-Apr-28 10:43 funboost-20.4.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       97 b- defN 23-Apr-28 10:43 funboost-20.4.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        9 b- defN 23-Apr-28 10:43 funboost-20.4.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat    23845 b- defN 23-Apr-28 10:43 funboost-20.4.dist-info/RECORD
+216 files, 3222090 bytes uncompressed, 1838989 bytes compressed:  42.9%
```

## zipnote {}

```diff
@@ -69,14 +69,17 @@
 
 Filename: funboost/consumers/__init__.py
 Comment: 
 
 Filename: funboost/consumers/base_consumer.py
 Comment: 
 
+Filename: funboost/consumers/celery_consumer.py
+Comment: 
+
 Filename: funboost/consumers/confirm_mixin.py
 Comment: 
 
 Filename: funboost/consumers/http_consumer.py
 Comment: 
 
 Filename: funboost/consumers/http_consumer000.py
@@ -99,14 +102,17 @@
 
 Filename: funboost/consumers/mongomq_consumer.py
 Comment: 
 
 Filename: funboost/consumers/mqtt_consumer.py
 Comment: 
 
+Filename: funboost/consumers/nameko_consumer.py
+Comment: 
+
 Filename: funboost/consumers/nats_consumer.py
 Comment: 
 
 Filename: funboost/consumers/nsq_consumer.py
 Comment: 
 
 Filename: funboost/consumers/peewee_conusmer.py
@@ -240,14 +246,17 @@
 
 Filename: funboost/publishers/__init__.py
 Comment: 
 
 Filename: funboost/publishers/base_publisher.py
 Comment: 
 
+Filename: funboost/publishers/celery_publisher.py
+Comment: 
+
 Filename: funboost/publishers/confluent_kafka_publisher.py
 Comment: 
 
 Filename: funboost/publishers/http_publisher.py
 Comment: 
 
 Filename: funboost/publishers/httpsqs_publisher.py
@@ -267,14 +276,17 @@
 
 Filename: funboost/publishers/mqtt_publisher.py
 Comment: 
 
 Filename: funboost/publishers/msg_result_getter.py
 Comment: 
 
+Filename: funboost/publishers/nameko_publisher.py
+Comment: 
+
 Filename: funboost/publishers/nats_publisher.py
 Comment: 
 
 Filename: funboost/publishers/nsq_publisher.py
 Comment: 
 
 Filename: funboost/publishers/peewee_publisher.py
@@ -615,23 +627,23 @@
 
 Filename: funboost/utils/pysnooper_ydf/utils.py
 Comment: 
 
 Filename: funboost/utils/pysnooper_ydf/variables.py
 Comment: 
 
-Filename: funboost-20.3.dist-info/LICENSE
+Filename: funboost-20.4.dist-info/LICENSE
 Comment: 
 
-Filename: funboost-20.3.dist-info/METADATA
+Filename: funboost-20.4.dist-info/METADATA
 Comment: 
 
-Filename: funboost-20.3.dist-info/WHEEL
+Filename: funboost-20.4.dist-info/WHEEL
 Comment: 
 
-Filename: funboost-20.3.dist-info/top_level.txt
+Filename: funboost-20.4.dist-info/top_level.txt
 Comment: 
 
-Filename: funboost-20.3.dist-info/RECORD
+Filename: funboost-20.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## funboost/__init__.py

```diff
@@ -18,15 +18,15 @@
 from funboost.utils.paramiko_util import ParamikoFolderUploader
 from funboost.consumers.base_consumer import (ExceptionForRequeue, ExceptionForRetry, ExceptionForPushToDlxqueue,
                                               AbstractConsumer, ConsumersManager,
                                               FunctionResultStatusPersistanceConfig,
                                               wait_for_possible_has_finish_all_tasks_by_conusmer_list,
                                               ActiveCousumerProcessInfoGetter, FunctionResultStatus)
 from funboost.publishers.base_publisher import (PriorityConsumingControlConfig,
-                                                AbstractPublisher, AsyncResult, HasNotAsyncResult, AioAsyncResult,ResultFromMongo)
+                                                AbstractPublisher, AsyncResult, HasNotAsyncResult, AioAsyncResult, ResultFromMongo)
 from funboost.factories.publisher_factotry import get_publisher
 from funboost.factories.consumer_factory import get_consumer
 
 # noinspection PyUnresolvedReferences
 from funboost.utils import nb_print, patch_print, LogManager, get_logger, LoggerMixin
 from funboost.timing_job import fsdf_background_scheduler, timing_publish_deco
 from funboost.constant import BrokerEnum, ConcurrentModeEnum
@@ -294,14 +294,19 @@
         func.push = func.delay = consumer.publisher_of_same_queue.push
         func.multi_process_pub_params_list = partial(multi_process_pub_params_list, func)
         func.clear = func.clear_queue = consumer.publisher_of_same_queue.clear
         func.get_message_count = consumer.publisher_of_same_queue.get_message_count
 
         func.start_consuming_message = func.consume = func.start = consumer.start_consuming_message
         func.multi_process_start = func.multi_process_consume = partial(run_consumer_with_multi_process, func)
+        if broker_kind == BrokerEnum.CELERY:   # celery作为消息队列
+            from multiprocessing import set_start_method
+            set_start_method('spawn', force=True)  # linux上运行需要这样。
+            func.consume = partial(func.multi_process_consume, 1)
+
         func.fabric_deploy = partial(fabric_deploy, func)
 
         func.clear_filter_tasks = consumer.clear_filter_tasks
 
         func.wait_for_possible_has_finish_all_tasks = consumer.wait_for_possible_has_finish_all_tasks
 
         func.pause = func.pause_consume = consumer.pause_consume
```

## funboost/constant.py

```diff
@@ -47,30 +47,33 @@
     """ 基于emq作为中间件的。这个和上面的中间件有很大不同，服务端不存储消息。所以不能先发布几十万个消息，然后再启动消费。mqtt优点是web前后端能交互，
     前端不能操作redis rabbitmq kafka，但很方便操作mqtt。这种使用场景是高实时的互联网接口。
     """
     MQTT = 17
 
     HTTPSQS = 18  # httpsqs中间件实现的，基于http协议操作，dcoker安装此中间件简单。
 
+    PULSAR = 20  # 最有潜力的下一代分布式消息系统。5年后会同时取代rabbitmq和kafka。
+
     UDP = 21  # 基于socket udp 实现的，需要先启动消费端再启动发布，支持分布式但不支持持久化，好处是不需要安装消息队列中间件软件。
 
     TCP = 22  # 基于socket tcp 实现的，需要先启动消费端再启动发布，支持分布式但不支持持久化，好处是不需要安装消息队列中间件软件。
 
     HTTP = 23  # 基于http实现的，发布使用的urllib3，消费服务端使用的aiohttp.server实现的，支持分布式但不支持持久化，好处是不需要安装消息队列中间件软件。
 
     NATS = 24  # 高性能中间件nats,中间件服务端性能很好,。
 
     TXT_FILE = 25  # 磁盘txt文件作为消息队列，支持单机持久化，不支持多机分布式。不建议这个，用sqlite。
 
     PEEWEE = 26  # peewee包操作mysql，使用表模拟消息队列
 
-    PULSAR = 20  # 最有潜力的下一代分布式消息系统。5年后会同时取代rabbitmq和kafka。目前python客户端只支持linux，win不行
+    REDIS_PUBSUB = 27  # 基于redis 发布订阅的，发布一个消息多个消费者都能收到消息，但不支持持久化
 
-    REDIS_PUBSUB = 27 # 基于redis 发布订阅的，发布一个消息多个消费者都能收到消息，但不支持持久化
+    CELERY = 30  # funboost支持celery框架来发布和消费任务，由celery框架来调度执行任务，但是写法简单暴击celery，永无无需关心和操作Celery对象实例。
 
+    NAMEKO = 40  # funboost支持python微服务框架nameko，用户无需掌握nameko api语法，就玩转python nameko微服务
 
 
 class ConcurrentModeEnum:
     THREADING = 1
     GEVENT = 2
     EVENTLET = 3
     ASYNC = 4  # asyncio并发，适用于async def定义的函数。
```

## funboost/funboost_config_deafult.py

```diff
@@ -1,10 +1,11 @@
 # -*- coding: utf-8 -*-
 
 from pathlib import Path
+import pytz
 from funboost.constant import BrokerEnum, ConcurrentModeEnum
 from funboost.helpers import FunctionResultStatusPersistanceConfig
 from funboost.utils.simple_data_class import DataClassBase
 
 '''
 此文件是第一次运行框架自动生成刀项目根目录的，不需要用由户手动创建。
 此文件里面可以写任意python代码。例如 中间件 帐号 密码自己完全可以从apola配置中心获取或者从环境变量获取。
@@ -22,15 +23,15 @@
 框架使用文档是 https://funboost.readthedocs.io/zh_CN/latest/
 
 '''
 
 # $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$  以下是中间件连接配置    $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
 
 
-MONGO_CONNECT_URL = f'mongodb://127.0.0.1:27017'  # 如果有密码连接 'mongodb://myUserAdmin:8mwTdy1klnSYepNo@192.168.199.202:27016/admin'
+MONGO_CONNECT_URL = f'mongodb://127.0.0.1:27017'  # 如果有密码连接 'mongodb://myUserAdmin:8mwTdy1klnSYepNo@192.168.199.202:27016/MONGO_CONNECT_URL = 'mongodb://root:123456@192.168.64.151:27017?authSource=admin''
 
 RABBITMQ_USER = 'rabbitmq_user'
 RABBITMQ_PASS = 'rabbitmq_pass'
 RABBITMQ_HOST = '127.0.0.1'
 RABBITMQ_PORT = 5672
 RABBITMQ_VIRTUAL_HOST = '/'  # my_host # 这个是rabbitmq的虚拟子host用户自己创建的，如果你想直接用rabbitmq的根host而不是使用虚拟子host，这里写 / 即可。
 
@@ -67,17 +68,20 @@
 
 HTTPSQS_HOST = '127.0.0.1'
 HTTPSQS_PORT = '1218'
 HTTPSQS_AUTH = '123456'
 
 NATS_URL = 'nats://192.168.6.134:4222'
 
-KOMBU_URL = 'redis://127.0.0.1:6379/0'
+KOMBU_URL = 'redis://127.0.0.1:6379/9'  # 这个就是celery依赖包kombu使用的消息队列格式，所以funboost支持一切celery支持的消息队列种类。
 # KOMBU_URL =  'sqla+sqlite:////dssf_kombu_sqlite.sqlite'  # 4个//// 代表磁盘根目录下生成一个文件。推荐绝对路径。3个///是相对路径。
 
+CELERY_BROKER_URL = 'redis://127.0.0.1:6379/12'  # 使用celery作为中间件。funboost新增支持celery框架来运行函数
+CELERY_RESULT_BACKEND = 'redis://127.0.0.1:6379/13'  # celery结果存放，可以为None
+
 PULSAR_URL = 'pulsar://192.168.70.128:6650'
 
 # $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ 以上是中间件连接配置    $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
 
 # nb_log包的第几个日志模板，内置了7个模板，可以在你当前项目根目录下的nb_log_config.py文件扩展模板。
 NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = 11  # 7是简短的不可跳转，5是可点击跳转的，11是可显示ip 进程 线程的模板。
 FSDF_DEVELOP_LOG_LEVEL = 50  # 作者开发时候的调试代码的日志，仅供我自己用，所以日志级别跳到最高，用户不需要管。
```

## funboost/helpers.py

```diff
@@ -209,16 +209,15 @@
                 'is_save_result': self.is_save_result, 'expire_seconds': self.expire_seconds}
 
     def __str__(self):
         return f'<FunctionResultStatusPersistanceConfig> {id(self)} {self.to_dict()}'
 
 
 # noinspection PyUnusedLocal
-def _interrupt_signal_handler(signal, frame):
+def _interrupt_signal_handler(signalx, framex):
     print('你按了 Ctrl+C  。 You pressed Ctrl+C!  结束程序！')
     # sys.exit(0)
     # noinspection PyUnresolvedReferences
     os._exit(0)  # os._exit才能更强力的迅速终止python，sys.exit只能退出主线程。
 
 
 signal.signal(signal.SIGINT, _interrupt_signal_handler)
-
```

## funboost/set_frame_config.py

```diff
@@ -154,14 +154,14 @@
                                
                                懂PYTHONPATH 的重要性和妙用见： https://github.com/ydf0509/pythonpathdemo
                                ''')
         return  # 当没设置pythonpath时候，也不要在 /lib/python36.zip这样的地方创建配置文件。
 
     file_name = Path(sys.path[1]) / Path('funboost_config.py')
     copyfile(Path(__file__).absolute().parent / Path('funboost_config_deafult.py'), file_name)
-    nb_print(f'在  {Path(sys.path[1])} 目录下自动生成了一个文件， 请查看或修改 \n "{file_name}:1" 文件')
+    nb_print(f'在  {Path(sys.path[1])} 目录下自动生成了一个文件， 请刷新文件夹查看或修改 \n "{file_name}:1" 文件')
     # with (file_name).open(mode='w', encoding='utf8') as f:
     #     nb_print(f'在 {file_name} 目录下自动生成了一个文件， 请查看或修改 \n "{file_name}:1" 文件')
     #     f.write(config_file_content)
 
 
 use_config_form_funboost_config_module()
```

## funboost/assist/user_custom_broker_register.py

```diff
@@ -48,7 +48,64 @@
     if __name__ == '__main__':
         f1.push(1,2)
         f1.consume()
     """
     from funboost.consumers.kombu_consumer import KombuConsumer
     from funboost.publishers.kombu_publisher import KombuPublisher
     register_custom_broker(BrokerEnum.KOMBU, KombuPublisher, KombuConsumer)
+
+
+def register_pulsar_broker():
+    from funboost.consumers.pulsar_consumer import PulsarConsumer
+    from funboost.publishers.pulsar_publisher import PulsarPublisher
+    register_custom_broker(BrokerEnum.PULSAR, PulsarPublisher, PulsarConsumer)
+
+
+def register_celery_broker():
+    """
+     如果有人想用celery作为funboost的消息队列中间件，先自己pip 安装celery包，然后调用这个函数，之后 boost装饰器就可以正常使用了。
+    :return:
+    """
+    """
+import time
+
+from funboost import boost, BrokerEnum
+from funboost.assist.user_custom_broker_register import register_celery_broker
+
+register_celery_broker()
+
+
+@boost('tets_funboost_celery_queue29a', broker_kind=BrokerEnum.CELERY, concurrent_num=10,
+       broker_exclusive_config={'celery_app_config':
+                                    {'task_default_rate_limit': '1/s', }}
+       )
+def fa(x, y):
+    time.sleep(3)
+    print(6666, x, y)
+
+
+@boost('tets_funboost_celery_queue29b', broker_kind=BrokerEnum.CELERY, concurrent_num=10,
+       broker_exclusive_config={'celery_app_config':
+                                    {'task_default_rate_limit': '2/s', }}
+       )
+def fb(a, b):
+    time.sleep(2)
+    print(7777, a, b)
+
+
+if __name__ == '__main__':
+    for i in range(1000):
+        fa.push(i, i + 1)
+        fb.push(i, i * 2)
+
+    fa.consume()
+    fb.consume()
+"""
+    from funboost.consumers.celery_consumer import CeleryConsumer
+    from funboost.publishers.celery_publisher import CeleryPublisher
+    register_custom_broker(BrokerEnum.CELERY, CeleryPublisher, CeleryConsumer)
+
+
+def register_nameko_broker():
+    from funboost.consumers.nameko_consumer import NamekoConsumer
+    from funboost.publishers.nameko_publisher import NamekoPublisher
+    register_custom_broker(BrokerEnum.NAMEKO, NamekoPublisher, NamekoConsumer)
```

## funboost/consumers/base_consumer.py

```diff
@@ -309,15 +309,15 @@
         #     return 'linux_fork'
 
 
 # noinspection DuplicatedCode
 class AbstractConsumer(LoggerLevelSetterMixin, metaclass=abc.ABCMeta, ):
     time_interval_for_check_do_not_run_time = 60
     BROKER_KIND = None
-    BROKER_EXCLUSIVE_CONFIG_KEYS = []  # 中间件能支持的独自的配置参数，例如kafka支持消费者组， 从最早还是最晚消费。因为支持30种中间件，
+    BROKER_EXCLUSIVE_CONFIG_DEFAULT = {}
 
     # 每种中间件的概念有所不同，用户可以从 broker_exclusive_config 中传递该种中间件特有的配置意义参数。
 
     @property
     @decorators.synchronized
     def publisher_of_same_queue(self):
         if not self._publisher_of_same_queue:
@@ -547,15 +547,16 @@
         self._result_persistence_helper: ResultPersistenceHelper
         self._user_custom_record_process_info_func = user_custom_record_process_info_func
 
         self._is_using_rpc_mode = is_using_rpc_mode
 
         if broker_exclusive_config is None:
             broker_exclusive_config = {}
-        self.broker_exclusive_config = broker_exclusive_config
+        self.broker_exclusive_config = copy.deepcopy(self.BROKER_EXCLUSIVE_CONFIG_DEFAULT)
+        self.broker_exclusive_config.update(broker_exclusive_config)
 
         self._stop_flag = None
         self._pause_flag = None  # 暂停消费标志，从reids读取
         self._last_show_pause_log_time = 0
         self._redis_key_stop_flag = f'funboost_stop_flag:{self.queue_name}'
         self._redis_key_pause_flag = f'funboost_pause_flag:{self.queue_name}'
 
@@ -590,19 +591,20 @@
 
         self._has_start_delay_task_scheduler = False
         self.custom_init()
 
         atexit.register(self.join_shedual_task_thread)
 
     def _check_broker_exclusive_config(self):
+        broker_exclusive_config_keys = self.BROKER_EXCLUSIVE_CONFIG_DEFAULT.keys()
         if self.broker_exclusive_config:
-            if set(self.broker_exclusive_config.keys()).issubset(self.BROKER_EXCLUSIVE_CONFIG_KEYS):
+            if set(self.broker_exclusive_config.keys()).issubset(broker_exclusive_config_keys):
                 self.logger.info(f'当前消息队列中间件能支持特殊独有配置 {self.broker_exclusive_config.keys()}')
             else:
-                self.logger.warning(f'当前消息队列中间件含有不支持的特殊配置 {self.broker_exclusive_config.keys()}，能支持的特殊独有配置包括 {self.BROKER_EXCLUSIVE_CONFIG_KEYS}')
+                self.logger.warning(f'当前消息队列中间件含有不支持的特殊配置 {self.broker_exclusive_config.keys()}，能支持的特殊独有配置包括 {broker_exclusive_config_keys}')
 
     def _check_monkey_patch(self):
         if self._concurrent_mode == 2:
             check_gevent_monkey_patch()
         elif self._concurrent_mode == 3:
             check_evenlet_monkey_patch()
         else:
@@ -703,14 +705,99 @@
     def _shedual_task(self):
         """
         每个子类必须实现这个的方法，完成如何从中间件取出消息，并将函数和运行参数添加到工作池。
         :return:
         """
         raise NotImplementedError
 
+    def _submit_task(self, kw):
+        while 1:  # 这一块的代码为支持暂停消费。
+            # print(self._pause_flag)
+            if self._pause_flag == 1:
+                time.sleep(5)
+                if time.time() - self._last_show_pause_log_time > 60:
+                    self.logger.warning(f'已设置 {self.queue_name} 队列中的任务为暂停消费')
+                    self._last_show_pause_log_time = time.time()
+            else:
+                break
+
+        if self._judge_is_daylight():
+            self._requeue(kw)
+            time.sleep(self.time_interval_for_check_do_not_run_time)
+            return
+
+        function_only_params = _delete_keys_and_return_new_dict(kw['body'], )
+        if self._get_priority_conf(kw, 'do_task_filtering') and self._redis_filter.check_value_exists(
+                function_only_params):  # 对函数的参数进行检查，过滤已经执行过并且成功的任务。
+            self.logger.warning(f'redis的 [{self._redis_filter_key_name}] 键 中 过滤任务 {kw["body"]}')
+            self._confirm_consume(kw)
+            return
+        publish_time = _get_publish_time(kw['body'])
+        msg_expire_senconds_priority = self._get_priority_conf(kw, 'msg_expire_senconds')
+        if msg_expire_senconds_priority and time.time() - msg_expire_senconds_priority > publish_time:
+            self.logger.warning(
+                f'消息发布时戳是 {publish_time} {kw["body"].get("publish_time_format", "")},距离现在 {round(time.time() - publish_time, 4)} 秒 ,'
+                f'超过了指定的 {msg_expire_senconds_priority} 秒，丢弃任务')
+            self._confirm_consume(kw)
+            return 0
+
+        msg_eta = self._get_priority_conf(kw, 'eta')
+        msg_countdown = self._get_priority_conf(kw, 'countdown')
+        misfire_grace_time = self._get_priority_conf(kw, 'misfire_grace_time')
+        run_date = None
+        # print(kw)
+        if msg_countdown:
+            run_date = time_util.DatetimeConverter(kw['body']['extra']['publish_time']).datetime_obj + datetime.timedelta(seconds=msg_countdown)
+        if msg_eta:
+            run_date = time_util.DatetimeConverter(msg_eta).datetime_obj
+        # print(run_date,time_util.DatetimeConverter().datetime_obj)
+        # print(run_date.timestamp(),time_util.DatetimeConverter().datetime_obj.timestamp())
+        # print(self.concurrent_pool)
+        if run_date:  # 延时任务
+            # print(repr(run_date),repr(datetime.datetime.now(tz=pytz.timezone(frame_config.TIMEZONE))))
+            if self._has_start_delay_task_scheduler is False:
+                self._has_start_delay_task_scheduler = True
+                self._start_delay_task_scheduler()
+            self._delay_task_scheduler.add_job(self.concurrent_pool.submit, 'date', run_date=run_date, args=(self._run,), kwargs={'kw': kw},
+                                               misfire_grace_time=misfire_grace_time)
+        else:  # 普通任务
+            self.concurrent_pool.submit(self._run, kw)
+
+        if self._is_using_distributed_frequency_control:  # 如果是需要分布式控频。
+            active_num = self._distributed_consumer_statistics.active_consumer_num
+            self._frequency_control(self._qps / active_num, self._msg_schedule_time_intercal * active_num)
+        else:
+            self._frequency_control(self._qps, self._msg_schedule_time_intercal)
+
+    def _frequency_control(self, qpsx: float, msg_schedule_time_intercalx: float):
+        # 以下是消费函数qps控制代码。无论是单个消费者空频还是分布式消费控频，都是基于直接计算的，没有依赖redis inrc计数，使得控频性能好。
+        if qpsx == 0:  # 不需要控频的时候，就不需要休眠。
+            return
+        if qpsx <= 5:
+            """ 原来的简单版 """
+            time.sleep(msg_schedule_time_intercalx)
+        elif 5 < qpsx <= 20:
+            """ 改进的控频版,防止消息队列中间件网络波动，例如1000qps使用redis,不能每次间隔1毫秒取下一条消息，
+            如果取某条消息有消息超过了1毫秒，后面不能匀速间隔1毫秒获取，time.sleep不能休眠一个负数来让时光倒流"""
+            time_sleep_for_qps_control = max((msg_schedule_time_intercalx - (time.time() - self._last_submit_task_timestamp)) * 0.99, 10 ** -3)
+            # print(time.time() - self._last_submit_task_timestamp)
+            # print(time_sleep_for_qps_control)
+            time.sleep(time_sleep_for_qps_control)
+            self._last_submit_task_timestamp = time.time()
+        else:
+            """基于当前消费者计数的控频，qps很大时候需要使用这种"""
+            if time.time() - self._last_start_count_qps_timestamp > 1:
+                self._has_execute_times_in_recent_second = 1
+                self._last_start_count_qps_timestamp = time.time()
+            else:
+                self._has_execute_times_in_recent_second += 1
+            # print(self._has_execute_times_in_recent_second)
+            if self._has_execute_times_in_recent_second >= qpsx:
+                time.sleep((1 - (time.time() - self._last_start_count_qps_timestamp)) * 1)
+
     def _print_message_get_from_broker(self, broker_name, msg):
         # print(999)
         if self._is_show_message_get_from_broker:
             if isinstance(msg, (dict, list)):
                 msg = json.dumps(msg, ensure_ascii=False)
             self.logger.debug(f'从 {broker_name} 中间件 的 {self._queue_name} 中取出的消息是 {msg}')
 
@@ -987,15 +1074,15 @@
     @abc.abstractmethod
     def _confirm_consume(self, kw):
         """确认消费"""
         raise NotImplementedError
 
     def check_heartbeat_and_message_count(self):
         self._msg_num_in_broker = self.publisher_of_same_queue.get_message_count()
-        if time.time() - self._last_timestamp_print_msg_num > 60:
+        if time.time() - self._last_timestamp_print_msg_num > 600:
             if self._msg_num_in_broker != -1:
                 self.logger.info(f'队列 [{self._queue_name}] 中还有 [{self._msg_num_in_broker}] 个任务')
             self._last_timestamp_print_msg_num = time.time()
         if self._msg_num_in_broker != 0:
             self._last_timestamp_when_has_task_in_queue = time.time()
         return self._msg_num_in_broker
 
@@ -1036,99 +1123,14 @@
         """设置队列为暂停消费状态"""
         RedisMixin().redis_db_frame.set(self._redis_key_pause_flag, 1)
 
     def continue_consume(self):
         """设置队列为继续消费状态"""
         RedisMixin().redis_db_frame.set(self._redis_key_pause_flag, 0)
 
-    def _submit_task(self, kw):
-        while 1:  # 这一块的代码为支持暂停消费。
-            # print(self._pause_flag)
-            if self._pause_flag == 1:
-                time.sleep(5)
-                if time.time() - self._last_show_pause_log_time > 60:
-                    self.logger.warning(f'已设置 {self.queue_name} 队列中的任务为暂停消费')
-                    self._last_show_pause_log_time = time.time()
-            else:
-                break
-
-        if self._judge_is_daylight():
-            self._requeue(kw)
-            time.sleep(self.time_interval_for_check_do_not_run_time)
-            return
-
-        function_only_params = _delete_keys_and_return_new_dict(kw['body'], )
-        if self._get_priority_conf(kw, 'do_task_filtering') and self._redis_filter.check_value_exists(
-                function_only_params):  # 对函数的参数进行检查，过滤已经执行过并且成功的任务。
-            self.logger.warning(f'redis的 [{self._redis_filter_key_name}] 键 中 过滤任务 {kw["body"]}')
-            self._confirm_consume(kw)
-            return
-        publish_time = _get_publish_time(kw['body'])
-        msg_expire_senconds_priority = self._get_priority_conf(kw, 'msg_expire_senconds')
-        if msg_expire_senconds_priority and time.time() - msg_expire_senconds_priority > publish_time:
-            self.logger.warning(
-                f'消息发布时戳是 {publish_time} {kw["body"].get("publish_time_format", "")},距离现在 {round(time.time() - publish_time, 4)} 秒 ,'
-                f'超过了指定的 {msg_expire_senconds_priority} 秒，丢弃任务')
-            self._confirm_consume(kw)
-            return 0
-
-        msg_eta = self._get_priority_conf(kw, 'eta')
-        msg_countdown = self._get_priority_conf(kw, 'countdown')
-        misfire_grace_time = self._get_priority_conf(kw, 'misfire_grace_time')
-        run_date = None
-        # print(kw)
-        if msg_countdown:
-            run_date = time_util.DatetimeConverter(kw['body']['extra']['publish_time']).datetime_obj + datetime.timedelta(seconds=msg_countdown)
-        if msg_eta:
-            run_date = time_util.DatetimeConverter(msg_eta).datetime_obj
-        # print(run_date,time_util.DatetimeConverter().datetime_obj)
-        # print(run_date.timestamp(),time_util.DatetimeConverter().datetime_obj.timestamp())
-        # print(self.concurrent_pool)
-        if run_date:  # 延时任务
-            # print(repr(run_date),repr(datetime.datetime.now(tz=pytz.timezone(frame_config.TIMEZONE))))
-            if self._has_start_delay_task_scheduler is False:
-                self._has_start_delay_task_scheduler = True
-                self._start_delay_task_scheduler()
-            self._delay_task_scheduler.add_job(self.concurrent_pool.submit, 'date', run_date=run_date, args=(self._run,), kwargs={'kw': kw},
-                                               misfire_grace_time=misfire_grace_time)
-        else:  # 普通任务
-            self.concurrent_pool.submit(self._run, kw)
-
-        if self._is_using_distributed_frequency_control:  # 如果是需要分布式控频。
-            active_num = self._distributed_consumer_statistics.active_consumer_num
-            self._frequency_control(self._qps / active_num, self._msg_schedule_time_intercal * active_num)
-        else:
-            self._frequency_control(self._qps, self._msg_schedule_time_intercal)
-
-    def _frequency_control(self, qpsx, msg_schedule_time_intercalx):
-        # 以下是消费函数qps控制代码。无论是单个消费者空频还是分布式消费控频，都是基于直接计算的，没有依赖redis inrc计数，使得控频性能好。
-        if qpsx == 0:  # 不需要控频的时候，就不需要休眠。
-            return
-        if qpsx <= 5:
-            """ 原来的简单版 """
-            time.sleep(msg_schedule_time_intercalx)
-        elif 5 < qpsx <= 20:
-            """ 改进的控频版,防止消息队列中间件网络波动，例如1000qps使用redis,不能每次间隔1毫秒取下一条消息，
-            如果取某条消息有消息超过了1毫秒，后面不能匀速间隔1毫秒获取，time.sleep不能休眠一个负数来让时光倒流"""
-            time_sleep_for_qps_control = max((msg_schedule_time_intercalx - (time.time() - self._last_submit_task_timestamp)) * 0.99, 10 ** -3)
-            # print(time.time() - self._last_submit_task_timestamp)
-            # print(time_sleep_for_qps_control)
-            time.sleep(time_sleep_for_qps_control)
-            self._last_submit_task_timestamp = time.time()
-        else:
-            """基于当前消费者计数的控频，qps很大时候需要使用这种"""
-            if time.time() - self._last_start_count_qps_timestamp > 1:
-                self._has_execute_times_in_recent_second = 1
-                self._last_start_count_qps_timestamp = time.time()
-            else:
-                self._has_execute_times_in_recent_second += 1
-            # print(self._has_execute_times_in_recent_second)
-            if self._has_execute_times_in_recent_second >= qpsx:
-                time.sleep((1 - (time.time() - self._last_start_count_qps_timestamp)) * 1)
-
     @decorators.FunctionResultCacher.cached_function_result_for_a_time(120)
     def _judge_is_daylight(self):
         if self._is_do_not_run_by_specify_time_effect and (
                 self._do_not_run_by_specify_time[0] < time_util.DatetimeConverter().time_str < self._do_not_run_by_specify_time[1]):
             self.logger.warning(
                 f'现在时间是 {time_util.DatetimeConverter()} ，现在时间是在 {self._do_not_run_by_specify_time} 之间，不运行')
             return True
```

## funboost/consumers/kafka_consumer.py

```diff
@@ -20,18 +20,15 @@
 class KafkaConsumer(AbstractConsumer):
     """
     kafka作为中间件实现的。自动确认消费，最多消费一次，随意重启会丢失正在大批正在运行的任务。推荐使用 confluent_kafka 中间件，kafka_consumer_manually_commit.py。
 
     可以让消费函数内部 sleep60秒，突然停止消费代码，使用 kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group funboost 来证实自动确认消费和手动确认消费的区别。
     """
     BROKER_KIND = 8
-    KAFKA_GROUP_ID = 'funboost_kafka'
-    AUTO_OFFSET_RESET = 'earliest'
-
-    BROKER_EXCLUSIVE_CONFIG_KEYS = ['group_id','auto_offset_reset']
+    BROKER_EXCLUSIVE_CONFIG_DEFAULT = {'group_id':'funboost_kafka','auto_offset_reset':'earliest'}
     # not_all_brokers_general_settings配置 ，支持独立的中间件配置参数是 group_id 和 auto_offset_reset
     """
     auto_offset_reset 介绍
       auto_offset_reset (str): A policy for resetting offsets on
             OffsetOutOfRange errors: 'earliest' will move to the oldest
             available message, 'latest' will move to the most recent. Any
             other value will raise the exception. Default: 'latest'.
@@ -43,17 +40,17 @@
             admin_client.create_topics([NewTopic(self._queue_name, 10, 1)])
             # admin_client.create_partitions({self._queue_name: NewPartitions(total_count=16)})
         except TopicAlreadyExistsError:
             pass
 
         self._producer = KafkaProducer(bootstrap_servers=funboost_config_deafult.KAFKA_BOOTSTRAP_SERVERS)
         consumer = OfficialKafkaConsumer(self._queue_name, bootstrap_servers=funboost_config_deafult.KAFKA_BOOTSTRAP_SERVERS,
-                                         group_id=self.broker_exclusive_config.get("group_id", self.KAFKA_GROUP_ID),
+                                         group_id=self.broker_exclusive_config["group_id"],
                                          enable_auto_commit=True,
-                                         auto_offset_reset=self.broker_exclusive_config.get("auto_offset_reset", self.AUTO_OFFSET_RESET),
+                                         auto_offset_reset=self.broker_exclusive_config["auto_offset_reset"],
                                          )
         #  auto_offset_reset (str): A policy for resetting offsets on
         #             OffsetOutOfRange errors: 'earliest' will move to the oldest
         #             available message, 'latest' will move to the most recent. Any
         #             other value will raise the exception. Default: 'latest'.       默认是latest
 
         # kafka 的 group_id
```

## funboost/consumers/kafka_consumer_manually_commit.py

```diff
@@ -25,16 +25,15 @@
     confluent_kafla作为中间件实现的。操作kafka中间件的速度比kafka-python快10倍。
     这个是自动间隔2秒的手动确认，由于是异步在并发池中并发消费，可以防止强制关闭程序造成正在运行的任务丢失，比自动commit好。
     如果使用kafka，推荐这个。
 
     可以让消费函数内部 sleep 60秒，突然停止消费代码，使用 kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group frame_group 来证实自动确认消费和手动确认消费的区别。
     """
     BROKER_KIND = 16
-    KAFKA_GROUP_ID = 'funboost_confluent_kafka'
-    BROKER_EXCLUSIVE_CONFIG_KEYS = ['group_id', 'auto_offset_reset']
+    BROKER_EXCLUSIVE_CONFIG_DEFAULT = {'group_id':'funboost_confluent_kafka','auto_offset_reset':'earliest'}
 
     def _shedual_task(self):
 
         from confluent_kafka import Consumer as ConfluentConsumer  # 这个包在win下不好安装，用户用这个中间件的时候自己再想办法安装。win用户需要安装c++ 14.0以上环境。
         try:
             admin_client = KafkaAdminClient(bootstrap_servers=funboost_config_deafult.KAFKA_BOOTSTRAP_SERVERS)
             admin_client.create_topics([NewTopic(self._queue_name, 10, 1)])
@@ -42,16 +41,16 @@
         except TopicAlreadyExistsError:
             pass
 
         self._producer = KafkaProducer(bootstrap_servers=funboost_config_deafult.KAFKA_BOOTSTRAP_SERVERS)
         # consumer 配置 https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md
         self._confluent_consumer = ConfluentConsumer({
             'bootstrap.servers': ','.join(funboost_config_deafult.KAFKA_BOOTSTRAP_SERVERS),
-            'group.id': self.broker_exclusive_config.get("group_id", self.KAFKA_GROUP_ID),
-            'auto.offset.reset': self.broker_exclusive_config.get("auto_offset_reset", 'earliest'),
+            'group.id': self.broker_exclusive_config["group_id"],
+            'auto.offset.reset': self.broker_exclusive_config["auto_offset_reset"],
             'enable.auto.commit': False
         })
         self._confluent_consumer.subscribe([self._queue_name])
 
         self._recent_commit_time = time.time()
         self._partion__offset_consume_status_map = defaultdict(OrderedDict)
         while 1:
```

## funboost/consumers/kombu_consumer.py

```diff
@@ -1,30 +1,35 @@
 # -*- coding: utf-8 -*-
 # @Author  : ydf
 # @Time    : 2021/04/18 0008 13:32
 # import time
+import os
 
+import traceback
+from pathlib import Path
 from kombu.entity import Exchange, Queue
 from kombu.connection import Connection
 from kombu.transport.virtual.base import Channel
 from kombu.transport.virtual.base import Message
-from nb_log import LogManager
+from kombu.transport import redis
+from kombu.transport.redis import Empty
+
+from nb_log import get_logger
 
 from funboost import funboost_config_deafult
 from funboost.consumers.base_consumer import AbstractConsumer
 
 
-def patch_kombu_redis():
+def patch_kombu_redis000():
+    # 这个也可以，代码长了一点。
     """
     给kombu的redis 模式打猴子补丁
-    kombu有bug，redis中间件 unnacked 中的任务即使客户端掉线了后者突然关闭脚本中正在运行的任务，也永远不会被重新消费。
+    kombu有bug，redis中间件 unnacked 中的任务即使客户端掉线了或者突然关闭脚本中正在运行的任务，也永远不会被重新消费。
     这个很容易验证那个测试，把消费函数写成sleep 100秒，启动20秒后把脚本关掉，取出来的任务在 unacked 队列中那个永远不会被确认消费，也不会被重新消费。
     """
-    from kombu.transport import redis
-    # from kombu.five import Empty  #
 
     # noinspection PyUnusedLocal
     def monkey_get(self, callback, timeout=None):
         self._in_protected_read = True
         try:
             for channel in self._channels:
                 if channel.active_queues:  # BRPOP mode?
@@ -35,68 +40,178 @@
 
             events = self.poller.poll(timeout)
             if events:
                 for fileno, event in events:
                     ret = None
                     # noinspection PyBroadException,PyUnusedLocal
                     try:
-                        ret = self.handle_event(fileno, event)
+                        ret = self.handle_event(fileno, event)  # 主要是这行改了加了try，不然会raise empty 导致self.maybe_restore_messages()没执行
                     except BaseException as e:
                         pass
+                        # print(traceback.format_exc())
+                        # print(e)
                     if ret:
                         return
             # - no new data, so try to restore messages.
             # - reset active redis commands.
             self.maybe_restore_messages()
-            # raise Empty()
+            raise Empty()
             # raise Exception('kombu.five.Empty')
         finally:
             self._in_protected_read = False
+            # print(self.after_read)
             while self.after_read:
                 try:
                     fun = self.after_read.pop()
                 except KeyError:
                     break
                 else:
                     fun()
 
     redis.MultiChannelPoller.get = monkey_get
 
 
+has_patch_kombu_redis = False
+
+
+def patch_kombu_redis():
+    """
+    给kombu的redis 模式打猴子补丁
+    kombu有bug，redis中间件 unnacked 中的任务即使客户端掉线了或者突然关闭脚本中正在运行的任务，也永远不会被重新消费。
+    这个很容易验证那个测试，把消费函数写成sleep 100秒，启动20秒后把脚本关掉，取出来的任务在 unacked 队列中那个永远不会被确认消费，也不会被重新消费。
+    """
+    global has_patch_kombu_redis
+    if not has_patch_kombu_redis:
+        redis_multichannelpoller_get_raw = redis.MultiChannelPoller.get
+
+        # noinspection PyUnusedLocal
+        def monkey_get(self, callback, timeout=None):
+            try:
+                redis_multichannelpoller_get_raw(self, callback, timeout)
+            except Empty:
+                self.maybe_restore_messages()
+                raise Empty()
+
+        redis.MultiChannelPoller.get = monkey_get
+        has_patch_kombu_redis = True
+
+
+''' kombu 能支持的消息队列中间件有如下，可以查看 D:\ProgramData\Miniconda3\Lib\site-packages\kombu\transport\__init__.py 文件。
+
+TRANSPORT_ALIASES = {
+    'amqp': 'kombu.transport.pyamqp:Transport',
+    'amqps': 'kombu.transport.pyamqp:SSLTransport',
+    'pyamqp': 'kombu.transport.pyamqp:Transport',
+    'librabbitmq': 'kombu.transport.librabbitmq:Transport',
+    'memory': 'kombu.transport.memory:Transport',
+    'redis': 'kombu.transport.redis:Transport',
+    'rediss': 'kombu.transport.redis:Transport',
+    'SQS': 'kombu.transport.SQS:Transport',
+    'sqs': 'kombu.transport.SQS:Transport',
+    'mongodb': 'kombu.transport.mongodb:Transport',
+    'zookeeper': 'kombu.transport.zookeeper:Transport',
+    'sqlalchemy': 'kombu.transport.sqlalchemy:Transport',
+    'sqla': 'kombu.transport.sqlalchemy:Transport',
+    'SLMQ': 'kombu.transport.SLMQ.Transport',
+    'slmq': 'kombu.transport.SLMQ.Transport',
+    'filesystem': 'kombu.transport.filesystem:Transport',
+    'qpid': 'kombu.transport.qpid:Transport',
+    'sentinel': 'kombu.transport.redis:SentinelTransport',
+    'consul': 'kombu.transport.consul:Transport',
+    'etcd': 'kombu.transport.etcd:Transport',
+    'azurestoragequeues': 'kombu.transport.azurestoragequeues:Transport',
+    'azureservicebus': 'kombu.transport.azureservicebus:Transport',
+    'pyro': 'kombu.transport.pyro:Transport'
+}
+
+'''
+
+
 # noinspection PyAttributeOutsideInit
 class KombuConsumer(AbstractConsumer, ):
     """
     使用kombu作为中间件,这个能直接一次性支持很多种小众中间件，但性能很差，除非是分布式函数调度框架没实现的中间件种类用户才可以用这种，用户也可以自己对比性能。
     """
 
     BROKER_KIND = 15
+    BROKER_EXCLUSIVE_CONFIG_DEFAULT = {'kombu_url': None,  # 如果这里也配置了kombu_url,则优先使用跟着你的kombu_url，否则使用funboost_config. KOMBU_URL
+                                       'transport_options': {},  # transport_options是kombu的transport_options 。
+                                       'prefetch_count': 500
+                                       }
+    # prefetch_count 是预获取消息数量
+    ''' transport_options是kombu的transport_options 。 
+       例如使用kombu使用redis作为中间件时候，可以设置 visibility_timeout 来决定消息取出多久没有ack，就自动重回队列。
+       kombu的每个中间件能设置什么 transport_options 可以看 kombu的源码中的 transport_options 参数说明。
+
+例如kombu redis的Transport Options 说明
+D:\ProgramData\Miniconda3\envs\py311\Lib\site-packages\kombu\transport\redis.py
+
+Transport Options
+=================
+* ``sep``
+* ``ack_emulation``: (bool) If set to True transport will
+  simulate Acknowledge of AMQP protocol.
+* ``unacked_key``
+* ``unacked_index_key``
+* ``unacked_mutex_key``
+* ``unacked_mutex_expire``
+* ``visibility_timeout``
+* ``unacked_restore_limit``
+* ``fanout_prefix``
+* ``fanout_patterns``
+* ``global_keyprefix``: (str) The global key prefix to be prepended to all keys
+  used by Kombu
+* ``socket_timeout``
+* ``socket_connect_timeout``
+* ``socket_keepalive``
+* ``socket_keepalive_options``
+* ``queue_order_strategy``
+* ``max_connections``
+* ``health_check_interval``
+* ``retry_on_timeout``
+* ``priority_steps``
+
+
+      '''
 
     def custom_init(self):
-        self._middware_name = funboost_config_deafult.KOMBU_URL.split(":")[0]
+        self.kombu_url = self.broker_exclusive_config['kombu_url'] or funboost_config_deafult.KOMBU_URL
+        self._middware_name = self.kombu_url.split(":")[0]
         logger_name = f'{self._logger_prefix}{self.__class__.__name__}--{self._middware_name}--{self._queue_name}'
-        self.logger = LogManager(logger_name).get_logger_and_add_handlers(self._log_level,
-                                                                          log_filename=f'{logger_name}.log' if self._create_logger_file else None,
-                                                                          formatter_template=funboost_config_deafult.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER,
-                                                                          )  #
-        patch_kombu_redis()
+        self.logger = get_logger(logger_name, log_level_int=self._log_level,
+                                 log_filename=f'{logger_name}.log' if self._create_logger_file else None,
+                                 formatter_template=funboost_config_deafult.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER,
+                                 )  #
+        if self.kombu_url.startswith('filesystem://'):
+            self._create_msg_file_dir()
+
+    def _create_msg_file_dir(self):
+        os.makedirs(self.broker_exclusive_config['transport_options']['data_folder_in'], exist_ok=True)
+        os.makedirs(self.broker_exclusive_config['transport_options']['data_folder_out'], exist_ok=True)
+        processed_folder = self.broker_exclusive_config['transport_options'].get('processed_folder', None)
+        if processed_folder:
+            os.makedirs(processed_folder, exist_ok=True)
 
     # noinspection DuplicatedCode
     def _shedual_task(self):  # 这个倍while 1 启动的，会自动重连。
+        patch_kombu_redis()
+
         def callback(body: dict, message: Message):
             # print(type(body),body,type(message),message)
             self._print_message_get_from_broker('kombu', body)
             # self.logger.debug(f""" 从 kombu {self._middware_name} 中取出的消息是 {body}""")
             kw = {'body': body, 'message': message, }
             self._submit_task(kw)
 
         self.exchange = Exchange('funboost_exchange', 'direct', durable=True)
-        self.queue = Queue(self._queue_name, exchange=self.exchange, routing_key=self._queue_name, auto_delete=False)
-        self.conn = Connection(funboost_config_deafult.KOMBU_URL, transport_options={"visibility_timeout": 600})  # 默认3600秒unacked重回队列
+        self.queue = Queue(self._queue_name, exchange=self.exchange, routing_key=self._queue_name, auto_delete=False, no_ack=False)
+        # https://docs.celeryq.dev/projects/kombu/en/stable/reference/kombu.html?highlight=visibility_timeout#kombu.Connection 每种中间件的transport_options不一样。
+        self.conn = Connection(self.kombu_url, transport_options=self.broker_exclusive_config['transport_options'])
         self.queue(self.conn).declare()
-        with self.conn.Consumer(self.queue, callbacks=[callback], no_ack=False, prefetch_count=100) as consumer:
+        with self.conn.Consumer(self.queue, callbacks=[callback], no_ack=False, prefetch_count=self.broker_exclusive_config['prefetch_count']) as consumer:
             # Process messages and handle events on all channels
             channel = consumer.channel  # type:Channel
             channel.body_encoding = 'no_encode'  # 这里改了编码，存到中间件的参数默认把消息base64了，我觉得没必要不方便查看消息明文。
             while True:
                 self.conn.drain_events()
 
     def _confirm_consume(self, kw):
```

## funboost/consumers/pulsar_consumer.py

```diff
@@ -1,10 +1,7 @@
-
-
-
 '''
 
 import pulsar
 
 client = pulsar.Client('pulsar://localhost:6650')
 consumer = client.subscribe('my-topic',
                             subscription_name='my-sub')
@@ -16,45 +13,52 @@
 
 client.close()
 '''
 
 # -*- coding: utf-8 -*-
 # @Author  : ydf
 # @Time    : 2022/8/8 0008 13:32
+import os
+
 import json
+from _pulsar import ConsumerType
+from pulsar.schema import schema
+
 from funboost.consumers.base_consumer import AbstractConsumer
-from  funboost import funboost_config_deafult
+from funboost import funboost_config_deafult
 
 
 class PulsarConsumer(AbstractConsumer, ):
     """
     pulsar作为中间件实现的。
     """
     BROKER_KIND = 20
-    BROKER_EXCLUSIVE_CONFIG_KEYS = ['subscription_name']
-    SUBSCRIPTION_NAME = 'funboost'
+    BROKER_EXCLUSIVE_CONFIG_DEFAULT = {'subscription_name': 'funboost_group',
+                                       'replicate_subscription_state_enabled': True,
+                                       'consumer_type': ConsumerType.Shared,
+                                       }
 
     def custom_init(self):
+        pass
+
+    def _shedual_task(self):
         try:
             import pulsar  # 需要用户自己 pip install pulsar-client ，目前20221206只支持linux安装此python包。
         except ImportError:
-            raise ImportError('需要用户自己 pip install pulsar-client ，目前20221206只支持linux安装此python包,win不支持。')
-        self._client = pulsar.Client(funboost_config_deafult.PULSAR_URL)
-        self._consumer = self._client.subscribe(self._queue_name,
-                                    subscription_name=self.SUBSCRIPTION_NAME)
-
-    def _shedual_task(self):
+            raise ImportError('需要用户自己 pip install pulsar-client ，')
+        self._client = pulsar.Client(funboost_config_deafult.PULSAR_URL, )
+        self._consumer = self._client.subscribe(self._queue_name, schema=schema.StringSchema(), consumer_name=f'funboost_consumer_{os.getpid()}',
+                                                subscription_name=self.broker_exclusive_config['subscription_name'],
+                                                consumer_type=self.broker_exclusive_config['consumer_type'],
+                                                replicate_subscription_state_enabled=self.broker_exclusive_config['replicate_subscription_state_enabled'])
         while True:
             msg = self._consumer.receive()
             if msg:
-                self._print_message_get_from_broker('pulsar',msg.data())
-                kw = {'body': json.loads(msg.data()),'msg':msg}
+                self._print_message_get_from_broker('pulsar', msg.data())
+                kw = {'body': json.loads(msg.data()), 'msg': msg}
                 self._submit_task(kw)
 
     def _confirm_consume(self, kw):
         self._consumer.acknowledge(kw['msg'])
 
     def _requeue(self, kw):
         self._consumer.negative_acknowledge(kw['msg'])
-
-
-
```

## funboost/consumers/rabbitmq_amqpstorm_consumer.py

```diff
@@ -34,10 +34,10 @@
         # noinspection PyBroadException
         try:
             kw['amqpstorm_message'].ack()  # 确认消费
         except BaseException as e:
             self.logger.error(f'AmqpStorm确认消费失败  {type(e)} {e}')
 
     def _requeue(self, kw):
-        amqpstorm.Message.delivery_tag
+        # amqpstorm.Message.delivery_tag
         print(kw['amqpstorm_message'].delivery_tag)
         kw['amqpstorm_message'].nack(requeue=True)
```

## funboost/consumers/redis_consumer.py

```diff
@@ -13,15 +13,15 @@
     """
     redis作为中间件实现的，使用redis list 结构实现的。
     这个如果消费脚本在运行时候随意反复重启或者非正常关闭或者消费宕机，会丢失大批任务。高可靠需要用rabbitmq或者redis_ack_able或者redis_stream的中间件方式。
 
     这个是复杂版，一次性拉取100个，简单版在 funboost/consumers/redis_consumer_simple.py
     """
     BROKER_KIND = 2
-    BROKER_EXCLUSIVE_CONFIG_KEYS = ['redis_bulk_push', ]
+    BROKER_EXCLUSIVE_CONFIG_DEFAULT = {'redis_bulk_push':0}   #redis_bulk_push 是否redis批量推送
 
     # noinspection DuplicatedCode
     def _shedual_task000(self):
         while True:
             result = self.redis_db_frame.blpop(self._queue_name, timeout=60)
             if result:
                 # self.logger.debug(f'从redis的 [{self._queue_name}] 队列中 取出的消息是：  {result[1].decode()}  ')
```

## funboost/consumers/redis_consumer_simple.py

```diff
@@ -1,10 +1,10 @@
 ﻿# -*- coding: utf-8 -*-
 # @Author  : ydf
-# @Time    : 2022/8/8 0008 13:32
+# @Time    : 2023/8/8 0008 13:32
 import json
 from funboost.consumers.base_consumer import AbstractConsumer
 from funboost.utils import RedisMixin
 
 
 class RedisConsumer(AbstractConsumer, RedisMixin):
     """
```

## funboost/factories/consumer_factory.py

```diff
@@ -1,20 +1,20 @@
 # -*- coding: utf-8 -*-
 # @Author  : ydf
 # @Time    : 2022/8/8 0008 13:19
 import copy
 # from collections import Callable
 from typing import Callable
 
-from funboost.consumers.pulsar_consumer import PulsarConsumer
+# from funboost.consumers.pulsar_consumer import PulsarConsumer
 from funboost.consumers.redis_pubsub_consumer import RedisPbSubConsumer
 from funboost.consumers.http_consumer import HTTPConsumer
 from funboost.consumers.kafka_consumer import KafkaConsumer
 from funboost.consumers.kafka_consumer_manually_commit import KafkaConsumerManuallyCommit
-# from funboost.consumers.kombu_consumer import KombuConsumer
+from funboost.consumers.kombu_consumer import KombuConsumer
 from funboost.consumers.local_python_queue_consumer import LocalPythonQueueConsumer
 from funboost.consumers.mongomq_consumer import MongoMqConsumer
 from funboost.consumers.nats_consumer import NatsConsumer
 from funboost.consumers.nsq_consumer import NsqConsumer
 from funboost.consumers.peewee_conusmer import PeeweeConsumer
 from funboost.consumers.persist_queue_consumer import PersistQueueConsumer
 from funboost.consumers.rabbitmq_amqpstorm_consumer import RabbitmqConsumerAmqpStorm
@@ -45,19 +45,19 @@
     8: KafkaConsumer,
     9: RedisConsumerAckAble,
     10: SqlachemyConsumer,
     11: RocketmqConsumer,
     12: RedisStreamConsumer,
     13: ZeroMqConsumer,
     14: RedisBrpopLpushConsumer,
-    # 15: KombuConsumer,
+    15: KombuConsumer,
     16: KafkaConsumerManuallyCommit,
     17: MqttConsumer,
     18: HttpsqsConsumer,
-    20: PulsarConsumer,
+    # 20: PulsarConsumer,  # 用户如果想用pulsar，先pip 安装pulsar-client ,然后代码调用 register_pulsar_broker() 会自动添加到这个字典里面
     21: UDPConsumer,
     22: TCPConsumer,
     23: HTTPConsumer,
     24: NatsConsumer,
     25: TxtFileConsumer,
     26: PeeweeConsumer,
     27: RedisPbSubConsumer,
```

## funboost/factories/publisher_factotry.py

```diff
@@ -2,18 +2,18 @@
 # @Author  : ydf
 # @Time    : 2022/8/8 0008 13:16
 import copy
 from typing import Callable
 from funboost.publishers.base_publisher import AbstractPublisher
 from funboost.publishers.confluent_kafka_publisher import ConfluentKafkaPublisher
 from funboost.publishers.http_publisher import HTTPPublisher
-# from funboost.publishers.kombu_publisher import KombuPublisher
+from funboost.publishers.kombu_publisher import KombuPublisher
 from funboost.publishers.nats_publisher import NatsPublisher
 from funboost.publishers.peewee_publisher import PeeweePublisher
-from funboost.publishers.pulsar_publisher import PulsarPublisher
+# from funboost.publishers.pulsar_publisher import PulsarPublisher
 from funboost.publishers.redis_publisher_lpush import RedisPublisherLpush
 from funboost.publishers.redis_pubsub_publisher import RedisPubSubPublisher
 from funboost.publishers.tcp_publisher import TCPPublisher
 from funboost.publishers.txt_file_publisher import TxtFilePublisher
 from funboost.publishers.udp_publisher import UDPPublisher
 from funboost.publishers.zeromq_publisher import ZeroMqPublisher
 from funboost.publishers.kafka_publisher import KafkaPublisher
@@ -43,29 +43,28 @@
     8: KafkaPublisher,
     9: RedisPublisher,
     10: SqlachemyQueuePublisher,
     11: RocketmqPublisher,
     12: RedisStreamPublisher,
     13: ZeroMqPublisher,
     14: RedisPublisherLpush,
-    # 15: KombuPublisher,
+    15: KombuPublisher,
     16: ConfluentKafkaPublisher,
     17: MqttPublisher,
     18: HttpsqsPublisher,
-    20: PulsarPublisher,
+    # 20: PulsarPublisher,
     21: UDPPublisher,
     22: TCPPublisher,
     23: HTTPPublisher,
     24: NatsPublisher,
     25: TxtFilePublisher,
     26: PeeweePublisher,
     27: RedisPubSubPublisher,
 }
 
-
 def get_publisher(queue_name, *, log_level_int=10, logger_prefix='', is_add_file_handler=True,
                   clear_queue_within_init=False, is_add_publish_time=True, consuming_function: Callable = None,
                   broker_kind: int = None,
                   broker_exclusive_config: dict = None,
                   ) -> AbstractPublisher:
     """
     :param queue_name:
```

## funboost/publishers/base_publisher.py

```diff
@@ -13,17 +13,17 @@
 from functools import wraps
 from threading import Lock
 import datetime
 import amqpstorm
 from kombu.exceptions import KombuError
 from pikav1.exceptions import AMQPError as PikaAMQPError
 
-from nb_log import LoggerLevelSetterMixin, LogManager, LoggerMixin
+from nb_log import LoggerLevelSetterMixin, get_logger, LoggerMixin
 
-from funboost.publishers.msg_result_getter import AsyncResult, AioAsyncResult, HasNotAsyncResult,ResultFromMongo
+from funboost.publishers.msg_result_getter import AsyncResult, AioAsyncResult, HasNotAsyncResult, ResultFromMongo
 from funboost.utils import decorators, time_util
 from funboost import funboost_config_deafult
 
 RedisAsyncResult = AsyncResult  # 别名
 RedisAioAsyncResult = AioAsyncResult  # 别名
 
 
@@ -145,18 +145,18 @@
             logger_prefix += '--'
         # consuming_function_name = f'--{consuming_function.__name__}' if consuming_function else ''
         # logger_name = f'{logger_prefix}{self.__class__.__name__}--{queue_name}{consuming_function_name}'
         self._is_add_file_handler = is_add_file_handler
         self._logger_prefix = logger_prefix
         self._log_level_int = log_level_int
         logger_name = f'{logger_prefix}{self.__class__.__name__}--{queue_name}'
-        self.logger = LogManager(logger_name).get_logger_and_add_handlers(log_level_int,
-                                                                          log_filename=f'{logger_name}.log' if is_add_file_handler else None,
-                                                                          formatter_template=funboost_config_deafult.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER,
-                                                                          )  #
+        self.logger = get_logger(logger_name, log_level_int=log_level_int,
+                                 log_filename=f'{logger_name}.log' if is_add_file_handler else None,
+                                 formatter_template=funboost_config_deafult.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER,
+                                 )  #
         self.publish_params_checker = PublishParamsChecker(consuming_function) if consuming_function else None
         if broker_exclusive_config is None:
             broker_exclusive_config = {}
         # print(broker_exclusive_config)
         self.broker_exclusive_config = broker_exclusive_config
         # self.rabbit_client = RabbitMqFactory(is_use_rabbitpy=is_use_rabbitpy).get_rabbit_cleint()
         # self.channel = self.rabbit_client.creat_a_channel()
@@ -269,15 +269,18 @@
         self.close()
         self.logger.warning(f'with中自动关闭publisher连接，累计推送了 {self.publish_msg_num_total} 条消息 ')
 
     def _at_exit(self):
         self.logger.warning(
             f'程序关闭前，{round(time.time() - self.__init_time)} 秒内，累计推送了 {self.publish_msg_num_total} 条消息 到 {self._queue_name} 中')
 
+
 has_init_broker_lock = threading.Lock()
+
+
 def deco_mq_conn_error(f):
     @wraps(f)
     def _deco_mq_conn_error(self, *args, **kwargs):
         with has_init_broker_lock:
             if not self.has_init_broker:
                 self.logger.warning(f'对象的方法 【{f.__name__}】 首次使用 进行初始化执行 init_broker 方法')
                 self.init_broker()
```

## funboost/publishers/kombu_publisher.py

```diff
@@ -1,17 +1,19 @@
 # -*- coding: utf-8 -*-
 # @Author  : ydf
 # @Time    : 2021-04-15 0008 12:12
+import os
+
 import json
 
 # noinspection PyUnresolvedReferences
 from kombu.transport.virtual.base import Channel
 from kombu.entity import Exchange, Queue
 from kombu.connection import Connection
-from nb_log import LogManager
+from nb_log import get_logger
 
 from funboost.publishers.base_publisher import AbstractPublisher, deco_mq_conn_error
 from funboost import funboost_config_deafult
 
 # nb_log.get_logger(name=None,log_level_int=10)
 """
 https://www.cnblogs.com/shenh/p/10497244.html
@@ -40,29 +42,39 @@
 # noinspection PyAttributeOutsideInit
 class KombuPublisher(AbstractPublisher, ):
     """
     使用kombu作为中间件,这个能直接一次性支持很多种小众中间件，但性能很差，除非是分布式函数调度框架没实现的中间件种类用户才可以用这种，用户也可以自己对比性能。
     """
 
     def custom_init(self):
-        self._kombu_broker_url_prefix = funboost_config_deafult.KOMBU_URL.split(":")[0]
+        self.kombu_url = self.broker_exclusive_config['kombu_url'] or funboost_config_deafult.KOMBU_URL
+        self._kombu_broker_url_prefix = self.kombu_url.split(":")[0]
         logger_name = f'{self._logger_prefix}{self.__class__.__name__}--{self._kombu_broker_url_prefix}--{self._queue_name}'
-        self.logger = LogManager(logger_name).get_logger_and_add_handlers(self._log_level_int,
-                                                                          log_filename=f'{logger_name}.log' if self._is_add_file_handler else None,
-                                                                          formatter_template=funboost_config_deafult.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER,
-                                                                          )  #
+        self.logger = get_logger(logger_name, log_level_int=self._log_level_int,
+                                 log_filename=f'{logger_name}.log' if self._is_add_file_handler else None,
+                                 formatter_template=funboost_config_deafult.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER,
+                                 )  #
+        if self.kombu_url.startswith('filesystem://'):
+            self._create_msg_file_dir()
+
+    def _create_msg_file_dir(self):
+        os.makedirs(self.broker_exclusive_config['transport_options']['data_folder_in'], exist_ok=True)
+        os.makedirs(self.broker_exclusive_config['transport_options']['data_folder_out'], exist_ok=True)
+        processed_folder = self.broker_exclusive_config['transport_options'].get('processed_folder', None)
+        if processed_folder:
+            os.makedirs(processed_folder, exist_ok=True)
 
     def init_broker(self):
         self.exchange = Exchange('funboost_exchange', 'direct', durable=True)
         self.queue = Queue(self._queue_name, exchange=self.exchange, routing_key=self._queue_name, auto_delete=False)
-        self.conn = Connection(funboost_config_deafult.KOMBU_URL)
+        self.conn = Connection(self.kombu_url, transport_options=self.broker_exclusive_config['transport_options'])
         self.queue(self.conn).declare()
         self.producer = self.conn.Producer(serializer='json')
         self.channel = self.producer.channel  # type: Channel
-        self.channel.body_encoding = 'no_encode'
+        self.channel.body_encoding = 'no_encode'  # 这里改了编码，存到中间件的参数默认把消息base64了，我觉得没必要不方便查看消息明文。
         # self.channel = self.conn.channel()  # type: Channel
         # # self.channel.exchange_declare(exchange='distributed_framework_exchange', durable=True, type='direct')
         # self.queue = self.channel.queue_declare(queue=self._queue_name, durable=True)
         self.logger.warning(f'使用 kombu 库 连接 {self._kombu_broker_url_prefix} 中间件')
 
     @deco_mq_conn_error
     def concrete_realization_of_publish(self, msg):
```

## funboost/publishers/pulsar_publisher.py

```diff
@@ -1,10 +1,7 @@
-
-
-
 '''
 
 import pulsar
 
 client = pulsar.Client('pulsar://localhost:6650')
 
 producer = client.create_producer('my-topic36')
@@ -12,37 +9,42 @@
 for i in range(10):
     producer.send(('Hello-%d' % i).encode('utf-8'))
 
 client.close()
 
 '''
 
-
 # -*- coding: utf-8 -*-
 # @Author  : ydf
 # @Time    : 2022/8/8 0008 12:12
+import os
+
+from pulsar.schema import schema
+
 from funboost.publishers.base_publisher import AbstractPublisher
-from  funboost import funboost_config_deafult
+from funboost import funboost_config_deafult
 
 
 class PulsarPublisher(AbstractPublisher, ):
     """
     使用pulsar作为中间件
     """
+
     def custom_init(self):
         import pulsar
-        self._client = pulsar.Client(funboost_config_deafult.PULSAR_URL)
-        self._producer = self._client.create_producer(self._queue_name)
+        self._client = pulsar.Client(funboost_config_deafult.PULSAR_URL, )
+        self._producer = self._client.create_producer(self._queue_name, schema=schema.StringSchema(), producer_name=f'funboost_publisher_{os.getpid()}')
 
     def concrete_realization_of_publish(self, msg):
-        self._producer.send(msg.encode('utf-8'))
+        self._producer.send(msg)
 
     def clear(self):
+        """用户换个 subscription_name 就可以重新消费了，不需要清空消息"""
         pass
 
+
     def get_message_count(self):
-        # nb_print(self.redis_db7,self._queue_name)
         return -1
 
     def close(self):
         # self.redis_db7.connection_pool.disconnect()
         self._client.close()
```

## funboost/publishers/rabbitmq_amqpstorm_publisher.py

```diff
@@ -6,32 +6,33 @@
 from amqpstorm.queue import Queue as AmqpStormQueue
 from funboost import funboost_config_deafult
 from funboost.publishers.base_publisher import AbstractPublisher, deco_mq_conn_error
 
 
 class RabbitmqPublisherUsingAmqpStorm(AbstractPublisher):
     # 使用amqpstorm包实现的mq操作。
-    # 实例属性没在init里面写，造成补全很麻烦，写在这里做类属性，方便pycharm补全
+    # 实例属性没在__init__里面写，造成代码补全很麻烦，写在这里做类属性，方便pycharm补全
     connection = amqpstorm.UriConnection
     channel = amqpstorm.Channel
     channel_wrapper_by_ampqstormbaic = AmqpStormBasic
     queue = AmqpStormQueue
+    DURABLE = True
 
     # noinspection PyAttributeOutsideInit
     # @decorators.synchronized
     def init_broker(self):
         # username=app_config.RABBITMQ_USER, password=app_config.RABBITMQ_PASS, host=app_config.RABBITMQ_HOST, port=app_config.RABBITMQ_PORT, virtual_host=app_config.RABBITMQ_VIRTUAL_HOST, heartbeat=60 * 10
         self.logger.warning(f'使用AmqpStorm包 链接mq')
         self.connection = amqpstorm.UriConnection(
             f'amqp://{funboost_config_deafult.RABBITMQ_USER}:{funboost_config_deafult.RABBITMQ_PASS}@{funboost_config_deafult.RABBITMQ_HOST}:{funboost_config_deafult.RABBITMQ_PORT}/{funboost_config_deafult.RABBITMQ_VIRTUAL_HOST}?heartbeat={60 * 10}&timeout=20000'
         )
         self.channel = self.connection.channel()  # type:amqpstorm.Channel
         self.channel_wrapper_by_ampqstormbaic = AmqpStormBasic(self.channel)
         self.queue = AmqpStormQueue(self.channel)
-        self.queue.declare(queue=self._queue_name, durable=True)
+        self.queue.declare(queue=self._queue_name, durable=self.DURABLE)
 
     # @decorators.tomorrow_threads(10)
     @deco_mq_conn_error
     def concrete_realization_of_publish(self, msg):
         self.channel_wrapper_by_ampqstormbaic.publish(exchange='',
                                                       routing_key=self._queue_name,
                                                       body=msg,
```

## funboost/publishers/redis_publisher.py

```diff
@@ -38,15 +38,15 @@
         with self._lock_for_bulk_push:
             self.__bulk_push_and_init()
 
     def concrete_realization_of_publish(self, msg):
         # print(getattr(frame_config,'has_start_a_consumer_flag',0))
         # 这里的 has_start_a_consumer_flag 是一个标志，借用此模块设置的一个标识变量而已，框架运行时候自动设定的，不要把这个变量写到模块里面。
         # if getattr(funboost_config_deafult, 'has_start_a_consumer_flag', 0) == 0:  # 加快速度推送，否则每秒只能推送4000次。如果是独立脚本推送，使用批量推送，如果是消费者中发布任务，为了保持原子性，用原来的单个推送。
-        if self.broker_exclusive_config.get('redis_bulk_push') == 1:
+        if self.broker_exclusive_config['redis_bulk_push'] == 1:
             # self._temp_msg_queue.put(msg)
             with self._lock_for_bulk_push:
                 self._temp_msg_list.append(msg)
                 if len(self._temp_msg_list) >= 1000:
                     # print(len(self._temp_msg_list))
                     self.__bulk_push_and_init()
         else:
```

## funboost/publishers/redis_publisher_simple.py

```diff
@@ -1,10 +1,10 @@
 # -*- coding: utf-8 -*-
 # @Author  : ydf
-# @Time    : 2022/8/8 0008 12:12
+# @Time    : 2023/8/8 0008 12:12
 from funboost.publishers.base_publisher import AbstractPublisher
 from funboost.utils import RedisMixin
 
 
 class RedisPublisher(AbstractPublisher, RedisMixin):
     """
     使用redis作为中间件
```

## Comparing `funboost-20.3.dist-info/LICENSE` & `funboost-20.4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `funboost-20.3.dist-info/METADATA` & `funboost-20.4.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: funboost
-Version: 20.3
+Version: 20.4
 Summary: pip install funboost，python全功能分布式函数调度框架,。支持python所有类型的并发模式和一切知名消息队列中间件，python函数加速器，框架包罗万象，一统编程思维，兼容50% python业务场景，适用范围广。只需要一行代码即可分布式执行python一切函数，99%用过funboost的pythoner 感受是 方便 快速 强大，相见恨晚 
 Home-page: https://github.com/ydf0509/funboost
 Author: bfzs
 Author-email: ydf0509@sohu.com
 Maintainer: ydf
 Maintainer-email: ydf0509@sohu.com
 License: BSD License
@@ -61,14 +61,15 @@
 Requires-Dist: nats-python
 Requires-Dist: nb-filelock
 Requires-Dist: aiohttp (==3.8.3)
 Requires-Dist: pysnooper
 Requires-Dist: deprecated
 Requires-Dist: cryptography
 Requires-Dist: auto-run-on-remote
+Requires-Dist: frozenlist
 
 
 # 1.分布式函数调度框架简介
 
 <pre style="color: greenyellow;background-color: #0c1119; font-size: medium;">
 pip install funboost ,python全功能分布式函数调度框架,。 支持python所有类型的并发模式和全球一切知名消息队列中间件，
 python函数加速器，框架包罗万象，一统编程思维，兼容50% python编程业务场景，适用范围广。
```

## Comparing `funboost-20.3.dist-info/RECORD` & `funboost-20.4.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-funboost/__init__.py,sha256=6PW6OrqaKbV2YF05ZiS6Q2mA1S6_jAz-y6Ft6kA2XEk,20766
-funboost/constant.py,sha256=rC81k-DiWEquS-4eoUDgQEoTbpavPFuk3jJ3D80dyE8,5627
-funboost/funboost_config_deafult.py,sha256=q4B_Oc1Rt2rabtvWtoQUPFzuE2Py-6gCgBoOI3Ac2pk,6660
-funboost/helpers.py,sha256=4v_pRYvrVhYTqUO_PVtT22Q0iHU4E1cnlndKMhBMtDk,14104
-funboost/set_frame_config.py,sha256=NHq3KSM9YvH5Qkn1eJGFrEzXYod3ZW0YBY20nfqaSM8,9134
-funboost/assist/user_custom_broker_register.py,sha256=QeMsojHe_s8AjHCFP7jFZfwIJ3qkD45TkxRg2ThLiAc,2858
+funboost/__init__.py,sha256=bA6IaAysO2we8gqOy3JDVrM__-3Px7VQTLYORx5dQQY,21053
+funboost/constant.py,sha256=1PtxXLXFg7LsHMePU2iZeL2XOF4JUXnanI6kDFeh-JU,5910
+funboost/funboost_config_deafult.py,sha256=hQD7MZtJFQykqqJIULmqNJBwHSBEXGcCs_2LX2oDTdc,7100
+funboost/helpers.py,sha256=KApnbT-OXtgKKlY-MGjTnsP7YxBtDn3k3LL_XOn4TGU,14104
+funboost/set_frame_config.py,sha256=hz_38C-IXEulYpHQdr1fhsMcdEDCHIsF2la8MkHiIjA,9149
+funboost/assist/user_custom_broker_register.py,sha256=kgtwpaazLOTugsyrx_Q114FW1y_hdQpuHY1QYVJ4bV0,4734
 funboost/beggar_version_implementation/beggar_redis_consumer.py,sha256=aiucCkj7-GWbLMIWHhevdQrAsxzyc55AL69fue8esYs,3930
 funboost/concurrent_pool/__init__.py,sha256=dGgxgzMSwcXWMexwAnojsML7EMjHAAsmAofNgrxtl2w,759
 funboost/concurrent_pool/async_helper.py,sha256=iyb0Jcjyx-vkUGC_saSUWqN657kcR5K7B-L_SB6cDCE,3256
 funboost/concurrent_pool/async_pool_executor.py,sha256=zCymNAFuPrV5CuW9hXCyzQ8nLCY73ixvvDsWFPNvt90,7227
 funboost/concurrent_pool/bounded_processpoolexcutor_gt_py37.py,sha256=y6tL41X4sC_d5E2k2sNz0JZUJU2hyJDyMcOi2RzkI_w,4723
 funboost/concurrent_pool/bounded_processpoolexcutor_py36.py,sha256=fwhCvXCRILshQbGVv5Y9kFqCZsX0VMKTUdLhI9dLDbg,3011
 funboost/concurrent_pool/bounded_threadpoolexcutor.py,sha256=T1mJA1yxUYAkoDjrJMxCPPxSF3bUH4_5AFpYx3PWjfQ,1571
@@ -18,53 +18,55 @@
 funboost/concurrent_pool/custom_threadpool_executor000.py,sha256=jJLXy3h-bELap6nZA6yLtdozzTWcvCtZ7IY6MTqLEAM,9317
 funboost/concurrent_pool/single_thread_executor.py,sha256=NDWOegh8Nxpb-Bp-lUlj-DONWvepSmA9qepL1yNgdQI,373
 funboost/concurrent_pool/backup/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 funboost/concurrent_pool/backup/async_pool_executor0223.py,sha256=iTxxJFk2lu1P9ZAIkBip3euq3oEQ4_qTODy3xUaOecY,9548
 funboost/concurrent_pool/backup/async_pool_executor_back.py,sha256=vIgUUyF4Zb0jIRPWgNPqyO09YEkQP32kkpGBldqm4qA,9568
 funboost/concurrent_pool/backup/async_pool_executor_janus.py,sha256=OHMWJ9l3EYTpPpcrPrGGKd4K0tmQ2PN8HiX0Dta0EOo,5728
 funboost/consumers/__init__.py,sha256=ZXY_6Kut1VYNQiF5aWEgIWobsW1ht9YUP0TdRZRWFqI,126
-funboost/consumers/base_consumer.py,sha256=QCN3eu2UUqENsIeAS1jCCjjy4dfux6TkIIjqW0wW5hA,93969
+funboost/consumers/base_consumer.py,sha256=QBm7yYPmKlcSra-HHo3oBUjJvwv35eFhB3vchP6SCTc,94018
+funboost/consumers/celery_consumer.py,sha256=8SF8ppHIMH-BIAHO0NyJYnSQxe_PcT6hv05e7DySG54,4574
 funboost/consumers/confirm_mixin.py,sha256=H0w07PceU2gGf6X1EXvAB5oD7IavzGv96bQTxm-58sE,5877
 funboost/consumers/http_consumer.py,sha256=n45vdw3u7ta6f-AxSQKJfoMoSu4eV5C0NUOQaDAafQ8,2045
 funboost/consumers/http_consumer000.py,sha256=NXOSiN1qpLAJfJkuF6SjFpWQ28YxMDULzWCBTNMwYe8,4463
 funboost/consumers/httpsqs_consumer.py,sha256=wfK_7QLxLDnBw3HE8KChPiwR6bzogIHyTQkiRLJYuJQ,1058
-funboost/consumers/kafka_consumer.py,sha256=8WfrCG_HHuStd7_QJdCUkkXb-CSEEJUFBSG0VvWnffw,4295
-funboost/consumers/kafka_consumer_manually_commit.py,sha256=93E9dWNQcfSy8mHsC2PHmfc-LMzy-9K1rBFesOCZ2xE,6586
-funboost/consumers/kombu_consumer.py,sha256=V_-GYyBKPOX1pGQzH745D6V2qUwu3S1ElnjFLzUzAZc,5082
+funboost/consumers/kafka_consumer.py,sha256=5dcnWrJH3fpWSeUB54Um_xspNUw7ytrVbW8Bf34rSPs,4196
+funboost/consumers/kafka_consumer_manually_commit.py,sha256=Glox-UMWqPoJGtT-J_fOpv1yPbEAH7_BV9CKQFwAfbE,6536
+funboost/consumers/kombu_consumer.py,sha256=VYxmaQ54q3FVBD3uZ1JGQUOEDQ1YGE-Sbx2o_5JD8Yo,10168
 funboost/consumers/local_python_queue_consumer.py,sha256=bTekCaBY8B65WH-nV-3NJDcRxLSJkQafatErj7-MUVo,1272
 funboost/consumers/mongomq_consumer.py,sha256=J7Z4UX7peztVeyM33Pi0BnDtxmBB-u-HDo-obd7vTuc,1069
 funboost/consumers/mqtt_consumer.py,sha256=8GSlCAQIlByfelK6BHnIzFsXb50sgIwCiAbHbGl324c,2208
+funboost/consumers/nameko_consumer.py,sha256=LLixKkfNKUFLRE511JrxVNwbQgzBYn7va1llnNIkugg,2154
 funboost/consumers/nats_consumer.py,sha256=yv0XJWE1q296UwpwFaXK66dpRHzqbziha1_ophs0Rvc,1054
 funboost/consumers/nsq_consumer.py,sha256=fErxzlM1X-X4crkddkm98UssY9eop8O61-y-4Z8DYmA,1440
 funboost/consumers/peewee_conusmer.py,sha256=6eHZ0mttcVoyRWODD-l8nfgMF5E5KAMTxKrStknGTWY,1218
 funboost/consumers/persist_queue_consumer.py,sha256=J4OThFO2yvNMh3bFxkE1Ff7OFo-PaHbjLfoSi239a84,982
-funboost/consumers/pulsar_consumer.py,sha256=vNIRpjwFjD0bFV_uTztIboNPJZ2xZQwLQgrKY2ftAto,1791
-funboost/consumers/rabbitmq_amqpstorm_consumer.py,sha256=QWb2s8ZIpzw6lVUVBs4IFPEMCUuaXjUyoJAgXuhukfU,1698
+funboost/consumers/pulsar_consumer.py,sha256=vKhUhiGO3YODuti6bspeDR52R6vy1YyV4asStT3fE78,2394
+funboost/consumers/rabbitmq_amqpstorm_consumer.py,sha256=dw2bv7HloJ2ABWV6-HQxUSbrFkJfaxdeRVXT2l5yad4,1700
 funboost/consumers/rabbitmq_pika_consumer.py,sha256=yYb9QuZeR4RBYhvQcO8sp3D1Gdc8VBHw0wJhA70XHhk,5412
 funboost/consumers/rabbitmq_pika_consumerv0.py,sha256=i9BcTqyapMlQypWjvwb8D4m6hZXFzpbAGLVPDWvXd7s,4653
 funboost/consumers/rabbitmq_rabbitpy_consumer.py,sha256=I0GK7ur2qwJbWajdTfqo67WkLfgR0C72OxwNPjiinhs,1239
 funboost/consumers/redis_brpoplpush_consumer.py,sha256=VDKTVFhOGtqb7RJuW-5m_Aany__T7W0O0JaIUHfvmAc,3011
-funboost/consumers/redis_consumer.py,sha256=cZADAHlxJ-Hx7AkHY10UzrVeoSAi-4Gs2anqxiLn_l0,2762
+funboost/consumers/redis_consumer.py,sha256=kz1rQt5yMHWcq3VMxpPL-bRRnOYjOgUFODvb8FNG86Y,2808
 funboost/consumers/redis_consumer_ack_able.py,sha256=DBKh2Ejp1mY19GdmSvtpJ4lEhRPFv2bUl5hXfGj5vbM,7560
-funboost/consumers/redis_consumer_simple.py,sha256=fIkdKBQ26jEPpQYqJcUnvYcf8Lqo18rmUqR6fkGZdLc,899
+funboost/consumers/redis_consumer_simple.py,sha256=VheSdKUdsBfs5wMu89nTGrMzK2c29koFDvjQhm8TS_M,899
 funboost/consumers/redis_filter.py,sha256=TVyT2i9JhmhsJFyQZDx98phTiwBccNTl9fcErEDGXTM,7135
 funboost/consumers/redis_pubsub_consumer.py,sha256=dEMx5SEAAjW5mwtPnzoSEV5P6pV-ADZ_w3s6YxGHl08,1184
 funboost/consumers/redis_stream_consumer.py,sha256=0r-x_ac6Y6UjIlJc9qcKFIWwu9OOiJLQ4LFjfed6u_8,6304
 funboost/consumers/rocketmq_consumer.py,sha256=Re8O6qlx2cd6K82MqUJhBqpzS7YxPURQ6Oip7BvHLMM,1633
 funboost/consumers/sqlachemy_consumer.py,sha256=TV_BbV1PoOzBZAnL5_MB3BENAC7SA6pVgJlIkNvyjpU,1289
 funboost/consumers/tcp_consumer.py,sha256=KgkhctYIAu15KLuHUKffx7vDzofWH98AU5K78E-6aU8,2025
 funboost/consumers/txt_file_consumer.py,sha256=gQe8WxuniETq0geLV9vjzg-mBLV-y2GLNhBEBIGZgE0,1322
 funboost/consumers/udp_consumer.py,sha256=wDfUk9_RFCTjyx5gLbUTwv_LEfV5-POQQ_sGaWjlpjE,1625
 funboost/consumers/zeromq_consumer.py,sha256=TKcU1wOeKW6URfT5UOVEDRjmUCjvNzkgbBVJDLiD2t0,4137
 funboost/contrib/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 funboost/contrib/queue2queue.py,sha256=zSIOaj9dPjskV0Rzk-T6gLeO0X-vCZb1pQ1YvCCafOM,4703
 funboost/contrib/redis_consume_latest_msg_broker.py,sha256=V-8-pOyotOXNbs2olS7vig-yN1PxRdw_MeLOtpUufJc,1817
 funboost/factories/__init__.py,sha256=s7kKKjR1HU5eMjPD6r5b-SXTVMo1zBp2JjOAtkyt5Yo,178
-funboost/factories/consumer_factory.py,sha256=UY063zP7GQB4kYxG1WDbn8jINy3vNSiU9SJ0ZZFaagQ,3218
-funboost/factories/publisher_factotry.py,sha256=69DTpJLKVUpJ7E3l5WGFZsq7FuQEUK0DoVe1HZIiOtM,4589
+funboost/factories/consumer_factory.py,sha256=d7tiN6QVPD1mduCDL4MibLf_ZBmo6DUd3O5VldLlqy8,3357
+funboost/factories/publisher_factotry.py,sha256=kZBoB8lQhd-5kVLfC3-f0HC_E6Jq2ldYVMpOjzfKNrE,4587
 funboost/function_result_web/app.py,sha256=xUSDBwwDA5wQVWFdFBXj9Y1s7BOh2itUw5pCZl0URMw,4841
 funboost/function_result_web/functions.py,sha256=OIPMxc4jv51qnhBxFGfTZnpMx5p4lQflPoTviDTbJUc,7345
 funboost/function_result_web/__pycache__/app.cpython-37.pyc,sha256=p-jwU7xf31KOJhmhNXqj6J79PTxjMbiTU16gAotpSEw,4045
 funboost/function_result_web/__pycache__/functions.cpython-37.pyc,sha256=KuU8DnYhFpYN0p9rdDXE9mqFuE7eKkcXHCNze3aAdOw,3921
 funboost/function_result_web/static/assets/css/custom.css,sha256=3brvjy2aBOTIXcTUK4NV6dX5wFRqx6K2aLu_jQn63jM,7674
 funboost/function_result_web/static/assets/css/jquery.mCustomScrollbar.min.css,sha256=JHGEmB629pipTkMag9aMaw32I8zle24p3FpsEeI6oZU,42839
 funboost/function_result_web/static/assets/img/user.jpg,sha256=Vz1A99gho-0bKV67Pt2s_zT25mWhNcPe0mWG-0mRl9U,23610
@@ -75,35 +77,37 @@
 funboost/function_result_web/static/images/password.png,sha256=0jRivuQAhWKtkS73p8f_KiLy3D39_flqVTrpFKJPNqk,546
 funboost/function_result_web/static/images/tick.png,sha256=S9dZYN4HQzw7JsWPw3ut1dQp4OTJ_Uh2Qp2KUDF1Jv8,2912
 funboost/function_result_web/static/images/user.png,sha256=HxLjNc83WZzZEscZRdmVhGKlPXNdp_EKmmYxafuyb3g,622
 funboost/function_result_web/static/js/jquery-1.11.0.min.js,sha256=ryQZ3RXgnqkTz-lNEw-YcEhnMuV3ZODwLqOEbyBBRu4,96383
 funboost/function_result_web/templates/index.html,sha256=dWe-JFQhsDpoNjSsBF4P6SJWp_KvHX8EP_yECS5r7_o,19501
 funboost/function_result_web/templates/login.html,sha256=q37dj7O0LeyiV38Zd5P1Qn_qmhjdFomuYTRY1Yk48Bo,2007
 funboost/publishers/__init__.py,sha256=xqBHlvsJQVPfbdvP84G0LHmVB7-pFBS7vDnX1Uo9pVY,131
-funboost/publishers/base_publisher.py,sha256=fbQ5g2vVAy0nLN2jWTCcOUSL9THL7yjAwu-ID0sK4VM,15024
+funboost/publishers/base_publisher.py,sha256=davLWo-tSw7gwqF4fMrxlcz-sitZ9kqpfofb0yjp_ok,14894
+funboost/publishers/celery_publisher.py,sha256=ag2s7MzPPrnNdza3u8vcbDJqtiqbQw4lJJzAVuJ6GF0,3897
 funboost/publishers/confluent_kafka_publisher.py,sha256=cpbyWvZ0T_kM62LWeBKRUuEuMkJAKOof97UUMSz6-Dk,3541
 funboost/publishers/http_publisher.py,sha256=QbVG-dFdKdltCoElHmKpNSMsjpZY3Ibp-r_IzqrkPMk,777
 funboost/publishers/httpsqs_publisher.py,sha256=7cf5ijwrbp4smq6ofndrKisruAqG0Wzfo_d_7bnLUk4,2783
 funboost/publishers/kafka_publisher.py,sha256=cmlJ0mvwq0Ajlth4VQqwnoe6v_bZ4eIz49GgkiJr-ZU,2160
-funboost/publishers/kombu_publisher.py,sha256=ChX3qVE7Kvdu9XVFCKezV2KAwUqY7EhpvMS8nFelsY8,4567
+funboost/publishers/kombu_publisher.py,sha256=1tsYCngzx0PR9a4cF2vzvzW3S2wUYObKhfvaqOqDNNo,5246
 funboost/publishers/local_python_queue_publisher.py,sha256=veskMS5tjeneYU9HmrJLXZSK9_UT48NzHzcljjOoy3g,1365
 funboost/publishers/mongomq_publisher.py,sha256=xQr3KMQEKksX4OEvzPlCl8v1VeBHaoZtYw2QujOUyGo,1874
 funboost/publishers/mqtt_publisher.py,sha256=NKVDE5R12QL99IXgRjJtF4phyW8QaXKxHkqW5p_kXr4,3050
 funboost/publishers/msg_result_getter.py,sha256=a2ffSE8Rvz1t1KVEt4UxIPsWgcriaHE_Armkac-JrJY,7782
+funboost/publishers/nameko_publisher.py,sha256=HtR8I_NemyJCO2KL-w8geNMhZcoj06_95QZ8qq1-gog,2147
 funboost/publishers/nats_publisher.py,sha256=hFfaQovij9dm8w-iRN0SgiHHoS_TlrTAjw42dPwCLSA,776
 funboost/publishers/nsq_publisher.py,sha256=Go4UjLd_Vt4JuVtfkmCuuXrmxUXv1y6NaBQJX6s1XUo,1302
 funboost/publishers/peewee_publisher.py,sha256=RsYAqBKf_ZLxkGJeZPWExzG4cpUac7weCeNhcSQ9hZc,1095
 funboost/publishers/persist_queue_publisher.py,sha256=x6qRiR3Ln-jX9KPC5GvBzUzAlmZ0HDjU1KTnILXVJrw,2540
-funboost/publishers/pulsar_publisher.py,sha256=EIQnDVcwMc3NnuiiUiu2IRP6G1NUwWs6s14Qo2k40Z4,1085
-funboost/publishers/rabbitmq_amqpstorm_publisher.py,sha256=VuCy9zM_N_jX23ec8P35E6Zr8oE84AK1KhPyKCJN6o4,2687
+funboost/publishers/pulsar_publisher.py,sha256=3BqDtywExvTIw1KZWG4kT1uz029uw2YkntLggZ-Ao6A,1238
+funboost/publishers/rabbitmq_amqpstorm_publisher.py,sha256=0o6D7xD8wDalj-FEWfqkZBr_HjyUKRf_CsGOq6_8ygA,2725
 funboost/publishers/rabbitmq_pika_publisher.py,sha256=jZZw3DUiZ4VqJ6FqZGdv7qo3F_ltzHuKsy_5-j4jkCs,2343
 funboost/publishers/rabbitmq_rabbitpy_publisher.py,sha256=GGXPKxE6-mAjqMIKqwvR9d7L-zuJQcQoU9uRsQLNGas,1953
-funboost/publishers/redis_publisher.py,sha256=xxc9n77dwp-br7onSmDDmeryZkk6EduVA9Yw7A0KrWA,3933
+funboost/publishers/redis_publisher.py,sha256=AHGSgtlYHVYIVu48lSa5UqdiIU5VtFp7hXhj-wiQx8c,3929
 funboost/publishers/redis_publisher_lpush.py,sha256=xEWuCTtbDcKFLTxGrECrbIVapFfUwqX2-GHenMClu-Q,278
-funboost/publishers/redis_publisher_simple.py,sha256=cUizDVfNY3DB1G9CfXBNxywDBek1k5KPSbK0aMqftYE,872
+funboost/publishers/redis_publisher_simple.py,sha256=hLVWiDjy9ObGTmv7Vtrz21d18Fxkb52IfO5ZzaXjzMQ,872
 funboost/publishers/redis_pubsub_publisher.py,sha256=_6s7sbcGOSXxN2ZkBSDk9ILskmbj9cZTQyYHLQTYOuI,721
 funboost/publishers/redis_stream_publisher.py,sha256=DLxFcTlze0IdYFoaRmTcY8GCOaRwbj4aBNbylkt9gRA,2037
 funboost/publishers/rocketmq_publisher.py,sha256=vY82WgutDPsS9px6rukU1d3AexmsT_tqSS2dmX-Pw-c,2343
 funboost/publishers/sqla_queue_publisher.py,sha256=yUbge08K311-jWlFyOUw6g7-Z-flbxEeWCeCTGnJcic,1215
 funboost/publishers/tcp_publisher.py,sha256=e-QoZVpnnjy536fzj43tW_1TtqFb7m_plsoR1yPaHMs,1359
 funboost/publishers/txt_file_publisher.py,sha256=twTrqRAYnaNmFkXn0nr1xGBjeHCPJStt83voLX3vPao,1380
 funboost/publishers/udp_publisher.py,sha256=0EAwT7IY_02v9YlvDCs53ubDUP8WvWjYYtURzC-DN64,1218
@@ -201,12 +205,12 @@
 funboost/utils/dependency_packages_in_pythonpath/func_timeout/__pycache__/py3_raise.cpython-37.pyc,sha256=67Zqz4tjErzQSm9FM9mGaY3uMHYOUj3QYKtPqJQvQpE,303
 funboost/utils/dependency_packages_in_pythonpath/func_timeout/__pycache__/py3_raise.cpython-39.pyc,sha256=a1ajayGg3JjQz--IC3-6YQHRFStG9etoieY8mXEdJ6Q,311
 funboost/utils/pysnooper_ydf/__init__.py,sha256=ctbQdJpLVZ5g_PPstj7Xaqcl0sMIgvUGwZXtcogYyHA,909
 funboost/utils/pysnooper_ydf/pycompat.py,sha256=ehsCfjsLdwoK0_o5fwYWDo3WeqCVfHW5lxekrEZxq4Y,2243
 funboost/utils/pysnooper_ydf/tracer.py,sha256=DYxYeRFSH1jXy4OTB5KIAgQm2EHRWEOwq3EXJig7Yrk,19131
 funboost/utils/pysnooper_ydf/utils.py,sha256=evSmGi_Oul7vSP47AJ0DLjFwoCYCfunJZ1mWxAkwPZw,2753
 funboost/utils/pysnooper_ydf/variables.py,sha256=QejRDESBA06KG9OH4sBT4J1M55eaU29EIHg8K_igaXo,3693
-funboost-20.3.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
-funboost-20.3.dist-info/METADATA,sha256=zUPwI704wi_UBD75ZGsGFSjwQhaykX1ojPnajjBOCfQ,24416
-funboost-20.3.dist-info/WHEEL,sha256=D1Wh14kWDxPnrM-5t_6UCB-UuQNrEODtRa3vF4OsvQY,97
-funboost-20.3.dist-info/top_level.txt,sha256=K8WuKnS6MRcEWxP1NvbmCeujJq6TEfbsB150YROlRw0,9
-funboost-20.3.dist-info/RECORD,,
+funboost-20.4.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
+funboost-20.4.dist-info/METADATA,sha256=3shGFzjFDKlgfa8Ky0AVdXtWE0EDIDXHz5JBmHpPHuc,24442
+funboost-20.4.dist-info/WHEEL,sha256=D1Wh14kWDxPnrM-5t_6UCB-UuQNrEODtRa3vF4OsvQY,97
+funboost-20.4.dist-info/top_level.txt,sha256=K8WuKnS6MRcEWxP1NvbmCeujJq6TEfbsB150YROlRw0,9
+funboost-20.4.dist-info/RECORD,,
```

