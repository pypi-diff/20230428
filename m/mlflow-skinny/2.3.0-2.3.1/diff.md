# Comparing `tmp/mlflow_skinny-2.3.0-py3-none-any.whl.zip` & `tmp/mlflow_skinny-2.3.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,354 +1,354 @@
-Zip file size: 4070911 bytes, number of entries: 352
--rw-r--r--  2.0 unx     6155 b- defN 23-Apr-18 23:19 mlflow/__init__.py
--rw-r--r--  2.0 unx       39 b- defN 23-Apr-18 23:19 mlflow/__main__.py
--rw-r--r--  2.0 unx     3668 b- defN 23-Apr-18 23:19 mlflow/_doctor.py
--rw-r--r--  2.0 unx     9428 b- defN 23-Apr-18 23:19 mlflow/_spark_autologging.py
--rw-r--r--  2.0 unx    15140 b- defN 23-Apr-18 23:19 mlflow/catboost.py
--rw-r--r--  2.0 unx    23356 b- defN 23-Apr-18 23:19 mlflow/cli.py
--rw-r--r--  2.0 unx      407 b- defN 23-Apr-18 23:19 mlflow/client.py
--rw-r--r--  2.0 unx      881 b- defN 23-Apr-18 23:19 mlflow/db.py
--rw-r--r--  2.0 unx    28178 b- defN 23-Apr-18 23:19 mlflow/diviner.py
--rw-r--r--  2.0 unx    10080 b- defN 23-Apr-18 23:19 mlflow/environment_variables.py
--rw-r--r--  2.0 unx     4881 b- defN 23-Apr-18 23:19 mlflow/exceptions.py
--rw-r--r--  2.0 unx     5080 b- defN 23-Apr-18 23:19 mlflow/experiments.py
--rw-r--r--  2.0 unx    14185 b- defN 23-Apr-18 23:19 mlflow/h2o.py
--rw-r--r--  2.0 unx      311 b- defN 23-Apr-18 23:19 mlflow/keras.py
--rw-r--r--  2.0 unx    35698 b- defN 23-Apr-18 23:19 mlflow/lightgbm.py
--rw-r--r--  2.0 unx      180 b- defN 23-Apr-18 23:19 mlflow/llm.py
--rw-r--r--  2.0 unx     5474 b- defN 23-Apr-18 23:19 mlflow/ml_package_versions.py
--rw-r--r--  2.0 unx    13885 b- defN 23-Apr-18 23:19 mlflow/mleap.py
--rw-r--r--  2.0 unx    21826 b- defN 23-Apr-18 23:19 mlflow/onnx.py
--rw-r--r--  2.0 unx    17616 b- defN 23-Apr-18 23:19 mlflow/pmdarima.py
--rw-r--r--  2.0 unx    14024 b- defN 23-Apr-18 23:19 mlflow/prophet.py
--rw-r--r--  2.0 unx  7197781 b- defN 23-Apr-18 23:19 mlflow/pypi_package_index.json
--rw-r--r--  2.0 unx     2519 b- defN 23-Apr-18 23:19 mlflow/runs.py
--rw-r--r--  2.0 unx    26647 b- defN 23-Apr-18 23:19 mlflow/shap.py
--rw-r--r--  2.0 unx    14259 b- defN 23-Apr-18 23:19 mlflow/spacy.py
--rw-r--r--  2.0 unx    44813 b- defN 23-Apr-18 23:19 mlflow/spark.py
--rw-r--r--  2.0 unx    24596 b- defN 23-Apr-18 23:19 mlflow/statsmodels.py
--rw-r--r--  2.0 unx    84167 b- defN 23-Apr-18 23:19 mlflow/transformers.py
--rw-r--r--  2.0 unx      147 b- defN 23-Apr-18 23:19 mlflow/version.py
--rw-r--r--  2.0 unx     6350 b- defN 23-Apr-18 23:19 mlflow/artifacts/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/azure/__init__.py
--rw-r--r--  2.0 unx    11647 b- defN 23-Apr-18 23:19 mlflow/azure/client.py
--rw-r--r--  2.0 unx     3797 b- defN 23-Apr-18 23:19 mlflow/deployments/__init__.py
--rw-r--r--  2.0 unx    15572 b- defN 23-Apr-18 23:19 mlflow/deployments/base.py
--rw-r--r--  2.0 unx    15078 b- defN 23-Apr-18 23:19 mlflow/deployments/cli.py
--rw-r--r--  2.0 unx     3825 b- defN 23-Apr-18 23:19 mlflow/deployments/interface.py
--rw-r--r--  2.0 unx     5512 b- defN 23-Apr-18 23:19 mlflow/deployments/plugin_manager.py
--rw-r--r--  2.0 unx      556 b- defN 23-Apr-18 23:19 mlflow/deployments/utils.py
--rw-r--r--  2.0 unx      948 b- defN 23-Apr-18 23:19 mlflow/entities/__init__.py
--rw-r--r--  2.0 unx     1414 b- defN 23-Apr-18 23:19 mlflow/entities/_mlflow_object.py
--rw-r--r--  2.0 unx     3510 b- defN 23-Apr-18 23:19 mlflow/entities/experiment.py
--rw-r--r--  2.0 unx      887 b- defN 23-Apr-18 23:19 mlflow/entities/experiment_tag.py
--rw-r--r--  2.0 unx     1215 b- defN 23-Apr-18 23:19 mlflow/entities/file_info.py
--rw-r--r--  2.0 unx     1242 b- defN 23-Apr-18 23:19 mlflow/entities/lifecycle_stage.py
--rw-r--r--  2.0 unx     1418 b- defN 23-Apr-18 23:19 mlflow/entities/metric.py
--rw-r--r--  2.0 unx     1133 b- defN 23-Apr-18 23:19 mlflow/entities/param.py
--rw-r--r--  2.0 unx     1438 b- defN 23-Apr-18 23:19 mlflow/entities/run.py
--rw-r--r--  2.0 unx     3032 b- defN 23-Apr-18 23:19 mlflow/entities/run_data.py
--rw-r--r--  2.0 unx     6182 b- defN 23-Apr-18 23:19 mlflow/entities/run_info.py
--rw-r--r--  2.0 unx     1550 b- defN 23-Apr-18 23:19 mlflow/entities/run_status.py
--rw-r--r--  2.0 unx      890 b- defN 23-Apr-18 23:19 mlflow/entities/run_tag.py
--rw-r--r--  2.0 unx     1212 b- defN 23-Apr-18 23:19 mlflow/entities/source_type.py
--rw-r--r--  2.0 unx     1826 b- defN 23-Apr-18 23:19 mlflow/entities/view_type.py
--rw-r--r--  2.0 unx      529 b- defN 23-Apr-18 23:19 mlflow/entities/model_registry/__init__.py
--rw-r--r--  2.0 unx      286 b- defN 23-Apr-18 23:19 mlflow/entities/model_registry/_model_registry_entity.py
--rw-r--r--  2.0 unx     6435 b- defN 23-Apr-18 23:19 mlflow/entities/model_registry/model_version.py
--rw-r--r--  2.0 unx      831 b- defN 23-Apr-18 23:19 mlflow/entities/model_registry/model_version_stages.py
--rw-r--r--  2.0 unx     1533 b- defN 23-Apr-18 23:19 mlflow/entities/model_registry/model_version_status.py
--rw-r--r--  2.0 unx      933 b- defN 23-Apr-18 23:19 mlflow/entities/model_registry/model_version_tag.py
--rw-r--r--  2.0 unx     4933 b- defN 23-Apr-18 23:19 mlflow/entities/model_registry/registered_model.py
--rw-r--r--  2.0 unx     1053 b- defN 23-Apr-18 23:19 mlflow/entities/model_registry/registered_model_alias.py
--rw-r--r--  2.0 unx      948 b- defN 23-Apr-18 23:19 mlflow/entities/model_registry/registered_model_tag.py
--rw-r--r--  2.0 unx    25354 b- defN 23-Apr-18 23:19 mlflow/fastai/__init__.py
--rw-r--r--  2.0 unx     5757 b- defN 23-Apr-18 23:19 mlflow/fastai/callback.py
--rw-r--r--  2.0 unx    19063 b- defN 23-Apr-18 23:19 mlflow/gluon/__init__.py
--rw-r--r--  2.0 unx     2020 b- defN 23-Apr-18 23:19 mlflow/gluon/_autolog.py
--rw-r--r--  2.0 unx    16643 b- defN 23-Apr-18 23:19 mlflow/langchain/__init__.py
--rw-r--r--  2.0 unx     4781 b- defN 23-Apr-18 23:19 mlflow/langchain/api_request_parallel_processor.py
--rw-r--r--  2.0 unx     3326 b- defN 23-Apr-18 23:19 mlflow/models/__init__.py
--rw-r--r--  2.0 unx     9803 b- defN 23-Apr-18 23:19 mlflow/models/cli.py
--rw-r--r--  2.0 unx     9853 b- defN 23-Apr-18 23:19 mlflow/models/docker_utils.py
--rw-r--r--  2.0 unx     3420 b- defN 23-Apr-18 23:19 mlflow/models/flavor_backend.py
--rw-r--r--  2.0 unx     2354 b- defN 23-Apr-18 23:19 mlflow/models/flavor_backend_registry.py
--rw-r--r--  2.0 unx    23802 b- defN 23-Apr-18 23:19 mlflow/models/model.py
--rw-r--r--  2.0 unx     8634 b- defN 23-Apr-18 23:19 mlflow/models/signature.py
--rw-r--r--  2.0 unx    36823 b- defN 23-Apr-18 23:19 mlflow/models/utils.py
--rw-r--r--  2.0 unx    11707 b- defN 23-Apr-18 23:19 mlflow/models/wheeled_model.py
--rw-r--r--  2.0 unx     9383 b- defN 23-Apr-18 23:19 mlflow/models/container/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/models/container/scoring_server/__init__.py
--rw-r--r--  2.0 unx      131 b- defN 23-Apr-18 23:19 mlflow/models/container/scoring_server/wsgi.py
--rw-r--r--  2.0 unx      491 b- defN 23-Apr-18 23:19 mlflow/models/evaluation/__init__.py
--rw-r--r--  2.0 unx     3105 b- defN 23-Apr-18 23:19 mlflow/models/evaluation/_shap_patch.py
--rw-r--r--  2.0 unx     6769 b- defN 23-Apr-18 23:19 mlflow/models/evaluation/artifacts.py
--rw-r--r--  2.0 unx    59205 b- defN 23-Apr-18 23:19 mlflow/models/evaluation/base.py
--rw-r--r--  2.0 unx    50976 b- defN 23-Apr-18 23:19 mlflow/models/evaluation/default_evaluator.py
--rw-r--r--  2.0 unx     2036 b- defN 23-Apr-18 23:19 mlflow/models/evaluation/evaluator_registry.py
--rw-r--r--  2.0 unx     6223 b- defN 23-Apr-18 23:19 mlflow/models/evaluation/lift_curve.py
--rw-r--r--  2.0 unx    10946 b- defN 23-Apr-18 23:19 mlflow/models/evaluation/validation.py
--rw-r--r--  2.0 unx    20642 b- defN 23-Apr-18 23:19 mlflow/openai/__init__.py
--rw-r--r--  2.0 unx    12150 b- defN 23-Apr-18 23:19 mlflow/openai/api_request_parallel_processor.py
--rw-r--r--  2.0 unx     2936 b- defN 23-Apr-18 23:19 mlflow/openai/retry.py
--rw-r--r--  2.0 unx     1862 b- defN 23-Apr-18 23:19 mlflow/openai/utils.py
--rw-r--r--  2.0 unx    23859 b- defN 23-Apr-18 23:19 mlflow/paddle/__init__.py
--rw-r--r--  2.0 unx     4792 b- defN 23-Apr-18 23:19 mlflow/paddle/_paddle_autolog.py
--rw-r--r--  2.0 unx    17396 b- defN 23-Apr-18 23:19 mlflow/projects/__init__.py
--rw-r--r--  2.0 unx    11532 b- defN 23-Apr-18 23:19 mlflow/projects/_project_spec.py
--rw-r--r--  2.0 unx    20270 b- defN 23-Apr-18 23:19 mlflow/projects/databricks.py
--rw-r--r--  2.0 unx     6394 b- defN 23-Apr-18 23:19 mlflow/projects/docker.py
--rw-r--r--  2.0 unx       94 b- defN 23-Apr-18 23:19 mlflow/projects/env_type.py
--rw-r--r--  2.0 unx     6379 b- defN 23-Apr-18 23:19 mlflow/projects/kubernetes.py
--rw-r--r--  2.0 unx     3574 b- defN 23-Apr-18 23:19 mlflow/projects/submitted_run.py
--rw-r--r--  2.0 unx    13432 b- defN 23-Apr-18 23:19 mlflow/projects/utils.py
--rw-r--r--  2.0 unx      271 b- defN 23-Apr-18 23:19 mlflow/projects/backend/__init__.py
--rw-r--r--  2.0 unx     2210 b- defN 23-Apr-18 23:19 mlflow/projects/backend/abstract_backend.py
--rw-r--r--  2.0 unx     1079 b- defN 23-Apr-18 23:19 mlflow/projects/backend/loader.py
--rw-r--r--  2.0 unx    17240 b- defN 23-Apr-18 23:19 mlflow/projects/backend/local.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/protos/__init__.py
--rw-r--r--  2.0 unx    17261 b- defN 23-Apr-18 23:19 mlflow/protos/databricks_artifacts_pb2.py
--rw-r--r--  2.0 unx    14095 b- defN 23-Apr-18 23:19 mlflow/protos/databricks_pb2.py
--rw-r--r--  2.0 unx    32279 b- defN 23-Apr-18 23:19 mlflow/protos/databricks_uc_registry_messages_pb2.py
--rw-r--r--  2.0 unx    10491 b- defN 23-Apr-18 23:19 mlflow/protos/databricks_uc_registry_service_pb2.py
--rw-r--r--  2.0 unx    16146 b- defN 23-Apr-18 23:19 mlflow/protos/facet_feature_statistics_pb2.py
--rw-r--r--  2.0 unx     8552 b- defN 23-Apr-18 23:19 mlflow/protos/mlflow_artifacts_pb2.py
--rw-r--r--  2.0 unx    54475 b- defN 23-Apr-18 23:19 mlflow/protos/model_registry_pb2.py
--rw-r--r--  2.0 unx    48593 b- defN 23-Apr-18 23:19 mlflow/protos/service_pb2.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/protos/scalapb/__init__.py
--rw-r--r--  2.0 unx     3307 b- defN 23-Apr-18 23:19 mlflow/protos/scalapb/scalapb_pb2.py
--rw-r--r--  2.0 unx    79843 b- defN 23-Apr-18 23:19 mlflow/pyfunc/__init__.py
--rw-r--r--  2.0 unx    16640 b- defN 23-Apr-18 23:19 mlflow/pyfunc/backend.py
--rw-r--r--  2.0 unx      901 b- defN 23-Apr-18 23:19 mlflow/pyfunc/mlserver.py
--rw-r--r--  2.0 unx    15392 b- defN 23-Apr-18 23:19 mlflow/pyfunc/model.py
--rw-r--r--  2.0 unx     2124 b- defN 23-Apr-18 23:19 mlflow/pyfunc/spark_model_cache.py
--rw-r--r--  2.0 unx     1001 b- defN 23-Apr-18 23:19 mlflow/pyfunc/stdin_server.py
--rw-r--r--  2.0 unx    13910 b- defN 23-Apr-18 23:19 mlflow/pyfunc/scoring_server/__init__.py
--rw-r--r--  2.0 unx     4222 b- defN 23-Apr-18 23:19 mlflow/pyfunc/scoring_server/client.py
--rw-r--r--  2.0 unx      175 b- defN 23-Apr-18 23:19 mlflow/pyfunc/scoring_server/wsgi.py
--rw-r--r--  2.0 unx       50 b- defN 23-Apr-18 23:19 mlflow/pyspark/__init__.py
--rw-r--r--  2.0 unx    53458 b- defN 23-Apr-18 23:19 mlflow/pyspark/ml/__init__.py
--rw-r--r--  2.0 unx     2908 b- defN 23-Apr-18 23:19 mlflow/pyspark/ml/_autolog.py
--rw-r--r--  2.0 unx     1886 b- defN 23-Apr-18 23:19 mlflow/pyspark/ml/log_model_allowlist.txt
--rw-r--r--  2.0 unx    45669 b- defN 23-Apr-18 23:19 mlflow/pytorch/__init__.py
--rw-r--r--  2.0 unx    17629 b- defN 23-Apr-18 23:19 mlflow/pytorch/_lightning_autolog.py
--rw-r--r--  2.0 unx     2654 b- defN 23-Apr-18 23:19 mlflow/pytorch/_pytorch_autolog.py
--rw-r--r--  2.0 unx     2090 b- defN 23-Apr-18 23:19 mlflow/pytorch/pickle_module.py
--rw-r--r--  2.0 unx     1330 b- defN 23-Apr-18 23:19 mlflow/recipes/__init__.py
--rw-r--r--  2.0 unx     6092 b- defN 23-Apr-18 23:19 mlflow/recipes/artifacts.py
--rw-r--r--  2.0 unx     2917 b- defN 23-Apr-18 23:19 mlflow/recipes/cli.py
--rw-r--r--  2.0 unx    18431 b- defN 23-Apr-18 23:19 mlflow/recipes/dag_help_strings.py
--rw-r--r--  2.0 unx    17933 b- defN 23-Apr-18 23:19 mlflow/recipes/recipe.py
--rw-r--r--  2.0 unx    14988 b- defN 23-Apr-18 23:19 mlflow/recipes/step.py
--rw-r--r--  2.0 unx    10229 b- defN 23-Apr-18 23:19 mlflow/recipes/cards/__init__.py
--rw-r--r--  2.0 unx     4780 b- defN 23-Apr-18 23:19 mlflow/recipes/cards/histogram_generator.py
--rw-r--r--  2.0 unx    12472 b- defN 23-Apr-18 23:19 mlflow/recipes/cards/pandas_renderer.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/recipes/cards/templates/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/recipes/classification/__init__.py
--rw-r--r--  2.0 unx      122 b- defN 23-Apr-18 23:19 mlflow/recipes/classification/v1/__init__.py
--rw-r--r--  2.0 unx    20462 b- defN 23-Apr-18 23:19 mlflow/recipes/classification/v1/recipe.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/recipes/regression/__init__.py
--rw-r--r--  2.0 unx      114 b- defN 23-Apr-18 23:19 mlflow/recipes/regression/v1/__init__.py
--rw-r--r--  2.0 unx    22495 b- defN 23-Apr-18 23:19 mlflow/recipes/regression/v1/recipe.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/__init__.py
--rw-r--r--  2.0 unx    20717 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/evaluate.py
--rw-r--r--  2.0 unx    12132 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/predict.py
--rw-r--r--  2.0 unx     7680 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/register.py
--rw-r--r--  2.0 unx    19541 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/split.py
--rw-r--r--  2.0 unx    59789 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/train.py
--rw-r--r--  2.0 unx    10602 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/transform.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/automl/__init__.py
--rw-r--r--  2.0 unx     6269 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/automl/flaml.py
--rw-r--r--  2.0 unx    11137 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/ingest/__init__.py
--rw-r--r--  2.0 unx    26446 b- defN 23-Apr-18 23:19 mlflow/recipes/steps/ingest/datasets.py
--rw-r--r--  2.0 unx     6355 b- defN 23-Apr-18 23:19 mlflow/recipes/utils/__init__.py
--rw-r--r--  2.0 unx    28468 b- defN 23-Apr-18 23:19 mlflow/recipes/utils/execution.py
--rw-r--r--  2.0 unx     8990 b- defN 23-Apr-18 23:19 mlflow/recipes/utils/metrics.py
--rw-r--r--  2.0 unx     7392 b- defN 23-Apr-18 23:19 mlflow/recipes/utils/step.py
--rw-r--r--  2.0 unx    12375 b- defN 23-Apr-18 23:19 mlflow/recipes/utils/tracking.py
--rw-r--r--  2.0 unx     1748 b- defN 23-Apr-18 23:19 mlflow/recipes/utils/wrapped_recipe_model.py
--rw-r--r--  2.0 unx     1115 b- defN 23-Apr-18 23:19 mlflow/rfunc/__init__.py
--rw-r--r--  2.0 unx     3643 b- defN 23-Apr-18 23:19 mlflow/rfunc/backend.py
--rw-r--r--  2.0 unx   135097 b- defN 23-Apr-18 23:19 mlflow/sagemaker/__init__.py
--rw-r--r--  2.0 unx    12986 b- defN 23-Apr-18 23:19 mlflow/sagemaker/cli.py
--rw-r--r--  2.0 unx     6460 b- defN 23-Apr-18 23:19 mlflow/server/__init__.py
--rw-r--r--  2.0 unx    66811 b- defN 23-Apr-18 23:19 mlflow/server/handlers.py
--rw-r--r--  2.0 unx      481 b- defN 23-Apr-18 23:19 mlflow/server/prometheus_exporter.py
--rw-r--r--  2.0 unx     4551 b- defN 23-Apr-18 23:19 mlflow/server/auth/__init__.py
--rw-r--r--  2.0 unx      409 b- defN 23-Apr-18 23:19 mlflow/server/auth/config.py
--rw-r--r--  2.0 unx     2384 b- defN 23-Apr-18 23:19 mlflow/server/auth/entities.py
--rw-r--r--  2.0 unx     5303 b- defN 23-Apr-18 23:19 mlflow/server/auth/sqlalchemy_store.py
--rw-r--r--  2.0 unx    82134 b- defN 23-Apr-18 23:19 mlflow/sklearn/__init__.py
--rw-r--r--  2.0 unx    37485 b- defN 23-Apr-18 23:19 mlflow/sklearn/utils.py
--rw-r--r--  2.0 unx      227 b- defN 23-Apr-18 23:19 mlflow/store/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/store/_unity_catalog/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/store/_unity_catalog/registry/__init__.py
--rw-r--r--  2.0 unx    24217 b- defN 23-Apr-18 23:19 mlflow/store/_unity_catalog/registry/rest_store.py
--rw-r--r--  2.0 unx     3519 b- defN 23-Apr-18 23:19 mlflow/store/_unity_catalog/registry/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/store/artifact/__init__.py
--rw-r--r--  2.0 unx    14956 b- defN 23-Apr-18 23:19 mlflow/store/artifact/artifact_repo.py
--rw-r--r--  2.0 unx     5309 b- defN 23-Apr-18 23:19 mlflow/store/artifact/artifact_repository_registry.py
--rw-r--r--  2.0 unx     8136 b- defN 23-Apr-18 23:19 mlflow/store/artifact/azure_blob_artifact_repo.py
--rw-r--r--  2.0 unx     5829 b- defN 23-Apr-18 23:19 mlflow/store/artifact/azure_data_lake_artifact_repo.py
--rw-r--r--  2.0 unx     5378 b- defN 23-Apr-18 23:19 mlflow/store/artifact/cli.py
--rw-r--r--  2.0 unx    34084 b- defN 23-Apr-18 23:19 mlflow/store/artifact/databricks_artifact_repo.py
--rw-r--r--  2.0 unx     9021 b- defN 23-Apr-18 23:19 mlflow/store/artifact/databricks_models_artifact_repo.py
--rw-r--r--  2.0 unx    10247 b- defN 23-Apr-18 23:19 mlflow/store/artifact/dbfs_artifact_repo.py
--rw-r--r--  2.0 unx     5234 b- defN 23-Apr-18 23:19 mlflow/store/artifact/ftp_artifact_repo.py
--rw-r--r--  2.0 unx     5873 b- defN 23-Apr-18 23:19 mlflow/store/artifact/gcs_artifact_repo.py
--rw-r--r--  2.0 unx     9684 b- defN 23-Apr-18 23:19 mlflow/store/artifact/hdfs_artifact_repo.py
--rw-r--r--  2.0 unx     3377 b- defN 23-Apr-18 23:19 mlflow/store/artifact/http_artifact_repo.py
--rw-r--r--  2.0 unx     5085 b- defN 23-Apr-18 23:19 mlflow/store/artifact/local_artifact_repo.py
--rw-r--r--  2.0 unx     3001 b- defN 23-Apr-18 23:19 mlflow/store/artifact/mlflow_artifacts_repo.py
--rw-r--r--  2.0 unx     6757 b- defN 23-Apr-18 23:19 mlflow/store/artifact/models_artifact_repo.py
--rw-r--r--  2.0 unx     6016 b- defN 23-Apr-18 23:19 mlflow/store/artifact/runs_artifact_repo.py
--rw-r--r--  2.0 unx     9442 b- defN 23-Apr-18 23:19 mlflow/store/artifact/s3_artifact_repo.py
--rw-r--r--  2.0 unx     5455 b- defN 23-Apr-18 23:19 mlflow/store/artifact/sftp_artifact_repo.py
--rw-r--r--  2.0 unx     5326 b- defN 23-Apr-18 23:19 mlflow/store/artifact/unity_catalog_models_artifact_repo.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/store/artifact/utils/__init__.py
--rw-r--r--  2.0 unx     3888 b- defN 23-Apr-18 23:19 mlflow/store/artifact/utils/models.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/store/db/__init__.py
--rw-r--r--  2.0 unx       71 b- defN 23-Apr-18 23:19 mlflow/store/db/base_sql_model.py
--rw-r--r--  2.0 unx      221 b- defN 23-Apr-18 23:19 mlflow/store/db/db_types.py
--rw-r--r--  2.0 unx    10592 b- defN 23-Apr-18 23:19 mlflow/store/db/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/__init__.py
--rw-r--r--  2.0 unx     1634 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/alembic.ini
--rw-r--r--  2.0 unx     2768 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/env.py
--rw-r--r--  2.0 unx     1990 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/0a8213491aaa_drop_duplicate_killed_constraint.py
--rw-r--r--  2.0 unx      462 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/0c779009ac13_add_deleted_time_field_to_runs_table.py
--rw-r--r--  2.0 unx      924 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/181f10493468_allow_nulls_for_metric_values.py
--rw-r--r--  2.0 unx     1059 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/27a6a02d2cf1_add_model_version_tags_table.py
--rw-r--r--  2.0 unx     2624 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/2b4d017a5e9b_add_model_registry_tables_to_db.py
--rw-r--r--  2.0 unx     1375 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/3500859a5d39_add_model_aliases_table.py
--rw-r--r--  2.0 unx     1433 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/39d1c3be5f05_add_is_nan_constraint_for_metrics_tables_if_necessary.py
--rw-r--r--  2.0 unx     1201 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/451aebb31d03_add_metric_step.py
--rw-r--r--  2.0 unx      940 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/728d730b5ebd_add_registered_model_tags_table.py
--rw-r--r--  2.0 unx     1014 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/7ac759974ad8_update_run_tags_with_larger_limit.py
--rw-r--r--  2.0 unx      476 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/84291f40a231_add_run_link_to_model_version.py
--rw-r--r--  2.0 unx     5716 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/89d4b8295536_create_latest_metrics_table.py
--rw-r--r--  2.0 unx     1666 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/90e64c465722_migrate_user_column_to_tags.py
--rw-r--r--  2.0 unx      577 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/97727af70f4d_creation_time_last_update_time_experiments.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/__init__.py
--rw-r--r--  2.0 unx      582 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/a8c4a736bde6_allow_nulls_for_run_id.py
--rw-r--r--  2.0 unx      637 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/bd07f7e963c5_create_index_on_run_uuid.py
--rw-r--r--  2.0 unx     1295 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/c48cb773bb87_reset_default_value_for_is_nan_in_metrics_table_for_mysql.py
--rw-r--r--  2.0 unx      684 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/cc1f77228345_change_param_value_length_to_500.py
--rw-r--r--  2.0 unx     2830 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/cfd24bdc0731_update_run_status_constraint_with_killed.py
--rw-r--r--  2.0 unx      904 b- defN 23-Apr-18 23:19 mlflow/store/db_migrations/versions/df50e92ffc5e_add_experiment_tags_table.py
--rw-r--r--  2.0 unx       80 b- defN 23-Apr-18 23:19 mlflow/store/entities/__init__.py
--rw-r--r--  2.0 unx      479 b- defN 23-Apr-18 23:19 mlflow/store/entities/paged_list.py
--rw-r--r--  2.0 unx      605 b- defN 23-Apr-18 23:19 mlflow/store/model_registry/__init__.py
--rw-r--r--  2.0 unx    11022 b- defN 23-Apr-18 23:19 mlflow/store/model_registry/abstract_store.py
--rw-r--r--  2.0 unx     1330 b- defN 23-Apr-18 23:19 mlflow/store/model_registry/base_rest_store.py
--rw-r--r--  2.0 unx    38729 b- defN 23-Apr-18 23:19 mlflow/store/model_registry/file_store.py
--rw-r--r--  2.0 unx    16920 b- defN 23-Apr-18 23:19 mlflow/store/model_registry/rest_store.py
--rw-r--r--  2.0 unx    50457 b- defN 23-Apr-18 23:19 mlflow/store/model_registry/sqlalchemy_store.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/store/model_registry/dbmodels/__init__.py
--rw-r--r--  2.0 unx     6341 b- defN 23-Apr-18 23:19 mlflow/store/model_registry/dbmodels/models.py
--rw-r--r--  2.0 unx     1154 b- defN 23-Apr-18 23:19 mlflow/store/tracking/__init__.py
--rw-r--r--  2.0 unx    13042 b- defN 23-Apr-18 23:19 mlflow/store/tracking/abstract_store.py
--rw-r--r--  2.0 unx    46363 b- defN 23-Apr-18 23:19 mlflow/store/tracking/file_store.py
--rw-r--r--  2.0 unx    12172 b- defN 23-Apr-18 23:19 mlflow/store/tracking/rest_store.py
--rw-r--r--  2.0 unx    67230 b- defN 23-Apr-18 23:19 mlflow/store/tracking/sqlalchemy_store.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/store/tracking/dbmodels/__init__.py
--rw-r--r--  2.0 unx     8315 b- defN 23-Apr-18 23:19 mlflow/store/tracking/dbmodels/initial_models.py
--rw-r--r--  2.0 unx    15674 b- defN 23-Apr-18 23:19 mlflow/store/tracking/dbmodels/models.py
--rw-r--r--  2.0 unx    57261 b- defN 23-Apr-18 23:19 mlflow/tensorflow/__init__.py
--rw-r--r--  2.0 unx     8442 b- defN 23-Apr-18 23:19 mlflow/tensorflow/_autolog.py
--rw-r--r--  2.0 unx      995 b- defN 23-Apr-18 23:19 mlflow/tracking/__init__.py
--rw-r--r--  2.0 unx     7155 b- defN 23-Apr-18 23:19 mlflow/tracking/artifact_utils.py
--rw-r--r--  2.0 unx   126036 b- defN 23-Apr-18 23:19 mlflow/tracking/client.py
--rw-r--r--  2.0 unx    70818 b- defN 23-Apr-18 23:19 mlflow/tracking/fluent.py
--rw-r--r--  2.0 unx     3404 b- defN 23-Apr-18 23:19 mlflow/tracking/llm_utils.py
--rw-r--r--  2.0 unx     2248 b- defN 23-Apr-18 23:19 mlflow/tracking/metric_value_conversion_utils.py
--rw-r--r--  2.0 unx     3515 b- defN 23-Apr-18 23:19 mlflow/tracking/registry.py
--rw-r--r--  2.0 unx       41 b- defN 23-Apr-18 23:19 mlflow/tracking/_model_registry/__init__.py
--rw-r--r--  2.0 unx    15534 b- defN 23-Apr-18 23:19 mlflow/tracking/_model_registry/client.py
--rw-r--r--  2.0 unx     9364 b- defN 23-Apr-18 23:19 mlflow/tracking/_model_registry/fluent.py
--rw-r--r--  2.0 unx     3152 b- defN 23-Apr-18 23:19 mlflow/tracking/_model_registry/registry.py
--rw-r--r--  2.0 unx     7008 b- defN 23-Apr-18 23:19 mlflow/tracking/_model_registry/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/tracking/_tracking_service/__init__.py
--rw-r--r--  2.0 unx    23690 b- defN 23-Apr-18 23:19 mlflow/tracking/_tracking_service/client.py
--rw-r--r--  2.0 unx     2335 b- defN 23-Apr-18 23:19 mlflow/tracking/_tracking_service/registry.py
--rw-r--r--  2.0 unx     9517 b- defN 23-Apr-18 23:19 mlflow/tracking/_tracking_service/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/tracking/context/__init__.py
--rw-r--r--  2.0 unx     1076 b- defN 23-Apr-18 23:19 mlflow/tracking/context/abstract_context.py
--rw-r--r--  2.0 unx      520 b- defN 23-Apr-18 23:19 mlflow/tracking/context/databricks_cluster_context.py
--rw-r--r--  2.0 unx      561 b- defN 23-Apr-18 23:19 mlflow/tracking/context/databricks_command_context.py
--rw-r--r--  2.0 unx     1965 b- defN 23-Apr-18 23:19 mlflow/tracking/context/databricks_job_context.py
--rw-r--r--  2.0 unx     1713 b- defN 23-Apr-18 23:19 mlflow/tracking/context/databricks_notebook_context.py
--rw-r--r--  2.0 unx     1952 b- defN 23-Apr-18 23:19 mlflow/tracking/context/databricks_repo_context.py
--rw-r--r--  2.0 unx     1020 b- defN 23-Apr-18 23:19 mlflow/tracking/context/default_context.py
--rw-r--r--  2.0 unx      898 b- defN 23-Apr-18 23:19 mlflow/tracking/context/git_context.py
--rw-r--r--  2.0 unx     3738 b- defN 23-Apr-18 23:19 mlflow/tracking/context/registry.py
--rw-r--r--  2.0 unx      443 b- defN 23-Apr-18 23:19 mlflow/tracking/context/system_environment_context.py
--rw-r--r--  2.0 unx       28 b- defN 23-Apr-18 23:19 mlflow/tracking/default_experiment/__init__.py
--rw-r--r--  2.0 unx     1703 b- defN 23-Apr-18 23:19 mlflow/tracking/default_experiment/abstract_context.py
--rw-r--r--  2.0 unx     1718 b- defN 23-Apr-18 23:19 mlflow/tracking/default_experiment/databricks_job_experiment_provider.py
--rw-r--r--  2.0 unx     2300 b- defN 23-Apr-18 23:19 mlflow/tracking/default_experiment/databricks_notebook_experiment_provider.py
--rw-r--r--  2.0 unx     3173 b- defN 23-Apr-18 23:19 mlflow/tracking/default_experiment/registry.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-18 23:19 mlflow/tracking/request_header/__init__.py
--rw-r--r--  2.0 unx     1077 b- defN 23-Apr-18 23:19 mlflow/tracking/request_header/abstract_request_header_provider.py
--rw-r--r--  2.0 unx     1336 b- defN 23-Apr-18 23:19 mlflow/tracking/request_header/databricks_request_header_provider.py
--rw-r--r--  2.0 unx      486 b- defN 23-Apr-18 23:19 mlflow/tracking/request_header/default_request_header_provider.py
--rw-r--r--  2.0 unx     2867 b- defN 23-Apr-18 23:19 mlflow/tracking/request_header/registry.py
--rw-r--r--  2.0 unx      299 b- defN 23-Apr-18 23:19 mlflow/types/__init__.py
--rw-r--r--  2.0 unx    13334 b- defN 23-Apr-18 23:19 mlflow/types/schema.py
--rw-r--r--  2.0 unx    17636 b- defN 23-Apr-18 23:19 mlflow/types/utils.py
--rw-r--r--  2.0 unx     9389 b- defN 23-Apr-18 23:19 mlflow/utils/__init__.py
--rw-r--r--  2.0 unx     6270 b- defN 23-Apr-18 23:19 mlflow/utils/_capture_modules.py
--rw-r--r--  2.0 unx     6395 b- defN 23-Apr-18 23:19 mlflow/utils/_spark_utils.py
--rw-r--r--  2.0 unx     4906 b- defN 23-Apr-18 23:19 mlflow/utils/annotations.py
--rw-r--r--  2.0 unx      400 b- defN 23-Apr-18 23:19 mlflow/utils/arguments_utils.py
--rw-r--r--  2.0 unx      215 b- defN 23-Apr-18 23:19 mlflow/utils/class_utils.py
--rw-r--r--  2.0 unx     6431 b- defN 23-Apr-18 23:19 mlflow/utils/cli_args.py
--rw-r--r--  2.0 unx    13002 b- defN 23-Apr-18 23:19 mlflow/utils/conda.py
--rw-r--r--  2.0 unx      432 b- defN 23-Apr-18 23:19 mlflow/utils/data_utils.py
--rw-r--r--  2.0 unx    21450 b- defN 23-Apr-18 23:19 mlflow/utils/databricks_utils.py
--rw-r--r--  2.0 unx     9138 b- defN 23-Apr-18 23:19 mlflow/utils/docstring_utils.py
--rw-r--r--  2.0 unx      192 b- defN 23-Apr-18 23:19 mlflow/utils/env.py
--rw-r--r--  2.0 unx      474 b- defN 23-Apr-18 23:19 mlflow/utils/env_manager.py
--rw-r--r--  2.0 unx    21930 b- defN 23-Apr-18 23:19 mlflow/utils/environment.py
--rw-r--r--  2.0 unx    28476 b- defN 23-Apr-18 23:19 mlflow/utils/file_utils.py
--rw-r--r--  2.0 unx     2306 b- defN 23-Apr-18 23:19 mlflow/utils/git_utils.py
--rw-r--r--  2.0 unx    24166 b- defN 23-Apr-18 23:19 mlflow/utils/gorilla.py
--rw-r--r--  2.0 unx     2597 b- defN 23-Apr-18 23:19 mlflow/utils/logging_utils.py
--rw-r--r--  2.0 unx     1298 b- defN 23-Apr-18 23:19 mlflow/utils/mime_type_utils.py
--rw-r--r--  2.0 unx     3839 b- defN 23-Apr-18 23:19 mlflow/utils/mlflow_tags.py
--rw-r--r--  2.0 unx     6208 b- defN 23-Apr-18 23:19 mlflow/utils/model_utils.py
--rw-r--r--  2.0 unx     5873 b- defN 23-Apr-18 23:19 mlflow/utils/name_utils.py
--rw-r--r--  2.0 unx     2412 b- defN 23-Apr-18 23:19 mlflow/utils/nfs_on_spark.py
--rw-r--r--  2.0 unx      139 b- defN 23-Apr-18 23:19 mlflow/utils/os.py
--rw-r--r--  2.0 unx     5799 b- defN 23-Apr-18 23:19 mlflow/utils/process.py
--rw-r--r--  2.0 unx    19923 b- defN 23-Apr-18 23:19 mlflow/utils/proto_json_utils.py
--rw-r--r--  2.0 unx    18947 b- defN 23-Apr-18 23:19 mlflow/utils/requirements_utils.py
--rw-r--r--  2.0 unx    16849 b- defN 23-Apr-18 23:19 mlflow/utils/rest_utils.py
--rw-r--r--  2.0 unx    55945 b- defN 23-Apr-18 23:19 mlflow/utils/search_utils.py
--rw-r--r--  2.0 unx     2368 b- defN 23-Apr-18 23:19 mlflow/utils/server_cli_utils.py
--rw-r--r--  2.0 unx     3805 b- defN 23-Apr-18 23:19 mlflow/utils/string_utils.py
--rw-r--r--  2.0 unx      512 b- defN 23-Apr-18 23:19 mlflow/utils/time_utils.py
--rw-r--r--  2.0 unx    13915 b- defN 23-Apr-18 23:19 mlflow/utils/uri.py
--rw-r--r--  2.0 unx    16024 b- defN 23-Apr-18 23:19 mlflow/utils/validation.py
--rw-r--r--  2.0 unx    15879 b- defN 23-Apr-18 23:19 mlflow/utils/virtualenv.py
--rw-r--r--  2.0 unx    25551 b- defN 23-Apr-18 23:19 mlflow/utils/autologging_utils/__init__.py
--rw-r--r--  2.0 unx    15731 b- defN 23-Apr-18 23:19 mlflow/utils/autologging_utils/client.py
--rw-r--r--  2.0 unx    10937 b- defN 23-Apr-18 23:19 mlflow/utils/autologging_utils/events.py
--rw-r--r--  2.0 unx    13381 b- defN 23-Apr-18 23:19 mlflow/utils/autologging_utils/logging_and_warnings.py
--rw-r--r--  2.0 unx    47266 b- defN 23-Apr-18 23:19 mlflow/utils/autologging_utils/safety.py
--rw-r--r--  2.0 unx     3489 b- defN 23-Apr-18 23:19 mlflow/utils/autologging_utils/versioning.py
--rw-r--r--  2.0 unx    13489 b- defN 23-Apr-18 23:19 mlflow/utils/import_hooks/__init__.py
--rw-r--r--  2.0 unx    34313 b- defN 23-Apr-18 23:19 mlflow/xgboost/__init__.py
--rw-r--r--  2.0 unx     2908 b- defN 23-Apr-18 23:19 mlflow/xgboost/_autolog.py
--rw-r--r--  2.0 unx      521 b- defN 23-Apr-18 23:19 pylint_plugins/__init__.py
--rw-r--r--  2.0 unx     2006 b- defN 23-Apr-18 23:19 pylint_plugins/errors.py
--rw-r--r--  2.0 unx      856 b- defN 23-Apr-18 23:19 pylint_plugins/print_function.py
--rw-r--r--  2.0 unx      571 b- defN 23-Apr-18 23:19 pylint_plugins/set_checker.py
--rw-r--r--  2.0 unx      878 b- defN 23-Apr-18 23:19 pylint_plugins/string_checker.py
--rw-r--r--  2.0 unx      692 b- defN 23-Apr-18 23:19 pylint_plugins/unittest_assert_raises.py
--rw-r--r--  2.0 unx     1546 b- defN 23-Apr-18 23:19 pylint_plugins/pytest_raises_checker/__init__.py
--rw-r--r--  2.0 unx    11382 b- defN 23-Apr-18 23:19 mlflow_skinny-2.3.0.dist-info/LICENSE.txt
--rw-r--r--  2.0 unx    12386 b- defN 23-Apr-18 23:19 mlflow_skinny-2.3.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-18 23:19 mlflow_skinny-2.3.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-18 23:19 mlflow_skinny-2.3.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       22 b- defN 23-Apr-18 23:19 mlflow_skinny-2.3.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    32890 b- defN 23-Apr-18 23:19 mlflow_skinny-2.3.0.dist-info/RECORD
-352 files, 10941379 bytes uncompressed, 4018335 bytes compressed:  63.3%
+Zip file size: 4073960 bytes, number of entries: 352
+-rw-r--r--  2.0 unx     6155 b- defN 23-Apr-28 08:25 mlflow/__init__.py
+-rw-r--r--  2.0 unx       39 b- defN 23-Apr-28 08:25 mlflow/__main__.py
+-rw-r--r--  2.0 unx     3668 b- defN 23-Apr-28 08:25 mlflow/_doctor.py
+-rw-r--r--  2.0 unx     9428 b- defN 23-Apr-28 08:25 mlflow/_spark_autologging.py
+-rw-r--r--  2.0 unx    15140 b- defN 23-Apr-28 08:25 mlflow/catboost.py
+-rw-r--r--  2.0 unx    23356 b- defN 23-Apr-28 08:25 mlflow/cli.py
+-rw-r--r--  2.0 unx      407 b- defN 23-Apr-28 08:25 mlflow/client.py
+-rw-r--r--  2.0 unx      881 b- defN 23-Apr-28 08:25 mlflow/db.py
+-rw-r--r--  2.0 unx    28178 b- defN 23-Apr-28 08:25 mlflow/diviner.py
+-rw-r--r--  2.0 unx    10080 b- defN 23-Apr-28 08:25 mlflow/environment_variables.py
+-rw-r--r--  2.0 unx     4881 b- defN 23-Apr-28 08:25 mlflow/exceptions.py
+-rw-r--r--  2.0 unx     5080 b- defN 23-Apr-28 08:25 mlflow/experiments.py
+-rw-r--r--  2.0 unx    14185 b- defN 23-Apr-28 08:25 mlflow/h2o.py
+-rw-r--r--  2.0 unx      311 b- defN 23-Apr-28 08:25 mlflow/keras.py
+-rw-r--r--  2.0 unx    35698 b- defN 23-Apr-28 08:25 mlflow/lightgbm.py
+-rw-r--r--  2.0 unx      180 b- defN 23-Apr-28 08:25 mlflow/llm.py
+-rw-r--r--  2.0 unx     5474 b- defN 23-Apr-28 08:25 mlflow/ml_package_versions.py
+-rw-r--r--  2.0 unx    13885 b- defN 23-Apr-28 08:25 mlflow/mleap.py
+-rw-r--r--  2.0 unx    21826 b- defN 23-Apr-28 08:25 mlflow/onnx.py
+-rw-r--r--  2.0 unx    17616 b- defN 23-Apr-28 08:25 mlflow/pmdarima.py
+-rw-r--r--  2.0 unx    14024 b- defN 23-Apr-28 08:25 mlflow/prophet.py
+-rw-r--r--  2.0 unx  7197781 b- defN 23-Apr-28 08:25 mlflow/pypi_package_index.json
+-rw-r--r--  2.0 unx     2519 b- defN 23-Apr-28 08:25 mlflow/runs.py
+-rw-r--r--  2.0 unx    26647 b- defN 23-Apr-28 08:25 mlflow/shap.py
+-rw-r--r--  2.0 unx    14259 b- defN 23-Apr-28 08:25 mlflow/spacy.py
+-rw-r--r--  2.0 unx    44813 b- defN 23-Apr-28 08:25 mlflow/spark.py
+-rw-r--r--  2.0 unx    24596 b- defN 23-Apr-28 08:25 mlflow/statsmodels.py
+-rw-r--r--  2.0 unx    89127 b- defN 23-Apr-28 08:25 mlflow/transformers.py
+-rw-r--r--  2.0 unx      147 b- defN 23-Apr-28 08:25 mlflow/version.py
+-rw-r--r--  2.0 unx     6485 b- defN 23-Apr-28 08:25 mlflow/artifacts/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/azure/__init__.py
+-rw-r--r--  2.0 unx    11647 b- defN 23-Apr-28 08:25 mlflow/azure/client.py
+-rw-r--r--  2.0 unx     3797 b- defN 23-Apr-28 08:25 mlflow/deployments/__init__.py
+-rw-r--r--  2.0 unx    15572 b- defN 23-Apr-28 08:25 mlflow/deployments/base.py
+-rw-r--r--  2.0 unx    15078 b- defN 23-Apr-28 08:25 mlflow/deployments/cli.py
+-rw-r--r--  2.0 unx     3825 b- defN 23-Apr-28 08:25 mlflow/deployments/interface.py
+-rw-r--r--  2.0 unx     5512 b- defN 23-Apr-28 08:25 mlflow/deployments/plugin_manager.py
+-rw-r--r--  2.0 unx      556 b- defN 23-Apr-28 08:25 mlflow/deployments/utils.py
+-rw-r--r--  2.0 unx      948 b- defN 23-Apr-28 08:25 mlflow/entities/__init__.py
+-rw-r--r--  2.0 unx     1414 b- defN 23-Apr-28 08:25 mlflow/entities/_mlflow_object.py
+-rw-r--r--  2.0 unx     3510 b- defN 23-Apr-28 08:25 mlflow/entities/experiment.py
+-rw-r--r--  2.0 unx      887 b- defN 23-Apr-28 08:25 mlflow/entities/experiment_tag.py
+-rw-r--r--  2.0 unx     1215 b- defN 23-Apr-28 08:25 mlflow/entities/file_info.py
+-rw-r--r--  2.0 unx     1242 b- defN 23-Apr-28 08:25 mlflow/entities/lifecycle_stage.py
+-rw-r--r--  2.0 unx     1418 b- defN 23-Apr-28 08:25 mlflow/entities/metric.py
+-rw-r--r--  2.0 unx     1133 b- defN 23-Apr-28 08:25 mlflow/entities/param.py
+-rw-r--r--  2.0 unx     1438 b- defN 23-Apr-28 08:25 mlflow/entities/run.py
+-rw-r--r--  2.0 unx     3032 b- defN 23-Apr-28 08:25 mlflow/entities/run_data.py
+-rw-r--r--  2.0 unx     6182 b- defN 23-Apr-28 08:25 mlflow/entities/run_info.py
+-rw-r--r--  2.0 unx     1550 b- defN 23-Apr-28 08:25 mlflow/entities/run_status.py
+-rw-r--r--  2.0 unx      890 b- defN 23-Apr-28 08:25 mlflow/entities/run_tag.py
+-rw-r--r--  2.0 unx     1212 b- defN 23-Apr-28 08:25 mlflow/entities/source_type.py
+-rw-r--r--  2.0 unx     1826 b- defN 23-Apr-28 08:25 mlflow/entities/view_type.py
+-rw-r--r--  2.0 unx      529 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/__init__.py
+-rw-r--r--  2.0 unx      286 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/_model_registry_entity.py
+-rw-r--r--  2.0 unx     6435 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/model_version.py
+-rw-r--r--  2.0 unx      831 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/model_version_stages.py
+-rw-r--r--  2.0 unx     1533 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/model_version_status.py
+-rw-r--r--  2.0 unx      933 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/model_version_tag.py
+-rw-r--r--  2.0 unx     4933 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/registered_model.py
+-rw-r--r--  2.0 unx     1053 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/registered_model_alias.py
+-rw-r--r--  2.0 unx      948 b- defN 23-Apr-28 08:25 mlflow/entities/model_registry/registered_model_tag.py
+-rw-r--r--  2.0 unx    25354 b- defN 23-Apr-28 08:25 mlflow/fastai/__init__.py
+-rw-r--r--  2.0 unx     5757 b- defN 23-Apr-28 08:25 mlflow/fastai/callback.py
+-rw-r--r--  2.0 unx    19063 b- defN 23-Apr-28 08:25 mlflow/gluon/__init__.py
+-rw-r--r--  2.0 unx     2020 b- defN 23-Apr-28 08:25 mlflow/gluon/_autolog.py
+-rw-r--r--  2.0 unx    16643 b- defN 23-Apr-28 08:25 mlflow/langchain/__init__.py
+-rw-r--r--  2.0 unx     4846 b- defN 23-Apr-28 08:25 mlflow/langchain/api_request_parallel_processor.py
+-rw-r--r--  2.0 unx     3627 b- defN 23-Apr-28 08:25 mlflow/models/__init__.py
+-rw-r--r--  2.0 unx     9803 b- defN 23-Apr-28 08:25 mlflow/models/cli.py
+-rw-r--r--  2.0 unx     9853 b- defN 23-Apr-28 08:25 mlflow/models/docker_utils.py
+-rw-r--r--  2.0 unx     3420 b- defN 23-Apr-28 08:25 mlflow/models/flavor_backend.py
+-rw-r--r--  2.0 unx     2354 b- defN 23-Apr-28 08:25 mlflow/models/flavor_backend_registry.py
+-rw-r--r--  2.0 unx    23802 b- defN 23-Apr-28 08:25 mlflow/models/model.py
+-rw-r--r--  2.0 unx     8634 b- defN 23-Apr-28 08:25 mlflow/models/signature.py
+-rw-r--r--  2.0 unx    38033 b- defN 23-Apr-28 08:25 mlflow/models/utils.py
+-rw-r--r--  2.0 unx    11707 b- defN 23-Apr-28 08:25 mlflow/models/wheeled_model.py
+-rw-r--r--  2.0 unx     9387 b- defN 23-Apr-28 08:25 mlflow/models/container/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/models/container/scoring_server/__init__.py
+-rw-r--r--  2.0 unx      131 b- defN 23-Apr-28 08:25 mlflow/models/container/scoring_server/wsgi.py
+-rw-r--r--  2.0 unx      491 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/__init__.py
+-rw-r--r--  2.0 unx     3105 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/_shap_patch.py
+-rw-r--r--  2.0 unx     6769 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/artifacts.py
+-rw-r--r--  2.0 unx    59205 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/base.py
+-rw-r--r--  2.0 unx    50976 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/default_evaluator.py
+-rw-r--r--  2.0 unx     2036 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/evaluator_registry.py
+-rw-r--r--  2.0 unx     6223 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/lift_curve.py
+-rw-r--r--  2.0 unx    10946 b- defN 23-Apr-28 08:25 mlflow/models/evaluation/validation.py
+-rw-r--r--  2.0 unx    23159 b- defN 23-Apr-28 08:25 mlflow/openai/__init__.py
+-rw-r--r--  2.0 unx    12309 b- defN 23-Apr-28 08:25 mlflow/openai/api_request_parallel_processor.py
+-rw-r--r--  2.0 unx     2936 b- defN 23-Apr-28 08:25 mlflow/openai/retry.py
+-rw-r--r--  2.0 unx     2040 b- defN 23-Apr-28 08:25 mlflow/openai/utils.py
+-rw-r--r--  2.0 unx    23859 b- defN 23-Apr-28 08:25 mlflow/paddle/__init__.py
+-rw-r--r--  2.0 unx     4792 b- defN 23-Apr-28 08:25 mlflow/paddle/_paddle_autolog.py
+-rw-r--r--  2.0 unx    17396 b- defN 23-Apr-28 08:25 mlflow/projects/__init__.py
+-rw-r--r--  2.0 unx    11532 b- defN 23-Apr-28 08:25 mlflow/projects/_project_spec.py
+-rw-r--r--  2.0 unx    20270 b- defN 23-Apr-28 08:25 mlflow/projects/databricks.py
+-rw-r--r--  2.0 unx     6394 b- defN 23-Apr-28 08:25 mlflow/projects/docker.py
+-rw-r--r--  2.0 unx       94 b- defN 23-Apr-28 08:25 mlflow/projects/env_type.py
+-rw-r--r--  2.0 unx     6379 b- defN 23-Apr-28 08:25 mlflow/projects/kubernetes.py
+-rw-r--r--  2.0 unx     3574 b- defN 23-Apr-28 08:25 mlflow/projects/submitted_run.py
+-rw-r--r--  2.0 unx    13432 b- defN 23-Apr-28 08:25 mlflow/projects/utils.py
+-rw-r--r--  2.0 unx      271 b- defN 23-Apr-28 08:25 mlflow/projects/backend/__init__.py
+-rw-r--r--  2.0 unx     2210 b- defN 23-Apr-28 08:25 mlflow/projects/backend/abstract_backend.py
+-rw-r--r--  2.0 unx     1079 b- defN 23-Apr-28 08:25 mlflow/projects/backend/loader.py
+-rw-r--r--  2.0 unx    17240 b- defN 23-Apr-28 08:25 mlflow/projects/backend/local.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/protos/__init__.py
+-rw-r--r--  2.0 unx    17261 b- defN 23-Apr-28 08:25 mlflow/protos/databricks_artifacts_pb2.py
+-rw-r--r--  2.0 unx    14095 b- defN 23-Apr-28 08:25 mlflow/protos/databricks_pb2.py
+-rw-r--r--  2.0 unx    38674 b- defN 23-Apr-28 08:25 mlflow/protos/databricks_uc_registry_messages_pb2.py
+-rw-r--r--  2.0 unx    12471 b- defN 23-Apr-28 08:25 mlflow/protos/databricks_uc_registry_service_pb2.py
+-rw-r--r--  2.0 unx    16146 b- defN 23-Apr-28 08:25 mlflow/protos/facet_feature_statistics_pb2.py
+-rw-r--r--  2.0 unx     8552 b- defN 23-Apr-28 08:25 mlflow/protos/mlflow_artifacts_pb2.py
+-rw-r--r--  2.0 unx    54475 b- defN 23-Apr-28 08:25 mlflow/protos/model_registry_pb2.py
+-rw-r--r--  2.0 unx    48593 b- defN 23-Apr-28 08:25 mlflow/protos/service_pb2.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/protos/scalapb/__init__.py
+-rw-r--r--  2.0 unx     3307 b- defN 23-Apr-28 08:25 mlflow/protos/scalapb/scalapb_pb2.py
+-rw-r--r--  2.0 unx    81392 b- defN 23-Apr-28 08:25 mlflow/pyfunc/__init__.py
+-rw-r--r--  2.0 unx    16640 b- defN 23-Apr-28 08:25 mlflow/pyfunc/backend.py
+-rw-r--r--  2.0 unx      901 b- defN 23-Apr-28 08:25 mlflow/pyfunc/mlserver.py
+-rw-r--r--  2.0 unx    15392 b- defN 23-Apr-28 08:25 mlflow/pyfunc/model.py
+-rw-r--r--  2.0 unx     2124 b- defN 23-Apr-28 08:25 mlflow/pyfunc/spark_model_cache.py
+-rw-r--r--  2.0 unx     1001 b- defN 23-Apr-28 08:25 mlflow/pyfunc/stdin_server.py
+-rw-r--r--  2.0 unx    13910 b- defN 23-Apr-28 08:25 mlflow/pyfunc/scoring_server/__init__.py
+-rw-r--r--  2.0 unx     4222 b- defN 23-Apr-28 08:25 mlflow/pyfunc/scoring_server/client.py
+-rw-r--r--  2.0 unx      175 b- defN 23-Apr-28 08:25 mlflow/pyfunc/scoring_server/wsgi.py
+-rw-r--r--  2.0 unx       50 b- defN 23-Apr-28 08:25 mlflow/pyspark/__init__.py
+-rw-r--r--  2.0 unx    53458 b- defN 23-Apr-28 08:25 mlflow/pyspark/ml/__init__.py
+-rw-r--r--  2.0 unx     2908 b- defN 23-Apr-28 08:25 mlflow/pyspark/ml/_autolog.py
+-rw-r--r--  2.0 unx     1886 b- defN 23-Apr-28 08:25 mlflow/pyspark/ml/log_model_allowlist.txt
+-rw-r--r--  2.0 unx    45669 b- defN 23-Apr-28 08:25 mlflow/pytorch/__init__.py
+-rw-r--r--  2.0 unx    17629 b- defN 23-Apr-28 08:25 mlflow/pytorch/_lightning_autolog.py
+-rw-r--r--  2.0 unx     2654 b- defN 23-Apr-28 08:25 mlflow/pytorch/_pytorch_autolog.py
+-rw-r--r--  2.0 unx     2090 b- defN 23-Apr-28 08:25 mlflow/pytorch/pickle_module.py
+-rw-r--r--  2.0 unx     1330 b- defN 23-Apr-28 08:25 mlflow/recipes/__init__.py
+-rw-r--r--  2.0 unx     6092 b- defN 23-Apr-28 08:25 mlflow/recipes/artifacts.py
+-rw-r--r--  2.0 unx     2917 b- defN 23-Apr-28 08:25 mlflow/recipes/cli.py
+-rw-r--r--  2.0 unx    18431 b- defN 23-Apr-28 08:25 mlflow/recipes/dag_help_strings.py
+-rw-r--r--  2.0 unx    17933 b- defN 23-Apr-28 08:25 mlflow/recipes/recipe.py
+-rw-r--r--  2.0 unx    14988 b- defN 23-Apr-28 08:25 mlflow/recipes/step.py
+-rw-r--r--  2.0 unx    10229 b- defN 23-Apr-28 08:25 mlflow/recipes/cards/__init__.py
+-rw-r--r--  2.0 unx     4780 b- defN 23-Apr-28 08:25 mlflow/recipes/cards/histogram_generator.py
+-rw-r--r--  2.0 unx    12548 b- defN 23-Apr-28 08:25 mlflow/recipes/cards/pandas_renderer.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/recipes/cards/templates/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/recipes/classification/__init__.py
+-rw-r--r--  2.0 unx      122 b- defN 23-Apr-28 08:25 mlflow/recipes/classification/v1/__init__.py
+-rw-r--r--  2.0 unx    20462 b- defN 23-Apr-28 08:25 mlflow/recipes/classification/v1/recipe.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/recipes/regression/__init__.py
+-rw-r--r--  2.0 unx      114 b- defN 23-Apr-28 08:25 mlflow/recipes/regression/v1/__init__.py
+-rw-r--r--  2.0 unx    22495 b- defN 23-Apr-28 08:25 mlflow/recipes/regression/v1/recipe.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/__init__.py
+-rw-r--r--  2.0 unx    20717 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/evaluate.py
+-rw-r--r--  2.0 unx    12132 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/predict.py
+-rw-r--r--  2.0 unx     7680 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/register.py
+-rw-r--r--  2.0 unx    19541 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/split.py
+-rw-r--r--  2.0 unx    59789 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/train.py
+-rw-r--r--  2.0 unx    10602 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/transform.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/automl/__init__.py
+-rw-r--r--  2.0 unx     6269 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/automl/flaml.py
+-rw-r--r--  2.0 unx    11137 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/ingest/__init__.py
+-rw-r--r--  2.0 unx    26446 b- defN 23-Apr-28 08:25 mlflow/recipes/steps/ingest/datasets.py
+-rw-r--r--  2.0 unx     6355 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/__init__.py
+-rw-r--r--  2.0 unx    28468 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/execution.py
+-rw-r--r--  2.0 unx     8990 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/metrics.py
+-rw-r--r--  2.0 unx     7392 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/step.py
+-rw-r--r--  2.0 unx    12375 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/tracking.py
+-rw-r--r--  2.0 unx     1748 b- defN 23-Apr-28 08:25 mlflow/recipes/utils/wrapped_recipe_model.py
+-rw-r--r--  2.0 unx     1115 b- defN 23-Apr-28 08:25 mlflow/rfunc/__init__.py
+-rw-r--r--  2.0 unx     3643 b- defN 23-Apr-28 08:25 mlflow/rfunc/backend.py
+-rw-r--r--  2.0 unx   135097 b- defN 23-Apr-28 08:25 mlflow/sagemaker/__init__.py
+-rw-r--r--  2.0 unx    12986 b- defN 23-Apr-28 08:25 mlflow/sagemaker/cli.py
+-rw-r--r--  2.0 unx     6460 b- defN 23-Apr-28 08:25 mlflow/server/__init__.py
+-rw-r--r--  2.0 unx    68590 b- defN 23-Apr-28 08:25 mlflow/server/handlers.py
+-rw-r--r--  2.0 unx      481 b- defN 23-Apr-28 08:25 mlflow/server/prometheus_exporter.py
+-rw-r--r--  2.0 unx     4551 b- defN 23-Apr-28 08:25 mlflow/server/auth/__init__.py
+-rw-r--r--  2.0 unx      409 b- defN 23-Apr-28 08:25 mlflow/server/auth/config.py
+-rw-r--r--  2.0 unx     2384 b- defN 23-Apr-28 08:25 mlflow/server/auth/entities.py
+-rw-r--r--  2.0 unx     5303 b- defN 23-Apr-28 08:25 mlflow/server/auth/sqlalchemy_store.py
+-rw-r--r--  2.0 unx    82134 b- defN 23-Apr-28 08:25 mlflow/sklearn/__init__.py
+-rw-r--r--  2.0 unx    37485 b- defN 23-Apr-28 08:25 mlflow/sklearn/utils.py
+-rw-r--r--  2.0 unx      227 b- defN 23-Apr-28 08:25 mlflow/store/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/_unity_catalog/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/_unity_catalog/registry/__init__.py
+-rw-r--r--  2.0 unx    25610 b- defN 23-Apr-28 08:25 mlflow/store/_unity_catalog/registry/rest_store.py
+-rw-r--r--  2.0 unx     4276 b- defN 23-Apr-28 08:25 mlflow/store/_unity_catalog/registry/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/artifact/__init__.py
+-rw-r--r--  2.0 unx    15034 b- defN 23-Apr-28 08:25 mlflow/store/artifact/artifact_repo.py
+-rw-r--r--  2.0 unx     5309 b- defN 23-Apr-28 08:25 mlflow/store/artifact/artifact_repository_registry.py
+-rw-r--r--  2.0 unx     8136 b- defN 23-Apr-28 08:25 mlflow/store/artifact/azure_blob_artifact_repo.py
+-rw-r--r--  2.0 unx     5829 b- defN 23-Apr-28 08:25 mlflow/store/artifact/azure_data_lake_artifact_repo.py
+-rw-r--r--  2.0 unx     5378 b- defN 23-Apr-28 08:25 mlflow/store/artifact/cli.py
+-rw-r--r--  2.0 unx    31773 b- defN 23-Apr-28 08:25 mlflow/store/artifact/databricks_artifact_repo.py
+-rw-r--r--  2.0 unx     6654 b- defN 23-Apr-28 08:25 mlflow/store/artifact/databricks_models_artifact_repo.py
+-rw-r--r--  2.0 unx    10247 b- defN 23-Apr-28 08:25 mlflow/store/artifact/dbfs_artifact_repo.py
+-rw-r--r--  2.0 unx     5234 b- defN 23-Apr-28 08:25 mlflow/store/artifact/ftp_artifact_repo.py
+-rw-r--r--  2.0 unx     5873 b- defN 23-Apr-28 08:25 mlflow/store/artifact/gcs_artifact_repo.py
+-rw-r--r--  2.0 unx     9684 b- defN 23-Apr-28 08:25 mlflow/store/artifact/hdfs_artifact_repo.py
+-rw-r--r--  2.0 unx     3377 b- defN 23-Apr-28 08:25 mlflow/store/artifact/http_artifact_repo.py
+-rw-r--r--  2.0 unx     5085 b- defN 23-Apr-28 08:25 mlflow/store/artifact/local_artifact_repo.py
+-rw-r--r--  2.0 unx     3001 b- defN 23-Apr-28 08:25 mlflow/store/artifact/mlflow_artifacts_repo.py
+-rw-r--r--  2.0 unx     6757 b- defN 23-Apr-28 08:25 mlflow/store/artifact/models_artifact_repo.py
+-rw-r--r--  2.0 unx     6016 b- defN 23-Apr-28 08:25 mlflow/store/artifact/runs_artifact_repo.py
+-rw-r--r--  2.0 unx     9442 b- defN 23-Apr-28 08:25 mlflow/store/artifact/s3_artifact_repo.py
+-rw-r--r--  2.0 unx     5455 b- defN 23-Apr-28 08:25 mlflow/store/artifact/sftp_artifact_repo.py
+-rw-r--r--  2.0 unx     5326 b- defN 23-Apr-28 08:25 mlflow/store/artifact/unity_catalog_models_artifact_repo.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/artifact/utils/__init__.py
+-rw-r--r--  2.0 unx     3934 b- defN 23-Apr-28 08:25 mlflow/store/artifact/utils/models.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/db/__init__.py
+-rw-r--r--  2.0 unx       71 b- defN 23-Apr-28 08:25 mlflow/store/db/base_sql_model.py
+-rw-r--r--  2.0 unx      221 b- defN 23-Apr-28 08:25 mlflow/store/db/db_types.py
+-rw-r--r--  2.0 unx    10592 b- defN 23-Apr-28 08:25 mlflow/store/db/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/__init__.py
+-rw-r--r--  2.0 unx     1634 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/alembic.ini
+-rw-r--r--  2.0 unx     2768 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/env.py
+-rw-r--r--  2.0 unx     1990 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/0a8213491aaa_drop_duplicate_killed_constraint.py
+-rw-r--r--  2.0 unx      462 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/0c779009ac13_add_deleted_time_field_to_runs_table.py
+-rw-r--r--  2.0 unx      924 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/181f10493468_allow_nulls_for_metric_values.py
+-rw-r--r--  2.0 unx     1059 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/27a6a02d2cf1_add_model_version_tags_table.py
+-rw-r--r--  2.0 unx     2624 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/2b4d017a5e9b_add_model_registry_tables_to_db.py
+-rw-r--r--  2.0 unx     1375 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/3500859a5d39_add_model_aliases_table.py
+-rw-r--r--  2.0 unx     1433 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/39d1c3be5f05_add_is_nan_constraint_for_metrics_tables_if_necessary.py
+-rw-r--r--  2.0 unx     1201 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/451aebb31d03_add_metric_step.py
+-rw-r--r--  2.0 unx      940 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/728d730b5ebd_add_registered_model_tags_table.py
+-rw-r--r--  2.0 unx     1014 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/7ac759974ad8_update_run_tags_with_larger_limit.py
+-rw-r--r--  2.0 unx      476 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/84291f40a231_add_run_link_to_model_version.py
+-rw-r--r--  2.0 unx     5716 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/89d4b8295536_create_latest_metrics_table.py
+-rw-r--r--  2.0 unx     1666 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/90e64c465722_migrate_user_column_to_tags.py
+-rw-r--r--  2.0 unx      577 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/97727af70f4d_creation_time_last_update_time_experiments.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/__init__.py
+-rw-r--r--  2.0 unx      582 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/a8c4a736bde6_allow_nulls_for_run_id.py
+-rw-r--r--  2.0 unx      637 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/bd07f7e963c5_create_index_on_run_uuid.py
+-rw-r--r--  2.0 unx     1295 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/c48cb773bb87_reset_default_value_for_is_nan_in_metrics_table_for_mysql.py
+-rw-r--r--  2.0 unx      684 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/cc1f77228345_change_param_value_length_to_500.py
+-rw-r--r--  2.0 unx     2830 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/cfd24bdc0731_update_run_status_constraint_with_killed.py
+-rw-r--r--  2.0 unx      904 b- defN 23-Apr-28 08:25 mlflow/store/db_migrations/versions/df50e92ffc5e_add_experiment_tags_table.py
+-rw-r--r--  2.0 unx       80 b- defN 23-Apr-28 08:25 mlflow/store/entities/__init__.py
+-rw-r--r--  2.0 unx      479 b- defN 23-Apr-28 08:25 mlflow/store/entities/paged_list.py
+-rw-r--r--  2.0 unx      605 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/__init__.py
+-rw-r--r--  2.0 unx    11022 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/abstract_store.py
+-rw-r--r--  2.0 unx     1330 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/base_rest_store.py
+-rw-r--r--  2.0 unx    38729 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/file_store.py
+-rw-r--r--  2.0 unx    16920 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/rest_store.py
+-rw-r--r--  2.0 unx    50457 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/sqlalchemy_store.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/dbmodels/__init__.py
+-rw-r--r--  2.0 unx     6341 b- defN 23-Apr-28 08:25 mlflow/store/model_registry/dbmodels/models.py
+-rw-r--r--  2.0 unx     1154 b- defN 23-Apr-28 08:25 mlflow/store/tracking/__init__.py
+-rw-r--r--  2.0 unx    13042 b- defN 23-Apr-28 08:25 mlflow/store/tracking/abstract_store.py
+-rw-r--r--  2.0 unx    46363 b- defN 23-Apr-28 08:25 mlflow/store/tracking/file_store.py
+-rw-r--r--  2.0 unx    12172 b- defN 23-Apr-28 08:25 mlflow/store/tracking/rest_store.py
+-rw-r--r--  2.0 unx    67230 b- defN 23-Apr-28 08:25 mlflow/store/tracking/sqlalchemy_store.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/store/tracking/dbmodels/__init__.py
+-rw-r--r--  2.0 unx     8315 b- defN 23-Apr-28 08:25 mlflow/store/tracking/dbmodels/initial_models.py
+-rw-r--r--  2.0 unx    15674 b- defN 23-Apr-28 08:25 mlflow/store/tracking/dbmodels/models.py
+-rw-r--r--  2.0 unx    57261 b- defN 23-Apr-28 08:25 mlflow/tensorflow/__init__.py
+-rw-r--r--  2.0 unx     8442 b- defN 23-Apr-28 08:25 mlflow/tensorflow/_autolog.py
+-rw-r--r--  2.0 unx      995 b- defN 23-Apr-28 08:25 mlflow/tracking/__init__.py
+-rw-r--r--  2.0 unx     7155 b- defN 23-Apr-28 08:25 mlflow/tracking/artifact_utils.py
+-rw-r--r--  2.0 unx   126036 b- defN 23-Apr-28 08:25 mlflow/tracking/client.py
+-rw-r--r--  2.0 unx    70974 b- defN 23-Apr-28 08:25 mlflow/tracking/fluent.py
+-rw-r--r--  2.0 unx     3404 b- defN 23-Apr-28 08:25 mlflow/tracking/llm_utils.py
+-rw-r--r--  2.0 unx     2248 b- defN 23-Apr-28 08:25 mlflow/tracking/metric_value_conversion_utils.py
+-rw-r--r--  2.0 unx     3515 b- defN 23-Apr-28 08:25 mlflow/tracking/registry.py
+-rw-r--r--  2.0 unx       41 b- defN 23-Apr-28 08:25 mlflow/tracking/_model_registry/__init__.py
+-rw-r--r--  2.0 unx    15534 b- defN 23-Apr-28 08:25 mlflow/tracking/_model_registry/client.py
+-rw-r--r--  2.0 unx     9364 b- defN 23-Apr-28 08:25 mlflow/tracking/_model_registry/fluent.py
+-rw-r--r--  2.0 unx     3152 b- defN 23-Apr-28 08:25 mlflow/tracking/_model_registry/registry.py
+-rw-r--r--  2.0 unx     7008 b- defN 23-Apr-28 08:25 mlflow/tracking/_model_registry/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/tracking/_tracking_service/__init__.py
+-rw-r--r--  2.0 unx    23690 b- defN 23-Apr-28 08:25 mlflow/tracking/_tracking_service/client.py
+-rw-r--r--  2.0 unx     2335 b- defN 23-Apr-28 08:25 mlflow/tracking/_tracking_service/registry.py
+-rw-r--r--  2.0 unx     9517 b- defN 23-Apr-28 08:25 mlflow/tracking/_tracking_service/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/tracking/context/__init__.py
+-rw-r--r--  2.0 unx     1076 b- defN 23-Apr-28 08:25 mlflow/tracking/context/abstract_context.py
+-rw-r--r--  2.0 unx      520 b- defN 23-Apr-28 08:25 mlflow/tracking/context/databricks_cluster_context.py
+-rw-r--r--  2.0 unx      561 b- defN 23-Apr-28 08:25 mlflow/tracking/context/databricks_command_context.py
+-rw-r--r--  2.0 unx     1965 b- defN 23-Apr-28 08:25 mlflow/tracking/context/databricks_job_context.py
+-rw-r--r--  2.0 unx     1713 b- defN 23-Apr-28 08:25 mlflow/tracking/context/databricks_notebook_context.py
+-rw-r--r--  2.0 unx     1952 b- defN 23-Apr-28 08:25 mlflow/tracking/context/databricks_repo_context.py
+-rw-r--r--  2.0 unx     1020 b- defN 23-Apr-28 08:25 mlflow/tracking/context/default_context.py
+-rw-r--r--  2.0 unx      898 b- defN 23-Apr-28 08:25 mlflow/tracking/context/git_context.py
+-rw-r--r--  2.0 unx     3738 b- defN 23-Apr-28 08:25 mlflow/tracking/context/registry.py
+-rw-r--r--  2.0 unx      443 b- defN 23-Apr-28 08:25 mlflow/tracking/context/system_environment_context.py
+-rw-r--r--  2.0 unx       28 b- defN 23-Apr-28 08:25 mlflow/tracking/default_experiment/__init__.py
+-rw-r--r--  2.0 unx     1703 b- defN 23-Apr-28 08:25 mlflow/tracking/default_experiment/abstract_context.py
+-rw-r--r--  2.0 unx     1718 b- defN 23-Apr-28 08:25 mlflow/tracking/default_experiment/databricks_job_experiment_provider.py
+-rw-r--r--  2.0 unx     2300 b- defN 23-Apr-28 08:25 mlflow/tracking/default_experiment/databricks_notebook_experiment_provider.py
+-rw-r--r--  2.0 unx     3173 b- defN 23-Apr-28 08:25 mlflow/tracking/default_experiment/registry.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-28 08:25 mlflow/tracking/request_header/__init__.py
+-rw-r--r--  2.0 unx     1077 b- defN 23-Apr-28 08:25 mlflow/tracking/request_header/abstract_request_header_provider.py
+-rw-r--r--  2.0 unx     1336 b- defN 23-Apr-28 08:25 mlflow/tracking/request_header/databricks_request_header_provider.py
+-rw-r--r--  2.0 unx      486 b- defN 23-Apr-28 08:25 mlflow/tracking/request_header/default_request_header_provider.py
+-rw-r--r--  2.0 unx     2867 b- defN 23-Apr-28 08:25 mlflow/tracking/request_header/registry.py
+-rw-r--r--  2.0 unx      299 b- defN 23-Apr-28 08:25 mlflow/types/__init__.py
+-rw-r--r--  2.0 unx    13334 b- defN 23-Apr-28 08:25 mlflow/types/schema.py
+-rw-r--r--  2.0 unx    17899 b- defN 23-Apr-28 08:25 mlflow/types/utils.py
+-rw-r--r--  2.0 unx     9389 b- defN 23-Apr-28 08:25 mlflow/utils/__init__.py
+-rw-r--r--  2.0 unx     6270 b- defN 23-Apr-28 08:25 mlflow/utils/_capture_modules.py
+-rw-r--r--  2.0 unx     6395 b- defN 23-Apr-28 08:25 mlflow/utils/_spark_utils.py
+-rw-r--r--  2.0 unx     4906 b- defN 23-Apr-28 08:25 mlflow/utils/annotations.py
+-rw-r--r--  2.0 unx      400 b- defN 23-Apr-28 08:25 mlflow/utils/arguments_utils.py
+-rw-r--r--  2.0 unx      215 b- defN 23-Apr-28 08:25 mlflow/utils/class_utils.py
+-rw-r--r--  2.0 unx     6431 b- defN 23-Apr-28 08:25 mlflow/utils/cli_args.py
+-rw-r--r--  2.0 unx    13002 b- defN 23-Apr-28 08:25 mlflow/utils/conda.py
+-rw-r--r--  2.0 unx      432 b- defN 23-Apr-28 08:25 mlflow/utils/data_utils.py
+-rw-r--r--  2.0 unx    21834 b- defN 23-Apr-28 08:25 mlflow/utils/databricks_utils.py
+-rw-r--r--  2.0 unx     9138 b- defN 23-Apr-28 08:25 mlflow/utils/docstring_utils.py
+-rw-r--r--  2.0 unx      192 b- defN 23-Apr-28 08:25 mlflow/utils/env.py
+-rw-r--r--  2.0 unx      474 b- defN 23-Apr-28 08:25 mlflow/utils/env_manager.py
+-rw-r--r--  2.0 unx    21930 b- defN 23-Apr-28 08:25 mlflow/utils/environment.py
+-rw-r--r--  2.0 unx    25967 b- defN 23-Apr-28 08:25 mlflow/utils/file_utils.py
+-rw-r--r--  2.0 unx     2306 b- defN 23-Apr-28 08:25 mlflow/utils/git_utils.py
+-rw-r--r--  2.0 unx    24166 b- defN 23-Apr-28 08:25 mlflow/utils/gorilla.py
+-rw-r--r--  2.0 unx     2597 b- defN 23-Apr-28 08:25 mlflow/utils/logging_utils.py
+-rw-r--r--  2.0 unx     1298 b- defN 23-Apr-28 08:25 mlflow/utils/mime_type_utils.py
+-rw-r--r--  2.0 unx     3839 b- defN 23-Apr-28 08:25 mlflow/utils/mlflow_tags.py
+-rw-r--r--  2.0 unx     6208 b- defN 23-Apr-28 08:25 mlflow/utils/model_utils.py
+-rw-r--r--  2.0 unx     5873 b- defN 23-Apr-28 08:25 mlflow/utils/name_utils.py
+-rw-r--r--  2.0 unx     2412 b- defN 23-Apr-28 08:25 mlflow/utils/nfs_on_spark.py
+-rw-r--r--  2.0 unx      139 b- defN 23-Apr-28 08:25 mlflow/utils/os.py
+-rw-r--r--  2.0 unx     5799 b- defN 23-Apr-28 08:25 mlflow/utils/process.py
+-rw-r--r--  2.0 unx    19923 b- defN 23-Apr-28 08:25 mlflow/utils/proto_json_utils.py
+-rw-r--r--  2.0 unx    18470 b- defN 23-Apr-28 08:25 mlflow/utils/requirements_utils.py
+-rw-r--r--  2.0 unx    16880 b- defN 23-Apr-28 08:25 mlflow/utils/rest_utils.py
+-rw-r--r--  2.0 unx    56769 b- defN 23-Apr-28 08:25 mlflow/utils/search_utils.py
+-rw-r--r--  2.0 unx     2368 b- defN 23-Apr-28 08:25 mlflow/utils/server_cli_utils.py
+-rw-r--r--  2.0 unx     3805 b- defN 23-Apr-28 08:25 mlflow/utils/string_utils.py
+-rw-r--r--  2.0 unx      512 b- defN 23-Apr-28 08:25 mlflow/utils/time_utils.py
+-rw-r--r--  2.0 unx    13915 b- defN 23-Apr-28 08:25 mlflow/utils/uri.py
+-rw-r--r--  2.0 unx    16024 b- defN 23-Apr-28 08:25 mlflow/utils/validation.py
+-rw-r--r--  2.0 unx    16452 b- defN 23-Apr-28 08:25 mlflow/utils/virtualenv.py
+-rw-r--r--  2.0 unx    25551 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/__init__.py
+-rw-r--r--  2.0 unx    15731 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/client.py
+-rw-r--r--  2.0 unx    10937 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/events.py
+-rw-r--r--  2.0 unx    13381 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/logging_and_warnings.py
+-rw-r--r--  2.0 unx    47266 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/safety.py
+-rw-r--r--  2.0 unx     3489 b- defN 23-Apr-28 08:25 mlflow/utils/autologging_utils/versioning.py
+-rw-r--r--  2.0 unx    13489 b- defN 23-Apr-28 08:25 mlflow/utils/import_hooks/__init__.py
+-rw-r--r--  2.0 unx    34313 b- defN 23-Apr-28 08:25 mlflow/xgboost/__init__.py
+-rw-r--r--  2.0 unx     2908 b- defN 23-Apr-28 08:25 mlflow/xgboost/_autolog.py
+-rw-r--r--  2.0 unx      521 b- defN 23-Apr-28 08:25 pylint_plugins/__init__.py
+-rw-r--r--  2.0 unx     2006 b- defN 23-Apr-28 08:25 pylint_plugins/errors.py
+-rw-r--r--  2.0 unx      856 b- defN 23-Apr-28 08:25 pylint_plugins/print_function.py
+-rw-r--r--  2.0 unx      571 b- defN 23-Apr-28 08:25 pylint_plugins/set_checker.py
+-rw-r--r--  2.0 unx      878 b- defN 23-Apr-28 08:25 pylint_plugins/string_checker.py
+-rw-r--r--  2.0 unx      692 b- defN 23-Apr-28 08:25 pylint_plugins/unittest_assert_raises.py
+-rw-r--r--  2.0 unx     1546 b- defN 23-Apr-28 08:25 pylint_plugins/pytest_raises_checker/__init__.py
+-rw-r--r--  2.0 unx    11382 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/LICENSE.txt
+-rw-r--r--  2.0 unx    12392 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       22 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    32890 b- defN 23-Apr-28 08:25 mlflow_skinny-2.3.1.dist-info/RECORD
+352 files, 10959534 bytes uncompressed, 4021384 bytes compressed:  63.3%
```

## zipnote {}

```diff
@@ -1032,26 +1032,26 @@
 
 Filename: pylint_plugins/unittest_assert_raises.py
 Comment: 
 
 Filename: pylint_plugins/pytest_raises_checker/__init__.py
 Comment: 
 
-Filename: mlflow_skinny-2.3.0.dist-info/LICENSE.txt
+Filename: mlflow_skinny-2.3.1.dist-info/LICENSE.txt
 Comment: 
 
-Filename: mlflow_skinny-2.3.0.dist-info/METADATA
+Filename: mlflow_skinny-2.3.1.dist-info/METADATA
 Comment: 
 
-Filename: mlflow_skinny-2.3.0.dist-info/WHEEL
+Filename: mlflow_skinny-2.3.1.dist-info/WHEEL
 Comment: 
 
-Filename: mlflow_skinny-2.3.0.dist-info/entry_points.txt
+Filename: mlflow_skinny-2.3.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: mlflow_skinny-2.3.0.dist-info/top_level.txt
+Filename: mlflow_skinny-2.3.1.dist-info/top_level.txt
 Comment: 
 
-Filename: mlflow_skinny-2.3.0.dist-info/RECORD
+Filename: mlflow_skinny-2.3.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mlflow/transformers.py

```diff
@@ -1,11 +1,14 @@
+import ast
 import json
 import logging
 import pathlib
 import pandas as pd
+import numpy as np
+import re
 from typing import Union, List, Optional, Dict, Any, NamedTuple
 
 import yaml
 
 import mlflow
 from mlflow import pyfunc
 from mlflow.exceptions import MlflowException
@@ -1318,15 +1321,15 @@
     return _TransformersWrapper(pipeline).predict(data)
 
 
 class _TransformersWrapper:
     def __init__(self, pipeline, flavor_config=None, inference_config=None):
         self.pipeline = pipeline
         self.flavor_config = flavor_config
-        self.inference_config = inference_config
+        self.inference_config = inference_config or {}
         self._conversation = None
         # NB: Current special-case custom pipeline types that have not been added to
         # the native-supported transformers package but require custom parsing:
         # InstructionTextGenerationPipeline [Dolly] https://huggingface.co/databricks/dolly-v2-12b
         #   (and all variants)
         self._supported_custom_generator_types = {"InstructionTextGenerationPipeline"}
 
@@ -1442,40 +1445,44 @@
         else:
             raise MlflowException(
                 f"The loaded pipeline type {type(self.pipeline).__name__} is "
                 "not enabled for pyfunc predict functionality.",
                 error_code=BAD_REQUEST,
             )
 
-        # Optional input preservation for specific pipeline types
-        include_prompt = (
-            self.inference_config.pop("include_prompt", False) if self.inference_config else False
-        )
+        # Optional input preservation for specific pipeline types. This is True (include raw
+        # formatting output), but if `include_prompt` is set to False in the `inference_config`
+        # option during model saving, excess newline characters and the fed-in prompt will be
+        # trimmed out from the start of the response.
+        include_prompt = self.inference_config.pop("include_prompt", True)
+        # Optional stripping out of `\n` for specific generator pipelines.
+        collapse_whitespace = self.inference_config.pop("collapse_whitespace", False)
+
+        data = self._convert_cast_lists_from_np_back_to_list(data)
 
         # Generate inference data with the pipeline object
         if isinstance(self.pipeline, transformers.ConversationalPipeline):
             conversation_output = self.pipeline(self._conversation)
             return conversation_output.generated_responses[-1]
         elif isinstance(data, dict):
-            if self.inference_config:
-                raw_output = self.pipeline(**data, **self.inference_config)
-            else:
-                raw_output = self.pipeline(**data)
+            raw_output = self.pipeline(**data, **self.inference_config)
         else:
-            if self.inference_config:
-                raw_output = self.pipeline(data, **self.inference_config)
-            else:
-                raw_output = self.pipeline(data)
+            raw_output = self.pipeline(data, **self.inference_config)
 
         # Handle the pipeline outputs
         if type(self.pipeline).__name__ in self._supported_custom_generator_types or isinstance(
             self.pipeline, transformers.TextGenerationPipeline
         ):
             output = self._strip_input_from_response_in_instruction_pipelines(
-                data, raw_output, output_key, self.flavor_config, include_prompt
+                data,
+                raw_output,
+                output_key,
+                self.flavor_config,
+                include_prompt,
+                collapse_whitespace,
             )
         elif isinstance(self.pipeline, transformers.FillMaskPipeline):
             output = self._parse_list_of_multiple_dicts(raw_output, output_key)
         elif isinstance(self.pipeline, transformers.ZeroShotClassificationPipeline):
             interim_output = self._parse_lists_of_dict_to_list_of_str(raw_output, output_key)
             output = self._parse_list_output_for_multiple_candidate_pipelines(interim_output)
         elif isinstance(self.pipeline, transformers.TokenClassificationPipeline):
@@ -1597,29 +1604,46 @@
                             error_code=INVALID_PARAMETER_VALUE,
                         )
                     if value != parsed[key]:
                         value_type = type(parsed[key])
                         if value_type == str:
                             parsed[key] = [parsed[key], value]
                         elif value_type == list:
-                            parsed[key] = parsed[key].append(value)
+                            if all(len(entry) == 1 for entry in value):
+                                # This conversion is required solely for model serving.
+                                # In the parsing logic that occurs internally, strings that
+                                # contain single quotes `'` result in casting to a List[char]
+                                # instead of a str type. Attempting to append a List[char]
+                                # to a List[str] as would happen in the `else` block here
+                                # results in the entire List being overwritten as `None` without
+                                # an Exception being raised. By checking for single value entries
+                                # and subsequently converting to list and extracting the first
+                                # element reconstructs the original input string.
+                                parsed[key].append([str(value)][0])
+                            else:
+                                parsed[key] = parsed[key].append(value)
                         else:
                             parsed[key] = value
             return parsed
         else:
             return data
 
     def _strip_input_from_response_in_instruction_pipelines(
-        self, input_data, output, output_key, flavor_config, include_prompt
+        self,
+        input_data,
+        output,
+        output_key,
+        flavor_config,
+        include_prompt=True,
+        collapse_whitespace=False,
     ):
         """
         Parse the output from instruction pipelines to conform with other text generator
         pipeline types and remove line feed characters and other confusing outputs
         """
-        replacements = {"\n\n": " "}
 
         def extract_response_data(data_out):
             if all(isinstance(x, dict) for x in data_out):
                 return [elem[output_key] for elem in data_out][0]
             elif all(isinstance(x, list) for x in data_out):
                 return [elem[output_key] for coll in data_out for elem in coll]
             else:
@@ -1631,31 +1655,35 @@
         output = extract_response_data(output)
 
         def trim_input(data_in, data_out):
             # NB: the '\n\n' pattern is exclusive to specific InstructionalTextGenerationPipeline
             # types that have been loaded as a plain TextGenerator. The structure of these
             # pipelines will precisely repeat the input question immediately followed by 2 carriage
             # return statements, followed by the start of the response to the prompt. We only
-            # want to left-trim these types of pipelines output values if the user hasn't disabled
-            # the removal action of the input prompt in the returned str or List[str]
+            # want to left-trim these types of pipelines output values if the user has indicated
+            # the removal action of the input prompt in the returned str or List[str] by applying
+            # the optional inference_config entry of `{"include_prompt": False}`.
+            # By default, the prompt is included in the response.
+            # Stripping out additional carriage returns (\n) is another additional optional flag
+            # that can be set for these generator pipelines. It is off by default (False).
             if (
-                data_out.startswith(data_in + "\n\n")
+                not include_prompt
                 and flavor_config[_INSTANCE_TYPE_KEY] in self._supported_custom_generator_types
+                and data_out.startswith(data_in + "\n\n")
             ):
-                # If the user has indicated to preserve the prompt input in the response, do not
-                # split the response output or trim any portions of the response string
-                if not include_prompt:
-                    data_out = data_out[len(data_in) :].lstrip()
-                    if data_out.startswith("A:"):
-                        data_out = data_out[2:].lstrip()
-                for to_replace, replace in replacements.items():
-                    data_out = data_out.replace(to_replace, replace)
-                return data_out
-            else:
-                return data_out
+                # If the user has indicated to not preserve the prompt input in the response,
+                # split the response output and trim the input prompt from the response.
+                data_out = data_out[len(data_in) :].lstrip()
+                if data_out.startswith("A:"):
+                    data_out = data_out[2:].lstrip()
+                # If the user has indicated to remove newlines and extra spaces from the generated
+                # text, replace them with a single space.
+            if collapse_whitespace:
+                data_out = re.sub(r"\s+", " ", data_out).strip()
+            return data_out
 
         if isinstance(input_data, list) and isinstance(output, list):
             return [trim_input(data_in, data_out) for data_in, data_out in zip(input_data, output)]
         elif isinstance(input_data, str) and isinstance(output, str):
             return trim_input(input_data, output)
         else:
             raise MlflowException(
@@ -1887,14 +1915,50 @@
                         if key == key_to_unpack and isinstance(value, str)
                         else value
                     )
                     for key, value in entry.items()
                 }
                 for entry in data
             ]
+        elif isinstance(data, dict):
+            # This is to handle serving use cases as the DataFrame encapsulation converts
+            # collections within rows to np.array type. In order to process this data through
+            # the transformers.Pipeline API, we need to cast these arrays back to lists
+            # and replace the single quotes with double quotes after extracting the
+            # json-encoded `table` (a pandas DF) in order to convert it to a dict that
+            # the TableQuestionAnsweringPipeline can accept and cast to a Pandas DataFrame.
+            #
+            # An example casting that occurs for this case when input to model serving is the
+            # conversion of a user input of:
+            #   '{"inputs": {"query": "What is the longest distance?",
+            #                "table": {"Distance": ["1000", "10", "1"]}}}'
+            # is converted to:
+            #   [{'query': array('What is the longest distance?', dtype='<U29'),
+            #     'table': array('{\'Distance\': [\'1000\', \'10\', \'1\']}', dtype='U<204')}]
+            # which is an invalid input to the pipeline.
+            # this method converts the input to:
+            #   {'query': 'What is the longest distance?',
+            #    'table': {'Distance': ['1000', '10', '1']}}
+            # which is a valid input to the TableQuestionAnsweringPipeline.
+            output = {}
+            for key, value in data.items():
+                if key == key_to_unpack:
+                    if isinstance(value, np.ndarray):
+                        output[key] = ast.literal_eval(value.item())
+                    else:
+                        output[key] = ast.literal_eval(value)
+                else:
+                    if isinstance(value, np.ndarray):
+                        # This cast to np.ndarray occurs when more than one question is asked.
+                        output[key] = value.item()
+                    else:
+                        # Otherwise, the entry does not need casting from a np.ndarray type to
+                        # list as it is already a scalar string.
+                        output[key] = value
+            return output
         else:
             return {
                 key: (
                     json.loads(value) if key == key_to_unpack and isinstance(value, str) else value
                 )
                 for key, value in data.items()
             }
@@ -1908,7 +1972,29 @@
                 error_code=INVALID_PARAMETER_VALUE,
             )
         elif isinstance(data, list) and not all(isinstance(entry, str) for entry in data):
             raise MlflowException(
                 "If supplying a list, all values must be of string type.",
                 error_code=INVALID_PARAMETER_VALUE,
             )
+
+    @staticmethod
+    def _convert_cast_lists_from_np_back_to_list(data):
+        """
+        This handles the casting of dicts within lists from Pandas DF conversion within model
+        serving back into the required Dict[str, List[str]] if this type matching occurs.
+        Otherwise, it's a noop.
+        """
+        if not isinstance(data, list):
+            # NB: applying a short-circuit return here to not incur runtime overhead with
+            # type validation if the input is not a list
+            return data
+        elif not all(isinstance(value, dict) for value in data):
+            return data
+        else:
+            parsed_data = []
+            for entry in data:
+                if all(isinstance(value, np.ndarray) for value in entry.values()):
+                    parsed_data.append({key: value.tolist() for key, value in entry.items()})
+                else:
+                    parsed_data.append(entry)
+            return parsed_data
```

## mlflow/version.py

```diff
@@ -1,9 +1,9 @@
 # Copyright 2018 Databricks, Inc.
 import re
 
 
-VERSION = "2.3.0"
+VERSION = "2.3.1"
 
 
 def is_release_version():
     return bool(re.match(r"^\d+\.\d+\.\d+$", VERSION))
```

## mlflow/artifacts/__init__.py

```diff
@@ -5,15 +5,19 @@
 import pathlib
 import tempfile
 from typing import Optional
 
 from mlflow.exceptions import MlflowException
 from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE, BAD_REQUEST
 from mlflow.tracking import _get_store
-from mlflow.tracking.artifact_utils import _download_artifact_from_uri, get_artifact_repository
+from mlflow.tracking.artifact_utils import (
+    _download_artifact_from_uri,
+    get_artifact_repository,
+    add_databricks_profile_info_to_artifact_uri,
+)
 
 
 def download_artifacts(
     artifact_uri: Optional[str] = None,
     run_id: Optional[str] = None,
     artifact_path: Optional[str] = None,
     dst_path: Optional[str] = None,
@@ -55,15 +59,17 @@
     if artifact_uri is not None:
         return _download_artifact_from_uri(artifact_uri, output_path=dst_path)
 
     artifact_path = artifact_path if artifact_path is not None else ""
 
     store = _get_store(store_uri=tracking_uri)
     artifact_uri = store.get_run(run_id).info.artifact_uri
-    artifact_repo = get_artifact_repository(artifact_uri)
+    artifact_repo = get_artifact_repository(
+        add_databricks_profile_info_to_artifact_uri(artifact_uri, tracking_uri)
+    )
     artifact_location = artifact_repo.download_artifacts(artifact_path, dst_path=dst_path)
     return artifact_location
 
 
 def load_text(artifact_uri: str) -> str:
     """
     Loads the artifact contents as a string.
```

## mlflow/langchain/__init__.py

```diff
@@ -225,15 +225,15 @@
     pip_requirements=None,
     extra_pip_requirements=None,
     metadata=None,
 ):
     """
     Log a LangChain model as an MLflow artifact for the current run.
 
-    :param pr_model: LangChain model to be saved.
+    :param lc_model: LangChain model to be saved.
     :param artifact_path: Run-relative artifact path.
     :param conda_env: {{ conda_env }}
     :param code_paths: A list of local filesystem paths to Python file dependencies (or directories
                        containing file dependencies). These files are *prepended* to the system
                        path when the model is loaded.
 
     :param registered_model_name: This argument may change or be removed in a
```

## mlflow/langchain/api_request_parallel_processor.py

```diff
@@ -15,14 +15,15 @@
 - Logs errors, to diagnose problems with requests
 """
 from __future__ import annotations
 
 import logging
 import threading
 import queue
+import time
 from dataclasses import dataclass
 from concurrent.futures import ThreadPoolExecutor
 
 import langchain
 import mlflow
 
 _logger = logging.getLogger(__name__)
@@ -128,14 +129,16 @@
                 )
                 next_request = None  # reset next_request to empty
 
             # if all tasks are finished, break
             if status_tracker.num_tasks_in_progress == 0:
                 break
 
+            time.sleep(0.001)  # avoid busy waiting
+
         # after finishing, log final status
         if status_tracker.num_tasks_failed > 0:
             raise mlflow.MlflowException(
                 f"{status_tracker.num_tasks_failed} tasks failed. See logs for details."
             )
 
         return [res for _, res in sorted(results)]
```

## mlflow/models/__init__.py

```diff
@@ -1,25 +1,36 @@
 """
 The ``mlflow.models`` module provides an API for saving machine learning models in
 "flavors" that can be understood by different downstream tools.
 
 The built-in flavors are:
 
-- :py:mod:`mlflow.pyfunc`
+- :py:mod:`mlflow.catboost`
+- :py:mod:`mlflow.diviner`
+- :py:mod:`mlflow.fastai`
+- :py:mod:`mlflow.gluon`
 - :py:mod:`mlflow.h2o`
+- :py:mod:`mlflow.langchain`
 - :py:mod:`mlflow.lightgbm`
+- :py:mod:`mlflow.mleap`
+- :py:mod:`mlflow.onnx`
+- :py:mod:`mlflow.openai`
+- :py:mod:`mlflow.paddle`
+- :py:mod:`mlflow.pmdarima`
+- :py:mod:`mlflow.prophet`
+- :py:mod:`mlflow.pyfunc`
+- :py:mod:`mlflow.pyspark.ml`
 - :py:mod:`mlflow.pytorch`
 - :py:mod:`mlflow.sklearn`
+- :py:mod:`mlflow.spacy`
 - :py:mod:`mlflow.spark`
 - :py:mod:`mlflow.statsmodels`
 - :py:mod:`mlflow.tensorflow`
+- :py:mod:`mlflow.transformers`
 - :py:mod:`mlflow.xgboost`
-- :py:mod:`mlflow.spacy`
-- :py:mod:`mlflow.fastai`
-- :py:mod:`mlflow.paddle`
 
 For details, see `MLflow Models <../models.html>`_.
 """
 
 from .model import Model, get_model_info
 from .flavor_backend import FlavorBackend
 from ..utils.environment import infer_pip_requirements
```

## mlflow/models/utils.py

```diff
@@ -608,25 +608,46 @@
 
     For column-based signatures, we make sure the types of the input match the type specified in
     the schema or if it can be safely converted to match the input schema.
 
     For tensor-based signatures, we make sure the shape and type of the input matches the shape
     and type specified in model's input schema.
     """
+
+    def _is_scalar(x):
+        return np.isscalar(x) or x is None
+
     if isinstance(pf_input, pd.Series):
         pf_input = pd.DataFrame(pf_input)
     if not input_schema.is_tensor_spec():
         if isinstance(pf_input, (list, np.ndarray, dict, pd.Series, str)):
             try:
-                if isinstance(pf_input, dict) and all(
-                    not isinstance(value, (dict, list)) for value in pf_input.values()
+                if isinstance(pf_input, str):
+                    pf_input = pd.DataFrame([pf_input])
+                elif isinstance(pf_input, dict) and all(
+                    _is_scalar(value) for value in pf_input.values()
+                ):
+                    pf_input = pd.DataFrame([pf_input])
+                elif isinstance(pf_input, dict) and all(
+                    isinstance(value, np.ndarray)
+                    and value.dtype.type == np.str_
+                    and value.size == 1
+                    and value.shape == ()
+                    for value in pf_input.values()
                 ):
-                    pf_input = pd.DataFrame(pf_input, index=[0])
-                elif isinstance(pf_input, str):
-                    pf_input = pd.DataFrame({"inputs": pf_input}, index=[0])
+                    # This check is specifically to handle the serving structural cast for
+                    # certain inputs for the transformers implementation. Due to the fact that
+                    # specific Pipeline types in transformers support passing input data
+                    # of the form Dict[str, str] in which the value is a scalar string, model
+                    # serving will cast this entry as a numpy array with shape () and size 1.
+                    # This is seen as a scalar input when attempting to create a Pandas DataFrame
+                    # from such a numpy structure and requires the array to be encapsulated in a
+                    # list in order to prevent a ValueError exception for requiring an index
+                    # if passing in all scalar values thrown by Pandas.
+                    pf_input = pd.DataFrame([pf_input])
                 else:
                     pf_input = pd.DataFrame(pf_input)
             except Exception as e:
                 raise MlflowException(
                     "This model contains a column-based signature, which suggests a DataFrame"
                     " input. There was an error casting the input data to a DataFrame:"
                     " {}".format(str(e))
```

## mlflow/models/container/__init__.py

```diff
@@ -122,15 +122,15 @@
                 os.symlink(path, "/opt/activate")
                 activate_cmd = [env_activate_cmd]
 
     # NB: install gunicorn[gevent] from pip rather than from conda because gunicorn is already
     # dependency of mlflow on pip and we expect mlflow to be part of the environment.
     server_deps = ["gunicorn[gevent]"]
     if enable_mlserver:
-        server_deps = ["'mlserver>=1.2.0, <1.3'", "'mlserver-mlflow>=1.2.0, <1.3'"]
+        server_deps = ["'mlserver>=1.2.0,!=1.3.1'", "'mlserver-mlflow>=1.2.0,!=1.3.1'"]
 
     install_server_deps = [f"pip install {' '.join(server_deps)}"]
     if Popen(["bash", "-c", " && ".join(activate_cmd + install_server_deps)]).wait() != 0:
         raise Exception("Failed to install serving dependencies into the model environment.")
 
     if len(activate_cmd) and install_mlflow:
         install_mlflow_cmd = [
```

## mlflow/openai/__init__.py

```diff
@@ -5,19 +5,19 @@
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 When this flavor logs a model on Databricks, it saves a YAML file with the following contents as
 ``openai.yaml`` if the ``MLFLOW_OPENAI_SECRET_SCOPE`` environment variable is set.
 
 .. code-block:: yaml
 
-    OPENAI_API_BASE: test:openai_api_base
-    OPENAI_API_KEY: test:openai_api_key
-    OPENAI_API_KEY_PATH: test:openai_api_key_path
-    OPENAI_API_TYPE: test:openai_api_type
-    OPENAI_ORGANIZATION: test:openai_organization
+    OPENAI_API_BASE: {scope}:openai_api_base
+    OPENAI_API_KEY: {scope}:openai_api_key
+    OPENAI_API_KEY_PATH: {scope}:openai_api_key_path
+    OPENAI_API_TYPE: {scope}:openai_api_type
+    OPENAI_ORGANIZATION: {scope}:openai_organization
 
 - ``{scope}`` is the value of the ``MLFLOW_OPENAI_SECRET_SCOPE`` environment variable.
 - The keys are the environment variables that the ``openai-python`` package uses to
   configure the API client.
 - The values are the references to the secrets that store the values of the environment
   variables.
 
@@ -25,14 +25,16 @@
 corresponding environment variable. See https://docs.databricks.com/security/secrets/index.html
 for how to set up secrets on Databricks.
 """
 import os
 import yaml
 import logging
 from enum import Enum
+from string import Formatter
+import itertools
 
 import mlflow
 from mlflow import pyfunc
 from mlflow.models import Model, ModelInputExample
 from mlflow.models.model import MLMODEL_FILE_NAME
 from mlflow.models.signature import ModelSignature
 from mlflow.models.utils import _save_example
@@ -150,49 +152,84 @@
         return _class_to_task(task)
     else:
         raise mlflow.MlflowException(
             f"Unsupported task type: {type(task)}", error_code=INVALID_PARAMETER_VALUE
         )
 
 
-def get_openai_package_version():
+def _get_openai_package_version():
     import openai
 
     try:
         return openai.__version__
     except AttributeError:
         # openai < 0.27.5 doesn't have a __version__ attribute
         return openai.version.VERSION
 
 
 # See https://github.com/openai/openai-python/blob/cf03fe16a92cd01f2a8867537399c12e183ba58e/openai/__init__.py#L30-L38
 # for the list of environment variables that openai-python uses
-class OpenAIEnvVar(str, Enum):
+class _OpenAIEnvVar(str, Enum):
     OPENAI_API_TYPE = "OPENAI_API_TYPE"
     OPENAI_API_BASE = "OPENAI_API_BASE"
     OPENAI_API_KEY = "OPENAI_API_KEY"
     OPENAI_API_KEY_PATH = "OPENAI_API_KEY_PATH"
     OPENAI_ORGANIZATION = "OPENAI_ORGANIZATION"
 
     @property
     def secret_key(self):
         return self.value.lower()
 
     @classmethod
     def read_environ(cls):
         env_vars = {}
-        for e in OpenAIEnvVar:
+        for e in _OpenAIEnvVar:
             if value := os.getenv(e.value):
                 env_vars[e.value] = value
         return env_vars
 
 
 def _log_secrets_yaml(local_model_dir, scope):
     with open(os.path.join(local_model_dir, "openai.yaml"), "w") as f:
-        yaml.safe_dump({e.value: f"{scope}:{e.secret_key}" for e in OpenAIEnvVar}, f)
+        yaml.safe_dump({e.value: f"{scope}:{e.secret_key}" for e in _OpenAIEnvVar}, f)
+
+
+def _parse_format_fields(s):
+    """
+    Parses format fields from a given string, e.g. "Hello {name}" -> ["name"].
+    """
+    return [fn for _, fn, _, _ in Formatter().parse(s) if fn is not None]
+
+
+def _parse_variables(messages):
+    """
+    Parses variables from a list of messages for chat completion task. For example, if
+    messages = [{"content": "{x}", ...}, {"content": "{y}", ...}], then _parse_variables(messages)
+    returns ["x", "y"].
+    """
+    return sorted(
+        set(
+            itertools.chain.from_iterable(
+                _parse_format_fields(message.get("content")) for message in messages
+            )
+        )
+    )
+
+
+def _get_input_schema(messages):
+    if messages:
+        variables = _parse_variables(messages)
+        if len(variables) == 1:
+            return Schema([ColSpec(type="string")])
+        elif len(variables) > 1:
+            return Schema([ColSpec(name=v, type="string") for v in variables])
+        else:
+            return Schema([ColSpec(type="string")])
+    else:
+        return Schema([ColSpec(type="string")])
 
 
 @experimental
 @format_docstring(LOG_MODEL_PARAM_DOCS.format(package_name=FLAVOR_NAME))
 def save_model(
     model,
     task,
@@ -242,32 +279,42 @@
                           base64-encoded.
     :param pip_requirements: {{ pip_requirements }}
     :param extra_pip_requirements: {{ extra_pip_requirements }}
     :param metadata: Custom metadata dictionary passed to the model and stored in the MLmodel file.
 
                      .. Note:: Experimental: This parameter may change or be removed in a future
                                              release without warning.
-    :param  kwargs: Keyword arguments specific to the OpenAI task, such as the ``temperature`` or
-                    or ``top_p`` value to use for chat completion.
+    :param  kwargs:
+        Keyword arguments specific to the OpenAI task, such as the ``messages`` (see
+        :ref:`mlflow.openai.messages` for more details on this parameter)
+        or ``top_p`` value to use for chat completion.
     """
     _validate_env_arguments(conda_env, pip_requirements, extra_pip_requirements)
     path = os.path.abspath(path)
     _validate_and_prepare_target_save_path(path)
     code_dir_subpath = _validate_and_copy_code_paths(code_paths, path)
     task = _get_task_name(task)
 
     if mlflow_model is None:
         mlflow_model = Model()
+
     if signature is not None:
         mlflow_model.signature = signature
     elif task == "chat.completions":
+        messages = kwargs.get("messages", [])
+        if messages and not (
+            all(isinstance(m, dict) for m in messages) and all(map(_has_content_and_role, messages))
+        ):
+            raise mlflow.MlflowException.invalid_parameter_value(
+                "If `messages` is provided, it must be a list of dictionaries with keys "
+                "'role' and 'content'."
+            )
+
         mlflow_model.signature = ModelSignature(
-            inputs=Schema(
-                [ColSpec(type="string", name="role"), ColSpec(type="string", name="content")],
-            ),
+            inputs=_get_input_schema(messages),
             outputs=Schema([ColSpec(type="string", name=None)]),
         )
     if input_example is not None:
         _save_example(mlflow_model, input_example, path)
     if metadata is not None:
         mlflow_model.metadata = metadata
     model_data_path = os.path.join(path, MODEL_FILENAME)
@@ -286,15 +333,15 @@
             data=MODEL_FILENAME,
             conda_env=_CONDA_ENV_FILE_NAME,
             python_env=_PYTHON_ENV_FILE_NAME,
             code=code_dir_subpath,
         )
     mlflow_model.add_flavor(
         FLAVOR_NAME,
-        openai_version=get_openai_package_version(),
+        openai_version=_get_openai_package_version(),
         data=MODEL_FILENAME,
         code=code_dir_subpath,
     )
     mlflow_model.save(os.path.join(path, MLMODEL_FILE_NAME))
 
     if is_in_databricks_runtime():
         if scope := MLFLOW_OPENAI_SECRET_SCOPE.get():
@@ -389,21 +436,22 @@
                           serialized to json using the Pandas split-oriented format. Bytes are
                           base64-encoded.
     :param await_registration_for: Number of seconds to wait for the model version to finish
                             being created and is in ``READY`` status. By default, the function
                             waits for five minutes. Specify 0 or None to skip waiting.
     :param pip_requirements: {{ pip_requirements }}
     :param extra_pip_requirements: {{ extra_pip_requirements }}
-    :param model_format: File format in which the model is to be saved.
     :param metadata: Custom metadata dictionary passed to the model and stored in the MLmodel file.
 
                      .. Note:: Experimental: This parameter may change or be removed in a future
                                              release without warning.
-    :param  kwargs: Keyword arguments specific to the OpenAI task, such as the ``temperature`` or
-                    or ``top_p`` value to use for chat completion.
+    :param  kwargs:
+        Keyword arguments specific to the OpenAI task, such as the ``messages`` (see
+        :ref:`mlflow.openai.messages` for more details on this parameter)
+        or ``top_p`` value to use for chat completion.
     :return: A :py:class:`ModelInfo <mlflow.models.model.ModelInfo>` instance that contains the
              metadata of the logged model.
     """
     return Model.log(
         artifact_path=artifact_path,
         flavor=mlflow.openai,
         registered_model_name=registered_model_name,
@@ -426,55 +474,80 @@
         return yaml.safe_load(f)
 
 
 def _has_content_and_role(d):
     return "content" in d and "role" in d
 
 
+class _FormattableMessage:
+    def __init__(self, message):
+        self.content = message.get("content")
+        self.role = message.get("role")
+        self.variables = _parse_format_fields(self.content)
+
+    def format(self, **params):
+        if missing_params := set(self.variables) - set(params):
+            raise mlflow.MlflowException.invalid_parameter_value(
+                f"Expected parameters {self.variables} to be provided, "
+                f"only got {list(params)}, {list(missing_params)} are missing."
+            )
+        return {
+            "role": self.role,
+            "content": self.content.format(**{v: params[v] for v in self.variables}),
+        }
+
+
 class _OpenAIWrapper:
     def __init__(self, model):
         if model["task"] != "chat.completions":
             raise mlflow.MlflowException.invalid_parameter_value(
                 "Currently, only 'chat.completions' task is supported",
             )
         self.model = model
+        self.messages = self.model.get("messages", [])
+        self.variables = _parse_variables(self.messages)
+        self.formattable_messages = [_FormattableMessage(m) for m in self.messages]
+
+    def format_messages(self, params_list):
+        return [[m.format(**params) for m in self.formattable_messages] for params in params_list]
+
+    def get_params_list(self, data):
+        if len(self.variables) == 1:
+            variable = self.variables[0]
+            if variable in data.columns:
+                return data[[variable]].to_dict(orient="records")
+            else:
+                iter_string_columns = (c for c, v in data.iloc[0].items() if isinstance(v, str))
+                first_string_column = next(iter_string_columns)
+                return [{variable: s} for s in data[first_string_column]]
+        else:
+            return data[self.variables].to_dict(orient="records")
 
     def predict(self, data):
-        import pandas as pd
         from mlflow.openai.api_request_parallel_processor import process_api_requests
 
-        if isinstance(data, pd.DataFrame):
-            if "content" not in data or "role" not in data:
-                raise mlflow.MlflowException.invalid_parameter_value(
-                    "Input dataframe must contain columns 'content' and 'role'",
-                )
-            messages = data.to_dict(orient="records")
-        elif isinstance(data, list) and all(isinstance(d, dict) for d in data):
-            if not all(map(_has_content_and_role, data)):
-                raise mlflow.MlflowException.invalid_parameter_value(
-                    "Input list of dictionaries must contain keys 'content' and 'role'",
-                )
-            messages = data
+        if self.variables:
+            messages_list = self.format_messages(self.get_params_list(data))
         else:
-            raise mlflow.MlflowException.invalid_parameter_value(
-                "Input must be a pandas DataFrame or a list of dictionaries with keys "
-                "'content' and 'role'",
-            )
+            iter_string_columns = (c for c, v in data.iloc[0].items() if isinstance(v, str))
+            first_string_column = next(iter_string_columns)
+            messages_list = [
+                [*self.messages, {"role": "user", "content": s}] for s in data[first_string_column]
+            ]
 
         model_dict = self.model.copy()
         model_dict.pop("task", None)
-        prompt_messages = model_dict.pop("messages", [])
         requests = [
             {
                 **model_dict,
-                "messages": [*prompt_messages, message],
+                "messages": messages,
             }
-            for message in messages
+            for messages in messages_list
         ]
-        if OpenAIEnvVar.OPENAI_API_KEY.value not in os.environ:
+        if _OpenAIEnvVar.OPENAI_API_KEY.value not in os.environ:
             raise mlflow.MlflowException(
                 "OpenAI API key must be set in the OPENAI_API_KEY environment variable."
             )
         results = process_api_requests(requests)
         return [r["choices"][0]["message"]["content"] for r in results]
```

## mlflow/openai/api_request_parallel_processor.py

```diff
@@ -204,14 +204,16 @@
 
     # initialize available capacity counts
     available_request_capacity = max_requests_per_minute
     available_token_capacity = max_tokens_per_minute
     last_update_time = time.time()
     results: list[tuple[int, OpenAIObject]] = []
     requests_iter = enumerate(requests)
+    last_index = len(requests) - 1
+    requests_exhausted = False
     with ThreadPoolExecutor(max_workers=max_workers) as executor:
         while True:
             # get next request (if one is not already waiting for capacity)
             if next_request is None:
                 if not retry_queue.empty():
                     next_request = retry_queue.get_nowait()
                     _logger.warning(f"Retrying request {next_request.index}: {next_request}")
@@ -224,14 +226,15 @@
                         token_consumption=num_tokens_consumed_from_request(
                             request_json, "chat/completions", token_encoding_name
                         ),
                         attempts_left=max_attempts,
                         results=results,
                     )
                     status_tracker.start_task()
+                    requests_exhausted = index == last_index
 
             # update available capacity
             current_time = time.time()
             seconds_since_update = current_time - last_update_time
             available_request_capacity = min(
                 available_request_capacity
                 + int(max_requests_per_minute * seconds_since_update / 60.0),
@@ -261,15 +264,15 @@
                         next_request.call_api,
                         retry_queue=retry_queue,
                         status_tracker=status_tracker,
                     )
                     next_request = None  # reset next_request to empty
 
             # if all tasks are finished, break
-            if status_tracker.num_tasks_in_progress == 0:
+            if requests_exhausted and status_tracker.num_tasks_in_progress == 0:
                 break
 
             # if a rate limit error was hit recently, pause to cool down
             seconds_since_rate_limit_error = (
                 time.time() - status_tracker.time_of_last_rate_limit_error
             )
             if seconds_since_rate_limit_error < seconds_to_pause_after_rate_limit_error:
@@ -279,19 +282,21 @@
                 _logger.warning(
                     "Encountered rate limit error. Pausing to cool down for "
                     f"{remaining_seconds_to_pause} seconds..."
                 )
                 time.sleep(remaining_seconds_to_pause)
                 # ^e.g., if pause is 15 seconds and final limit was hit 5 seconds ago
 
-        # after finishing, log final status
-        if status_tracker.num_tasks_failed > 0:
-            raise mlflow.MlflowException(
-                f"{status_tracker.num_tasks_failed} tasks failed. See logs for details."
-            )
-        if status_tracker.num_rate_limit_errors > 0:
-            _logger.warning(
-                f"{status_tracker.num_rate_limit_errors} rate limit errors received. "
-                "Consider running at a lower rate."
-            )
+            time.sleep(0.001)  # avoid busy waiting
+
+    # after finishing, log final status
+    if status_tracker.num_tasks_failed > 0:
+        raise mlflow.MlflowException(
+            f"{status_tracker.num_tasks_failed} tasks failed. See logs for details."
+        )
+    if status_tracker.num_rate_limit_errors > 0:
+        _logger.warning(
+            f"{status_tracker.num_rate_limit_errors} rate limit errors received. "
+            "Consider running at a lower rate."
+        )
 
-        return [res for _, res in sorted(results)]
+    return [res for _, res in sorted(results)]
```

## mlflow/openai/utils.py

```diff
@@ -1,8 +1,9 @@
 import json
+import re
 import requests
 from unittest import mock
 from contextlib import contextmanager
 
 
 TEST_CONTENT = "test"
 
@@ -10,24 +11,24 @@
 class _MockResponse:
     def __init__(self, status_code, json_data):
         self.status_code = status_code
         self.content = json.dumps(json_data).encode()
         self.headers = {"Content-Type": "application/json"}
 
 
-def _chat_completion_json_sample():
+def _chat_completion_json_sample(content):
     # https://platform.openai.com/docs/api-reference/chat/create
     return {
         "id": "chatcmpl-123",
         "object": "chat.completion",
         "created": 1677652288,
         "choices": [
             {
                 "index": 0,
-                "message": {"role": "assistant", "content": TEST_CONTENT},
+                "message": {"role": "assistant", "content": content},
                 "finish_reason": "stop",
                 "text": TEST_CONTENT,
             }
         ],
         "usage": {"prompt_tokens": 9, "completion_tokens": 12, "total_tokens": 21},
     }
 
@@ -38,16 +39,16 @@
         "id": "gpt-3.5-turbo",
         "object": "model",
         "owned_by": "openai",
         "permission": [],
     }
 
 
-def _mock_chat_completion_response():
-    return _MockResponse(200, _chat_completion_json_sample())
+def _mock_chat_completion_response(content=TEST_CONTENT):
+    return _MockResponse(200, _chat_completion_json_sample(content))
 
 
 def _mock_models_retrieve_response():
     return _MockResponse(200, _models_retrieve_json_sample())
 
 
 @contextmanager
@@ -61,13 +62,14 @@
 
     def request(*args, **kwargs):
         if len(args) > 2:
             url = args[2]
         else:
             url = kwargs.get("url")
 
-        if "chat/completions" in url:
-            return _mock_chat_completion_response()
+        if re.match(r"^https://api\.openai\.com/v\d+/chat/completions$", url):
+            messages = json.loads(kwargs.get("data")).get("messages")
+            return _mock_chat_completion_response(content=json.dumps(messages))
         else:
             return original(*args, **kwargs)
 
     return _mock_request(new=request)
```

## mlflow/protos/databricks_uc_registry_messages_pb2.py

```diff
@@ -13,15 +13,15 @@
 _sym_db = _symbol_database.Default()
 
 
 from .scalapb import scalapb_pb2 as scalapb_dot_scalapb__pb2
 from . import databricks_pb2 as databricks__pb2
 
 
-DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n%databricks_uc_registry_messages.proto\x12\x16mlflow.ucmodelregistry\x1a\x15scalapb/scalapb.proto\x1a\x10\x64\x61tabricks.proto\"\x81\x01\n\x0fRegisteredModel\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x02 \x01(\x03\x12\x1e\n\x16last_updated_timestamp\x18\x03 \x01(\x03\x12\x0f\n\x07user_id\x18\x04 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x05 \x01(\t\"\xd8\x02\n\x0cModelVersion\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x03 \x01(\x03\x12\x1e\n\x16last_updated_timestamp\x18\x04 \x01(\x03\x12\x0f\n\x07user_id\x18\x05 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x06 \x01(\t\x12\x0e\n\x06source\x18\x07 \x01(\t\x12\x0e\n\x06run_id\x18\x08 \x01(\t\x12\x19\n\x11run_experiment_id\x18\t \x01(\t\x12\x1e\n\x16run_tracking_server_id\x18\n \x01(\t\x12:\n\x06status\x18\x0b \x01(\x0e\x32*.mlflow.ucmodelregistry.ModelVersionStatus\x12\x16\n\x0estatus_message\x18\x0c \x01(\t\x12\x18\n\x10storage_location\x18\r \x01(\t\"\x9d\x02\n\x14TemporaryCredentials\x12\x46\n\x14\x61ws_temp_credentials\x18\x02 \x01(\x0b\x32&.mlflow.ucmodelregistry.AwsCredentialsH\x00\x12S\n\x19\x61zure_user_delegation_sas\x18\x03 \x01(\x0b\x32..mlflow.ucmodelregistry.AzureUserDelegationSASH\x00\x12@\n\x0fgcp_oauth_token\x18\x04 \x01(\x0b\x32%.mlflow.ucmodelregistry.GcpOauthTokenH\x00\x12\x17\n\x0f\x65xpiration_time\x18\x01 \x01(\x03\x42\r\n\x0b\x63redentials\"Y\n\x0e\x41wsCredentials\x12\x15\n\raccess_key_id\x18\x01 \x01(\t\x12\x19\n\x11secret_access_key\x18\x02 \x01(\t\x12\x15\n\rsession_token\x18\x03 \x01(\t\"+\n\x16\x41zureUserDelegationSAS\x12\x11\n\tsas_token\x18\x01 \x01(\t\"$\n\rGcpOauthToken\x12\x13\n\x0boauth_token\x18\x01 \x01(\t\"\x83\x01\n\x1c\x43reateRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t::\xe2?7\n5com.databricks.rpc.RPC[CreateRegisteredModelResponse]\"b\n\x1d\x43reateRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"\x83\x01\n\x1cUpdateRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t::\xe2?7\n5com.databricks.rpc.RPC[UpdateRegisteredModelResponse]\"b\n\x1dUpdateRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"n\n\x1c\x44\x65leteRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01::\xe2?7\n5com.databricks.rpc.RPC[DeleteRegisteredModelResponse]\"\x1f\n\x1d\x44\x65leteRegisteredModelResponse\"h\n\x19GetRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01:7\xe2?4\n2com.databricks.rpc.RPC[GetRegisteredModelResponse]\"_\n\x1aGetRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"\x8a\x01\n\x1dSearchRegisteredModelsRequest\x12\x18\n\x0bmax_results\x18\x01 \x01(\x03:\x03\x31\x30\x30\x12\x12\n\npage_token\x18\x02 \x01(\t:;\xe2?8\n6com.databricks.rpc.RPC[SearchRegisteredModelsResponse]\"}\n\x1eSearchRegisteredModelsResponse\x12\x42\n\x11registered_models\x18\x01 \x03(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\"\xc3\x01\n\x19\x43reateModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x14\n\x06source\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x04 \x01(\t\x12\x1e\n\x16run_tracking_server_id\x18\x05 \x01(\t:7\xe2?4\n2com.databricks.rpc.RPC[CreateModelVersionResponse]\"Y\n\x1a\x43reateModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x94\x01\n\x19UpdateModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t:7\xe2?4\n2com.databricks.rpc.RPC[UpdateModelVersionResponse]\"Y\n\x1aUpdateModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x7f\n\x19\x44\x65leteModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:7\xe2?4\n2com.databricks.rpc.RPC[DeleteModelVersionResponse]\"\x1c\n\x1a\x44\x65leteModelVersionResponse\"y\n\x16GetModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:4\xe2?1\n/com.databricks.rpc.RPC[GetModelVersionResponse]\"V\n\x17GetModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x96\x01\n\x1aSearchModelVersionsRequest\x12\x0e\n\x06\x66ilter\x18\x01 \x01(\t\x12\x1a\n\x0bmax_results\x18\x02 \x01(\x03:\x05\x31\x30\x30\x30\x30\x12\x12\n\npage_token\x18\x03 \x01(\t:8\xe2?5\n3com.databricks.rpc.RPC[SearchModelVersionsResponse]\"t\n\x1bSearchModelVersionsResponse\x12<\n\x0emodel_versions\x18\x01 \x03(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\"\xf3\x01\n/GenerateTemporaryModelVersionCredentialsRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x46\n\toperation\x18\x03 \x01(\x0e\x32-.mlflow.ucmodelregistry.ModelVersionOperationB\x04\xf8\x86\x19\x01:M\xe2?J\nHcom.databricks.rpc.RPC[GenerateTemporaryModelVersionCredentialsResponse]\"u\n0GenerateTemporaryModelVersionCredentialsResponse\x12\x41\n\x0b\x63redentials\x18\x01 \x01(\x0b\x32,.mlflow.ucmodelregistry.TemporaryCredentials\"\x8f\x01\n!GetModelVersionDownloadUriRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:?\xe2?<\n:com.databricks.rpc.RPC[GetModelVersionDownloadUriResponse]\":\n\"GetModelVersionDownloadUriResponse\x12\x14\n\x0c\x61rtifact_uri\x18\x01 \x01(\t\"\x83\x01\n\x1b\x46inalizeModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:9\xe2?6\n4com.databricks.rpc.RPC[FinalizeModelVersionResponse]\"[\n\x1c\x46inalizeModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion*c\n\x12ModelVersionStatus\x12\x0f\n\x0bUNSPECIFIED\x10\x00\x12\x18\n\x14PENDING_REGISTRATION\x10\x01\x12\x17\n\x13\x46\x41ILED_REGISTRATION\x10\x02\x12\t\n\x05READY\x10\x03*\x8a\x01\n\x15ModelVersionOperation\x12\'\n#MODEL_VERSION_OPERATION_UNSPECIFIED\x10\x00\x12 \n\x1cMODEL_VERSION_OPERATION_READ\x10\x01\x12&\n\"MODEL_VERSION_OPERATION_READ_WRITE\x10\x02\x42\x32\n(com.databricks.api.proto.ucmodelregistry\xa0\x01\x01\xe2?\x02\x10\x01')
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n%databricks_uc_registry_messages.proto\x12\x16mlflow.ucmodelregistry\x1a\x15scalapb/scalapb.proto\x1a\x10\x64\x61tabricks.proto\"\x81\x01\n\x0fRegisteredModel\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x02 \x01(\x03\x12\x1e\n\x16last_updated_timestamp\x18\x03 \x01(\x03\x12\x0f\n\x07user_id\x18\x04 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x05 \x01(\t\"\xd8\x02\n\x0cModelVersion\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x03 \x01(\x03\x12\x1e\n\x16last_updated_timestamp\x18\x04 \x01(\x03\x12\x0f\n\x07user_id\x18\x05 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x06 \x01(\t\x12\x0e\n\x06source\x18\x07 \x01(\t\x12\x0e\n\x06run_id\x18\x08 \x01(\t\x12\x19\n\x11run_experiment_id\x18\t \x01(\t\x12\x1e\n\x16run_tracking_server_id\x18\n \x01(\t\x12:\n\x06status\x18\x0b \x01(\x0e\x32*.mlflow.ucmodelregistry.ModelVersionStatus\x12\x16\n\x0estatus_message\x18\x0c \x01(\t\x12\x18\n\x10storage_location\x18\r \x01(\t\"\x9d\x02\n\x14TemporaryCredentials\x12\x46\n\x14\x61ws_temp_credentials\x18\x02 \x01(\x0b\x32&.mlflow.ucmodelregistry.AwsCredentialsH\x00\x12S\n\x19\x61zure_user_delegation_sas\x18\x03 \x01(\x0b\x32..mlflow.ucmodelregistry.AzureUserDelegationSASH\x00\x12@\n\x0fgcp_oauth_token\x18\x04 \x01(\x0b\x32%.mlflow.ucmodelregistry.GcpOauthTokenH\x00\x12\x17\n\x0f\x65xpiration_time\x18\x01 \x01(\x03\x42\r\n\x0b\x63redentials\"Y\n\x0e\x41wsCredentials\x12\x15\n\raccess_key_id\x18\x01 \x01(\t\x12\x19\n\x11secret_access_key\x18\x02 \x01(\t\x12\x15\n\rsession_token\x18\x03 \x01(\t\"+\n\x16\x41zureUserDelegationSAS\x12\x11\n\tsas_token\x18\x01 \x01(\t\"$\n\rGcpOauthToken\x12\x13\n\x0boauth_token\x18\x01 \x01(\t\"\x83\x01\n\x1c\x43reateRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t::\xe2?7\n5com.databricks.rpc.RPC[CreateRegisteredModelResponse]\"b\n\x1d\x43reateRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"\x83\x01\n\x1cUpdateRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t::\xe2?7\n5com.databricks.rpc.RPC[UpdateRegisteredModelResponse]\"b\n\x1dUpdateRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"n\n\x1c\x44\x65leteRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01::\xe2?7\n5com.databricks.rpc.RPC[DeleteRegisteredModelResponse]\"\x1f\n\x1d\x44\x65leteRegisteredModelResponse\"h\n\x19GetRegisteredModelRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01:7\xe2?4\n2com.databricks.rpc.RPC[GetRegisteredModelResponse]\"_\n\x1aGetRegisteredModelResponse\x12\x41\n\x10registered_model\x18\x01 \x01(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\"\x8a\x01\n\x1dSearchRegisteredModelsRequest\x12\x18\n\x0bmax_results\x18\x01 \x01(\x03:\x03\x31\x30\x30\x12\x12\n\npage_token\x18\x02 \x01(\t:;\xe2?8\n6com.databricks.rpc.RPC[SearchRegisteredModelsResponse]\"}\n\x1eSearchRegisteredModelsResponse\x12\x42\n\x11registered_models\x18\x01 \x03(\x0b\x32\'.mlflow.ucmodelregistry.RegisteredModel\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\"\xc3\x01\n\x19\x43reateModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x14\n\x06source\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x04 \x01(\t\x12\x1e\n\x16run_tracking_server_id\x18\x05 \x01(\t:7\xe2?4\n2com.databricks.rpc.RPC[CreateModelVersionResponse]\"Y\n\x1a\x43reateModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x94\x01\n\x19UpdateModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t:7\xe2?4\n2com.databricks.rpc.RPC[UpdateModelVersionResponse]\"Y\n\x1aUpdateModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x7f\n\x19\x44\x65leteModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:7\xe2?4\n2com.databricks.rpc.RPC[DeleteModelVersionResponse]\"\x1c\n\x1a\x44\x65leteModelVersionResponse\"y\n\x16GetModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:4\xe2?1\n/com.databricks.rpc.RPC[GetModelVersionResponse]\"V\n\x17GetModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x96\x01\n\x1aSearchModelVersionsRequest\x12\x0e\n\x06\x66ilter\x18\x01 \x01(\t\x12\x1a\n\x0bmax_results\x18\x02 \x01(\x03:\x05\x31\x30\x30\x30\x30\x12\x12\n\npage_token\x18\x03 \x01(\t:8\xe2?5\n3com.databricks.rpc.RPC[SearchModelVersionsResponse]\"t\n\x1bSearchModelVersionsResponse\x12<\n\x0emodel_versions\x18\x01 \x03(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\"\xf3\x01\n/GenerateTemporaryModelVersionCredentialsRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x46\n\toperation\x18\x03 \x01(\x0e\x32-.mlflow.ucmodelregistry.ModelVersionOperationB\x04\xf8\x86\x19\x01:M\xe2?J\nHcom.databricks.rpc.RPC[GenerateTemporaryModelVersionCredentialsResponse]\"u\n0GenerateTemporaryModelVersionCredentialsResponse\x12\x41\n\x0b\x63redentials\x18\x01 \x01(\x0b\x32,.mlflow.ucmodelregistry.TemporaryCredentials\"\x8f\x01\n!GetModelVersionDownloadUriRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:?\xe2?<\n:com.databricks.rpc.RPC[GetModelVersionDownloadUriResponse]\":\n\"GetModelVersionDownloadUriResponse\x12\x14\n\x0c\x61rtifact_uri\x18\x01 \x01(\t\"\x83\x01\n\x1b\x46inalizeModelVersionRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:9\xe2?6\n4com.databricks.rpc.RPC[FinalizeModelVersionResponse]\"[\n\x1c\x46inalizeModelVersionResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion\"\x9e\x01\n\x1eSetRegisteredModelAliasRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x05\x61lias\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x15\n\x07version\x18\x03 \x01(\tB\x04\xf8\x86\x19\x01:<\xe2?9\n7com.databricks.rpc.RPC[SetRegisteredModelAliasResponse]\"!\n\x1fSetRegisteredModelAliasResponse\"\x8d\x01\n!DeleteRegisteredModelAliasRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x05\x61lias\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:?\xe2?<\n:com.databricks.rpc.RPC[DeleteRegisteredModelAliasResponse]\"$\n\"DeleteRegisteredModelAliasResponse\"\x85\x01\n\x1dGetModelVersionByAliasRequest\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x05\x61lias\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01:;\xe2?8\n6com.databricks.rpc.RPC[GetModelVersionByAliasResponse]\"]\n\x1eGetModelVersionByAliasResponse\x12;\n\rmodel_version\x18\x01 \x01(\x0b\x32$.mlflow.ucmodelregistry.ModelVersion*c\n\x12ModelVersionStatus\x12\x0f\n\x0bUNSPECIFIED\x10\x00\x12\x18\n\x14PENDING_REGISTRATION\x10\x01\x12\x17\n\x13\x46\x41ILED_REGISTRATION\x10\x02\x12\t\n\x05READY\x10\x03*\x8a\x01\n\x15ModelVersionOperation\x12\'\n#MODEL_VERSION_OPERATION_UNSPECIFIED\x10\x00\x12 \n\x1cMODEL_VERSION_OPERATION_READ\x10\x01\x12&\n\"MODEL_VERSION_OPERATION_READ_WRITE\x10\x02\x42\x32\n(com.databricks.api.proto.ucmodelregistry\xa0\x01\x01\xe2?\x02\x10\x01')
 
 _MODELVERSIONSTATUS = DESCRIPTOR.enum_types_by_name['ModelVersionStatus']
 ModelVersionStatus = enum_type_wrapper.EnumTypeWrapper(_MODELVERSIONSTATUS)
 _MODELVERSIONOPERATION = DESCRIPTOR.enum_types_by_name['ModelVersionOperation']
 ModelVersionOperation = enum_type_wrapper.EnumTypeWrapper(_MODELVERSIONOPERATION)
 UNSPECIFIED = 0
 PENDING_REGISTRATION = 1
@@ -60,14 +60,20 @@
 _SEARCHMODELVERSIONSRESPONSE = DESCRIPTOR.message_types_by_name['SearchModelVersionsResponse']
 _GENERATETEMPORARYMODELVERSIONCREDENTIALSREQUEST = DESCRIPTOR.message_types_by_name['GenerateTemporaryModelVersionCredentialsRequest']
 _GENERATETEMPORARYMODELVERSIONCREDENTIALSRESPONSE = DESCRIPTOR.message_types_by_name['GenerateTemporaryModelVersionCredentialsResponse']
 _GETMODELVERSIONDOWNLOADURIREQUEST = DESCRIPTOR.message_types_by_name['GetModelVersionDownloadUriRequest']
 _GETMODELVERSIONDOWNLOADURIRESPONSE = DESCRIPTOR.message_types_by_name['GetModelVersionDownloadUriResponse']
 _FINALIZEMODELVERSIONREQUEST = DESCRIPTOR.message_types_by_name['FinalizeModelVersionRequest']
 _FINALIZEMODELVERSIONRESPONSE = DESCRIPTOR.message_types_by_name['FinalizeModelVersionResponse']
+_SETREGISTEREDMODELALIASREQUEST = DESCRIPTOR.message_types_by_name['SetRegisteredModelAliasRequest']
+_SETREGISTEREDMODELALIASRESPONSE = DESCRIPTOR.message_types_by_name['SetRegisteredModelAliasResponse']
+_DELETEREGISTEREDMODELALIASREQUEST = DESCRIPTOR.message_types_by_name['DeleteRegisteredModelAliasRequest']
+_DELETEREGISTEREDMODELALIASRESPONSE = DESCRIPTOR.message_types_by_name['DeleteRegisteredModelAliasResponse']
+_GETMODELVERSIONBYALIASREQUEST = DESCRIPTOR.message_types_by_name['GetModelVersionByAliasRequest']
+_GETMODELVERSIONBYALIASRESPONSE = DESCRIPTOR.message_types_by_name['GetModelVersionByAliasResponse']
 RegisteredModel = _reflection.GeneratedProtocolMessageType('RegisteredModel', (_message.Message,), {
   'DESCRIPTOR' : _REGISTEREDMODEL,
   '__module__' : 'databricks_uc_registry_messages_pb2'
   # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.RegisteredModel)
   })
 _sym_db.RegisterMessage(RegisteredModel)
 
@@ -284,14 +290,56 @@
 FinalizeModelVersionResponse = _reflection.GeneratedProtocolMessageType('FinalizeModelVersionResponse', (_message.Message,), {
   'DESCRIPTOR' : _FINALIZEMODELVERSIONRESPONSE,
   '__module__' : 'databricks_uc_registry_messages_pb2'
   # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.FinalizeModelVersionResponse)
   })
 _sym_db.RegisterMessage(FinalizeModelVersionResponse)
 
+SetRegisteredModelAliasRequest = _reflection.GeneratedProtocolMessageType('SetRegisteredModelAliasRequest', (_message.Message,), {
+  'DESCRIPTOR' : _SETREGISTEREDMODELALIASREQUEST,
+  '__module__' : 'databricks_uc_registry_messages_pb2'
+  # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.SetRegisteredModelAliasRequest)
+  })
+_sym_db.RegisterMessage(SetRegisteredModelAliasRequest)
+
+SetRegisteredModelAliasResponse = _reflection.GeneratedProtocolMessageType('SetRegisteredModelAliasResponse', (_message.Message,), {
+  'DESCRIPTOR' : _SETREGISTEREDMODELALIASRESPONSE,
+  '__module__' : 'databricks_uc_registry_messages_pb2'
+  # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.SetRegisteredModelAliasResponse)
+  })
+_sym_db.RegisterMessage(SetRegisteredModelAliasResponse)
+
+DeleteRegisteredModelAliasRequest = _reflection.GeneratedProtocolMessageType('DeleteRegisteredModelAliasRequest', (_message.Message,), {
+  'DESCRIPTOR' : _DELETEREGISTEREDMODELALIASREQUEST,
+  '__module__' : 'databricks_uc_registry_messages_pb2'
+  # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.DeleteRegisteredModelAliasRequest)
+  })
+_sym_db.RegisterMessage(DeleteRegisteredModelAliasRequest)
+
+DeleteRegisteredModelAliasResponse = _reflection.GeneratedProtocolMessageType('DeleteRegisteredModelAliasResponse', (_message.Message,), {
+  'DESCRIPTOR' : _DELETEREGISTEREDMODELALIASRESPONSE,
+  '__module__' : 'databricks_uc_registry_messages_pb2'
+  # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.DeleteRegisteredModelAliasResponse)
+  })
+_sym_db.RegisterMessage(DeleteRegisteredModelAliasResponse)
+
+GetModelVersionByAliasRequest = _reflection.GeneratedProtocolMessageType('GetModelVersionByAliasRequest', (_message.Message,), {
+  'DESCRIPTOR' : _GETMODELVERSIONBYALIASREQUEST,
+  '__module__' : 'databricks_uc_registry_messages_pb2'
+  # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.GetModelVersionByAliasRequest)
+  })
+_sym_db.RegisterMessage(GetModelVersionByAliasRequest)
+
+GetModelVersionByAliasResponse = _reflection.GeneratedProtocolMessageType('GetModelVersionByAliasResponse', (_message.Message,), {
+  'DESCRIPTOR' : _GETMODELVERSIONBYALIASRESPONSE,
+  '__module__' : 'databricks_uc_registry_messages_pb2'
+  # @@protoc_insertion_point(class_scope:mlflow.ucmodelregistry.GetModelVersionByAliasResponse)
+  })
+_sym_db.RegisterMessage(GetModelVersionByAliasResponse)
+
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   DESCRIPTOR._serialized_options = b'\n(com.databricks.api.proto.ucmodelregistry\240\001\001\342?\002\020\001'
   _CREATEREGISTEREDMODELREQUEST.fields_by_name['name']._options = None
   _CREATEREGISTEREDMODELREQUEST.fields_by_name['name']._serialized_options = b'\370\206\031\001'
   _CREATEREGISTEREDMODELREQUEST._options = None
@@ -352,18 +400,38 @@
   _GETMODELVERSIONDOWNLOADURIREQUEST._serialized_options = b'\342?<\n:com.databricks.rpc.RPC[GetModelVersionDownloadUriResponse]'
   _FINALIZEMODELVERSIONREQUEST.fields_by_name['name']._options = None
   _FINALIZEMODELVERSIONREQUEST.fields_by_name['name']._serialized_options = b'\370\206\031\001'
   _FINALIZEMODELVERSIONREQUEST.fields_by_name['version']._options = None
   _FINALIZEMODELVERSIONREQUEST.fields_by_name['version']._serialized_options = b'\370\206\031\001'
   _FINALIZEMODELVERSIONREQUEST._options = None
   _FINALIZEMODELVERSIONREQUEST._serialized_options = b'\342?6\n4com.databricks.rpc.RPC[FinalizeModelVersionResponse]'
-  _MODELVERSIONSTATUS._serialized_start=4101
-  _MODELVERSIONSTATUS._serialized_end=4200
-  _MODELVERSIONOPERATION._serialized_start=4203
-  _MODELVERSIONOPERATION._serialized_end=4341
+  _SETREGISTEREDMODELALIASREQUEST.fields_by_name['name']._options = None
+  _SETREGISTEREDMODELALIASREQUEST.fields_by_name['name']._serialized_options = b'\370\206\031\001'
+  _SETREGISTEREDMODELALIASREQUEST.fields_by_name['alias']._options = None
+  _SETREGISTEREDMODELALIASREQUEST.fields_by_name['alias']._serialized_options = b'\370\206\031\001'
+  _SETREGISTEREDMODELALIASREQUEST.fields_by_name['version']._options = None
+  _SETREGISTEREDMODELALIASREQUEST.fields_by_name['version']._serialized_options = b'\370\206\031\001'
+  _SETREGISTEREDMODELALIASREQUEST._options = None
+  _SETREGISTEREDMODELALIASREQUEST._serialized_options = b'\342?9\n7com.databricks.rpc.RPC[SetRegisteredModelAliasResponse]'
+  _DELETEREGISTEREDMODELALIASREQUEST.fields_by_name['name']._options = None
+  _DELETEREGISTEREDMODELALIASREQUEST.fields_by_name['name']._serialized_options = b'\370\206\031\001'
+  _DELETEREGISTEREDMODELALIASREQUEST.fields_by_name['alias']._options = None
+  _DELETEREGISTEREDMODELALIASREQUEST.fields_by_name['alias']._serialized_options = b'\370\206\031\001'
+  _DELETEREGISTEREDMODELALIASREQUEST._options = None
+  _DELETEREGISTEREDMODELALIASREQUEST._serialized_options = b'\342?<\n:com.databricks.rpc.RPC[DeleteRegisteredModelAliasResponse]'
+  _GETMODELVERSIONBYALIASREQUEST.fields_by_name['name']._options = None
+  _GETMODELVERSIONBYALIASREQUEST.fields_by_name['name']._serialized_options = b'\370\206\031\001'
+  _GETMODELVERSIONBYALIASREQUEST.fields_by_name['alias']._options = None
+  _GETMODELVERSIONBYALIASREQUEST.fields_by_name['alias']._serialized_options = b'\370\206\031\001'
+  _GETMODELVERSIONBYALIASREQUEST._options = None
+  _GETMODELVERSIONBYALIASREQUEST._serialized_options = b'\342?8\n6com.databricks.rpc.RPC[GetModelVersionByAliasResponse]'
+  _MODELVERSIONSTATUS._serialized_start=4710
+  _MODELVERSIONSTATUS._serialized_end=4809
+  _MODELVERSIONOPERATION._serialized_start=4812
+  _MODELVERSIONOPERATION._serialized_end=4950
   _REGISTEREDMODEL._serialized_start=107
   _REGISTEREDMODEL._serialized_end=236
   _MODELVERSION._serialized_start=239
   _MODELVERSION._serialized_end=583
   _TEMPORARYCREDENTIALS._serialized_start=586
   _TEMPORARYCREDENTIALS._serialized_end=871
   _AWSCREDENTIALS._serialized_start=873
@@ -420,8 +488,20 @@
   _GETMODELVERSIONDOWNLOADURIREQUEST._serialized_end=3812
   _GETMODELVERSIONDOWNLOADURIRESPONSE._serialized_start=3814
   _GETMODELVERSIONDOWNLOADURIRESPONSE._serialized_end=3872
   _FINALIZEMODELVERSIONREQUEST._serialized_start=3875
   _FINALIZEMODELVERSIONREQUEST._serialized_end=4006
   _FINALIZEMODELVERSIONRESPONSE._serialized_start=4008
   _FINALIZEMODELVERSIONRESPONSE._serialized_end=4099
+  _SETREGISTEREDMODELALIASREQUEST._serialized_start=4102
+  _SETREGISTEREDMODELALIASREQUEST._serialized_end=4260
+  _SETREGISTEREDMODELALIASRESPONSE._serialized_start=4262
+  _SETREGISTEREDMODELALIASRESPONSE._serialized_end=4295
+  _DELETEREGISTEREDMODELALIASREQUEST._serialized_start=4298
+  _DELETEREGISTEREDMODELALIASREQUEST._serialized_end=4439
+  _DELETEREGISTEREDMODELALIASRESPONSE._serialized_start=4441
+  _DELETEREGISTEREDMODELALIASRESPONSE._serialized_end=4477
+  _GETMODELVERSIONBYALIASREQUEST._serialized_start=4480
+  _GETMODELVERSIONBYALIASREQUEST._serialized_end=4613
+  _GETMODELVERSIONBYALIASRESPONSE._serialized_start=4615
+  _GETMODELVERSIONBYALIASRESPONSE._serialized_end=4708
 # @@protoc_insertion_point(module_scope)
```

## mlflow/protos/databricks_uc_registry_service_pb2.py

```diff
@@ -15,15 +15,15 @@
 
 
 from . import databricks_pb2 as databricks__pb2
 from . import databricks_uc_registry_messages_pb2 as databricks_uc_registry_messages_pb2
 from .scalapb import scalapb_pb2 as scalapb_dot_scalapb__pb2
 
 
-DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n$databricks_uc_registry_service.proto\x12\x16mlflow.ucmodelregistry\x1a\x10\x64\x61tabricks.proto\x1a%databricks_uc_registry_messages.proto\x1a\x15scalapb/scalapb.proto2\xb8\x19\n\x16UcModelRegistryService\x12\xf2\x01\n\x15\x43reateRegisteredModel\x12\x34.mlflow.ucmodelregistry.CreateRegisteredModelRequest\x1a\x35.mlflow.ucmodelregistry.CreateRegisteredModelResponse\"l\xf2\x86\x19h\n<\n\x04POST\x12./mlflow/unity-catalog/registered-models/create\x1a\x04\x08\x02\x10\x00\x10\x03*&(Unity Catalog) Create RegisteredModel\x12\xf3\x01\n\x15UpdateRegisteredModel\x12\x34.mlflow.ucmodelregistry.UpdateRegisteredModelRequest\x1a\x35.mlflow.ucmodelregistry.UpdateRegisteredModelResponse\"m\xf2\x86\x19i\n=\n\x05PATCH\x12./mlflow/unity-catalog/registered-models/update\x1a\x04\x08\x02\x10\x00\x10\x03*&(Unity Catalog) Update RegisteredModel\x12\xf4\x01\n\x15\x44\x65leteRegisteredModel\x12\x34.mlflow.ucmodelregistry.DeleteRegisteredModelRequest\x1a\x35.mlflow.ucmodelregistry.DeleteRegisteredModelResponse\"n\xf2\x86\x19j\n>\n\x06\x44\x45LETE\x12./mlflow/unity-catalog/registered-models/delete\x1a\x04\x08\x02\x10\x00\x10\x03*&(Unity Catalog) Delete RegisteredModel\x12\xe2\x01\n\x12GetRegisteredModel\x12\x31.mlflow.ucmodelregistry.GetRegisteredModelRequest\x1a\x32.mlflow.ucmodelregistry.GetRegisteredModelResponse\"e\xf2\x86\x19\x61\n8\n\x03GET\x12+/mlflow/unity-catalog/registered-models/get\x1a\x04\x08\x02\x10\x00\x10\x03*#(Unity Catalog) Get RegisteredModel\x12\xf5\x01\n\x16SearchRegisteredModels\x12\x35.mlflow.ucmodelregistry.SearchRegisteredModelsRequest\x1a\x36.mlflow.ucmodelregistry.SearchRegisteredModelsResponse\"l\xf2\x86\x19h\n;\n\x03GET\x12./mlflow/unity-catalog/registered-models/search\x1a\x04\x08\x02\x10\x00\x10\x03*\'(Unity Catalog) Search RegisteredModels\x12\xe3\x01\n\x12\x43reateModelVersion\x12\x31.mlflow.ucmodelregistry.CreateModelVersionRequest\x1a\x32.mlflow.ucmodelregistry.CreateModelVersionResponse\"f\xf2\x86\x19\x62\n9\n\x04POST\x12+/mlflow/unity-catalog/model-versions/create\x1a\x04\x08\x02\x10\x00\x10\x03*#(Unity Catalog) Create ModelVersion\x12\xe4\x01\n\x12UpdateModelVersion\x12\x31.mlflow.ucmodelregistry.UpdateModelVersionRequest\x1a\x32.mlflow.ucmodelregistry.UpdateModelVersionResponse\"g\xf2\x86\x19\x63\n:\n\x05PATCH\x12+/mlflow/unity-catalog/model-versions/update\x1a\x04\x08\x02\x10\x00\x10\x03*#(Unity Catalog) Update ModelVersion\x12\xe5\x01\n\x12\x44\x65leteModelVersion\x12\x31.mlflow.ucmodelregistry.DeleteModelVersionRequest\x1a\x32.mlflow.ucmodelregistry.DeleteModelVersionResponse\"h\xf2\x86\x19\x64\n;\n\x06\x44\x45LETE\x12+/mlflow/unity-catalog/model-versions/delete\x1a\x04\x08\x02\x10\x00\x10\x03*#(Unity Catalog) Delete ModelVersion\x12\xd3\x01\n\x0fGetModelVersion\x12..mlflow.ucmodelregistry.GetModelVersionRequest\x1a/.mlflow.ucmodelregistry.GetModelVersionResponse\"_\xf2\x86\x19[\n5\n\x03GET\x12(/mlflow/unity-catalog/model-versions/get\x1a\x04\x08\x02\x10\x00\x10\x03* (Unity Catalog) Get ModelVersion\x12\xe6\x01\n\x13SearchModelVersions\x12\x32.mlflow.ucmodelregistry.SearchModelVersionsRequest\x1a\x33.mlflow.ucmodelregistry.SearchModelVersionsResponse\"f\xf2\x86\x19\x62\n8\n\x03GET\x12+/mlflow/unity-catalog/model-versions/search\x1a\x04\x08\x02\x10\x00\x10\x03*$(Unity Catalog) Search ModelVersions\x12\xd8\x02\n(GenerateTemporaryModelVersionCredentials\x12G.mlflow.ucmodelregistry.GenerateTemporaryModelVersionCredentialsRequest\x1aH.mlflow.ucmodelregistry.GenerateTemporaryModelVersionCredentialsResponse\"\x98\x01\xf2\x86\x19\x93\x01\nQ\n\x04POST\x12\x43/mlflow/unity-catalog/model-versions/generate-temporary-credentials\x1a\x04\x08\x02\x10\x00\x10\x03*<(Unity Catalog) Generate Temporary Model Version Credentials\x12\x9e\x02\n\x1aGetModelVersionDownloadUri\x12\x39.mlflow.ucmodelregistry.GetModelVersionDownloadUriRequest\x1a:.mlflow.ucmodelregistry.GetModelVersionDownloadUriResponse\"\x88\x01\xf2\x86\x19\x83\x01\nB\n\x03GET\x12\x35/mlflow/unity-catalog/model-versions/get-download-uri\x1a\x04\x08\x02\x10\x00\x10\x03*;(Unity Catalog) Get Download URI For ModelVersion Artifacts\x12\xee\x01\n\x14\x46inalizeModelVersion\x12\x33.mlflow.ucmodelregistry.FinalizeModelVersionRequest\x1a\x34.mlflow.ucmodelregistry.FinalizeModelVersionResponse\"k\xf2\x86\x19g\n;\n\x04POST\x12-/mlflow/unity-catalog/model-versions/finalize\x1a\x04\x08\x02\x10\x00\x10\x03*&(Unity Catalog) Finalize Model VersionB5\n(com.databricks.api.proto.ucmodelregistry\x90\x01\x01\xa0\x01\x01\xe2?\x02\x10\x01')
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n$databricks_uc_registry_service.proto\x12\x16mlflow.ucmodelregistry\x1a\x10\x64\x61tabricks.proto\x1a%databricks_uc_registry_messages.proto\x1a\x15scalapb/scalapb.proto2\xb9\x1f\n\x16UcModelRegistryService\x12\xf2\x01\n\x15\x43reateRegisteredModel\x12\x34.mlflow.ucmodelregistry.CreateRegisteredModelRequest\x1a\x35.mlflow.ucmodelregistry.CreateRegisteredModelResponse\"l\xf2\x86\x19h\n<\n\x04POST\x12./mlflow/unity-catalog/registered-models/create\x1a\x04\x08\x02\x10\x00\x10\x03*&(Unity Catalog) Create RegisteredModel\x12\xf3\x01\n\x15UpdateRegisteredModel\x12\x34.mlflow.ucmodelregistry.UpdateRegisteredModelRequest\x1a\x35.mlflow.ucmodelregistry.UpdateRegisteredModelResponse\"m\xf2\x86\x19i\n=\n\x05PATCH\x12./mlflow/unity-catalog/registered-models/update\x1a\x04\x08\x02\x10\x00\x10\x03*&(Unity Catalog) Update RegisteredModel\x12\xf4\x01\n\x15\x44\x65leteRegisteredModel\x12\x34.mlflow.ucmodelregistry.DeleteRegisteredModelRequest\x1a\x35.mlflow.ucmodelregistry.DeleteRegisteredModelResponse\"n\xf2\x86\x19j\n>\n\x06\x44\x45LETE\x12./mlflow/unity-catalog/registered-models/delete\x1a\x04\x08\x02\x10\x00\x10\x03*&(Unity Catalog) Delete RegisteredModel\x12\xe2\x01\n\x12GetRegisteredModel\x12\x31.mlflow.ucmodelregistry.GetRegisteredModelRequest\x1a\x32.mlflow.ucmodelregistry.GetRegisteredModelResponse\"e\xf2\x86\x19\x61\n8\n\x03GET\x12+/mlflow/unity-catalog/registered-models/get\x1a\x04\x08\x02\x10\x00\x10\x03*#(Unity Catalog) Get RegisteredModel\x12\xf5\x01\n\x16SearchRegisteredModels\x12\x35.mlflow.ucmodelregistry.SearchRegisteredModelsRequest\x1a\x36.mlflow.ucmodelregistry.SearchRegisteredModelsResponse\"l\xf2\x86\x19h\n;\n\x03GET\x12./mlflow/unity-catalog/registered-models/search\x1a\x04\x08\x02\x10\x00\x10\x03*\'(Unity Catalog) Search RegisteredModels\x12\xe3\x01\n\x12\x43reateModelVersion\x12\x31.mlflow.ucmodelregistry.CreateModelVersionRequest\x1a\x32.mlflow.ucmodelregistry.CreateModelVersionResponse\"f\xf2\x86\x19\x62\n9\n\x04POST\x12+/mlflow/unity-catalog/model-versions/create\x1a\x04\x08\x02\x10\x00\x10\x03*#(Unity Catalog) Create ModelVersion\x12\xe4\x01\n\x12UpdateModelVersion\x12\x31.mlflow.ucmodelregistry.UpdateModelVersionRequest\x1a\x32.mlflow.ucmodelregistry.UpdateModelVersionResponse\"g\xf2\x86\x19\x63\n:\n\x05PATCH\x12+/mlflow/unity-catalog/model-versions/update\x1a\x04\x08\x02\x10\x00\x10\x03*#(Unity Catalog) Update ModelVersion\x12\xe5\x01\n\x12\x44\x65leteModelVersion\x12\x31.mlflow.ucmodelregistry.DeleteModelVersionRequest\x1a\x32.mlflow.ucmodelregistry.DeleteModelVersionResponse\"h\xf2\x86\x19\x64\n;\n\x06\x44\x45LETE\x12+/mlflow/unity-catalog/model-versions/delete\x1a\x04\x08\x02\x10\x00\x10\x03*#(Unity Catalog) Delete ModelVersion\x12\xd3\x01\n\x0fGetModelVersion\x12..mlflow.ucmodelregistry.GetModelVersionRequest\x1a/.mlflow.ucmodelregistry.GetModelVersionResponse\"_\xf2\x86\x19[\n5\n\x03GET\x12(/mlflow/unity-catalog/model-versions/get\x1a\x04\x08\x02\x10\x00\x10\x03* (Unity Catalog) Get ModelVersion\x12\xe6\x01\n\x13SearchModelVersions\x12\x32.mlflow.ucmodelregistry.SearchModelVersionsRequest\x1a\x33.mlflow.ucmodelregistry.SearchModelVersionsResponse\"f\xf2\x86\x19\x62\n8\n\x03GET\x12+/mlflow/unity-catalog/model-versions/search\x1a\x04\x08\x02\x10\x00\x10\x03*$(Unity Catalog) Search ModelVersions\x12\xd8\x02\n(GenerateTemporaryModelVersionCredentials\x12G.mlflow.ucmodelregistry.GenerateTemporaryModelVersionCredentialsRequest\x1aH.mlflow.ucmodelregistry.GenerateTemporaryModelVersionCredentialsResponse\"\x98\x01\xf2\x86\x19\x93\x01\nQ\n\x04POST\x12\x43/mlflow/unity-catalog/model-versions/generate-temporary-credentials\x1a\x04\x08\x02\x10\x00\x10\x03*<(Unity Catalog) Generate Temporary Model Version Credentials\x12\x9e\x02\n\x1aGetModelVersionDownloadUri\x12\x39.mlflow.ucmodelregistry.GetModelVersionDownloadUriRequest\x1a:.mlflow.ucmodelregistry.GetModelVersionDownloadUriResponse\"\x88\x01\xf2\x86\x19\x83\x01\nB\n\x03GET\x12\x35/mlflow/unity-catalog/model-versions/get-download-uri\x1a\x04\x08\x02\x10\x00\x10\x03*;(Unity Catalog) Get Download URI For ModelVersion Artifacts\x12\xee\x01\n\x14\x46inalizeModelVersion\x12\x33.mlflow.ucmodelregistry.FinalizeModelVersionRequest\x1a\x34.mlflow.ucmodelregistry.FinalizeModelVersionResponse\"k\xf2\x86\x19g\n;\n\x04POST\x12-/mlflow/unity-catalog/model-versions/finalize\x1a\x04\x08\x02\x10\x00\x10\x03*&(Unity Catalog) Finalize Model Version\x12\xfa\x01\n\x17SetRegisteredModelAlias\x12\x36.mlflow.ucmodelregistry.SetRegisteredModelAliasRequest\x1a\x37.mlflow.ucmodelregistry.SetRegisteredModelAliasResponse\"n\xf2\x86\x19j\n;\n\x04POST\x12-/mlflow/unity-catalog/registered-models/alias\x1a\x04\x08\x02\x10\x00\x10\x03*)(Unity Catalog) Set RegisteredModel Alias\x12\x88\x02\n\x1a\x44\x65leteRegisteredModelAlias\x12\x39.mlflow.ucmodelregistry.DeleteRegisteredModelAliasRequest\x1a:.mlflow.ucmodelregistry.DeleteRegisteredModelAliasResponse\"s\xf2\x86\x19o\n=\n\x06\x44\x45LETE\x12-/mlflow/unity-catalog/registered-models/alias\x1a\x04\x08\x02\x10\x00\x10\x03*,(Unity Catalog) Delete RegisteredModel Alias\x12\xf6\x01\n\x16GetModelVersionByAlias\x12\x35.mlflow.ucmodelregistry.GetModelVersionByAliasRequest\x1a\x36.mlflow.ucmodelregistry.GetModelVersionByAliasResponse\"m\xf2\x86\x19i\n:\n\x03GET\x12-/mlflow/unity-catalog/registered-models/alias\x1a\x04\x08\x02\x10\x00\x10\x03*)(Unity Catalog) Get ModelVersion By AliasB5\n(com.databricks.api.proto.ucmodelregistry\x90\x01\x01\xa0\x01\x01\xe2?\x02\x10\x01')
 
 
 
 _UCMODELREGISTRYSERVICE = DESCRIPTOR.services_by_name['UcModelRegistryService']
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
@@ -50,16 +50,22 @@
   _UCMODELREGISTRYSERVICE.methods_by_name['SearchModelVersions']._serialized_options = b'\362\206\031b\n8\n\003GET\022+/mlflow/unity-catalog/model-versions/search\032\004\010\002\020\000\020\003*$(Unity Catalog) Search ModelVersions'
   _UCMODELREGISTRYSERVICE.methods_by_name['GenerateTemporaryModelVersionCredentials']._options = None
   _UCMODELREGISTRYSERVICE.methods_by_name['GenerateTemporaryModelVersionCredentials']._serialized_options = b'\362\206\031\223\001\nQ\n\004POST\022C/mlflow/unity-catalog/model-versions/generate-temporary-credentials\032\004\010\002\020\000\020\003*<(Unity Catalog) Generate Temporary Model Version Credentials'
   _UCMODELREGISTRYSERVICE.methods_by_name['GetModelVersionDownloadUri']._options = None
   _UCMODELREGISTRYSERVICE.methods_by_name['GetModelVersionDownloadUri']._serialized_options = b'\362\206\031\203\001\nB\n\003GET\0225/mlflow/unity-catalog/model-versions/get-download-uri\032\004\010\002\020\000\020\003*;(Unity Catalog) Get Download URI For ModelVersion Artifacts'
   _UCMODELREGISTRYSERVICE.methods_by_name['FinalizeModelVersion']._options = None
   _UCMODELREGISTRYSERVICE.methods_by_name['FinalizeModelVersion']._serialized_options = b'\362\206\031g\n;\n\004POST\022-/mlflow/unity-catalog/model-versions/finalize\032\004\010\002\020\000\020\003*&(Unity Catalog) Finalize Model Version'
+  _UCMODELREGISTRYSERVICE.methods_by_name['SetRegisteredModelAlias']._options = None
+  _UCMODELREGISTRYSERVICE.methods_by_name['SetRegisteredModelAlias']._serialized_options = b'\362\206\031j\n;\n\004POST\022-/mlflow/unity-catalog/registered-models/alias\032\004\010\002\020\000\020\003*)(Unity Catalog) Set RegisteredModel Alias'
+  _UCMODELREGISTRYSERVICE.methods_by_name['DeleteRegisteredModelAlias']._options = None
+  _UCMODELREGISTRYSERVICE.methods_by_name['DeleteRegisteredModelAlias']._serialized_options = b'\362\206\031o\n=\n\006DELETE\022-/mlflow/unity-catalog/registered-models/alias\032\004\010\002\020\000\020\003*,(Unity Catalog) Delete RegisteredModel Alias'
+  _UCMODELREGISTRYSERVICE.methods_by_name['GetModelVersionByAlias']._options = None
+  _UCMODELREGISTRYSERVICE.methods_by_name['GetModelVersionByAlias']._serialized_options = b'\362\206\031i\n:\n\003GET\022-/mlflow/unity-catalog/registered-models/alias\032\004\010\002\020\000\020\003*)(Unity Catalog) Get ModelVersion By Alias'
   _UCMODELREGISTRYSERVICE._serialized_start=145
-  _UCMODELREGISTRYSERVICE._serialized_end=3401
+  _UCMODELREGISTRYSERVICE._serialized_end=4170
 UcModelRegistryService = service_reflection.GeneratedServiceType('UcModelRegistryService', (_service.Service,), dict(
   DESCRIPTOR = _UCMODELREGISTRYSERVICE,
   __module__ = 'databricks_uc_registry_service_pb2'
   ))
 
 UcModelRegistryService_Stub = service_reflection.GeneratedServiceStubType('UcModelRegistryService_Stub', (UcModelRegistryService,), dict(
   DESCRIPTOR = _UCMODELREGISTRYSERVICE,
```

## mlflow/pyfunc/__init__.py

```diff
@@ -950,15 +950,15 @@
         LongType,
         StringType,
         BooleanType,
     )
 
     # Used in test to force install local version of mlflow when starting a model server
     mlflow_home = os.environ.get("MLFLOW_HOME")
-    openai_env_vars = mlflow.openai.OpenAIEnvVar.read_environ()
+    openai_env_vars = mlflow.openai._OpenAIEnvVar.read_environ()
 
     _EnvManager.validate(env_manager)
 
     # Check whether spark is in local or local-cluster mode
     # this case all executors and driver share the same filesystem
     is_spark_in_local_mode = spark.conf.get("spark.master").startswith("local")
 
@@ -1640,26 +1640,75 @@
                           - One or more of the files specified by the ``code_path`` parameter.
 
     :param data_path: Path to a file or directory containing model data.
     :param code_path: A list of local filesystem paths to Python file dependencies (or directories
                       containing file dependencies). These files are *prepended* to the system
                       path before the model is loaded.
     :param conda_env: {{ conda_env }}
-    :param python_model: An instance of a subclass of :class:`~PythonModel`. This class is
-                         serialized using the CloudPickle library. Any dependencies of the class
-                         should be included in one of the following locations:
-
-                            - The MLflow library.
-                            - Package(s) listed in the model's Conda environment, specified by
-                              the ``conda_env`` parameter.
-                            - One or more of the files specified by the ``code_path`` parameter.
-
-                         Note: If the class is imported from another module, as opposed to being
-                         defined in the ``__main__`` scope, the defining module should also be
-                         included in one of the listed locations.
+    :param python_model:
+        An instance of a subclass of :class:`~PythonModel` or a callable object with a single
+        argument (see the examples below). The passed-in object is serialized using the CloudPickle
+        library. Any dependencies of the class should be included in one of the following locations:
+
+        - The MLflow library.
+        - Package(s) listed in the model's Conda environment, specified by the ``conda_env``
+          parameter.
+        - One or more of the files specified by the ``code_path`` parameter.
+
+        Note: If the class is imported from another module, as opposed to being defined in the
+        ``__main__`` scope, the defining module should also be included in one of the listed
+        locations.
+
+        **Examples**
+
+        Class model
+
+        .. code-block:: python
+
+            from typing import List, Dict
+            import mlflow
+
+
+            class MyModel(mlflow.pyfunc.PythonModel):
+                def predict(self, context, model_input: List[str]) -> List[str]:
+                    return [i.upper() for i in model_input]
+
+
+            mlflow.pyfunc.save_model("model", python_model=MyModel(), input_example=["a"])
+            model = mlflow.pyfunc.load_model("model")
+            print(model.predict(["a", "b", "c"]))  # -> ["A", "B", "C"]
+
+        Functional model
+
+        .. note::
+            Experimental: Functional model support is experimental and may change or be removed in
+            a future release without warning.
+
+        .. code-block:: python
+
+            from typing import List
+            import mlflow
+
+
+            def predict(model_input: List[str]) -> List[str]:
+                return [i.upper() for i in model_input]
+
+
+            mlflow.pyfunc.save_model("model", python_model=predict, input_example=["a"])
+            model = mlflow.pyfunc.load_model("model")
+            print(model.predict(["a", "b", "c"]))  # -> ["A", "B", "C"]
+
+        If the `predict` method or function has type annotations, MLflow automatically constructs
+        a model signature based on the type annotations (unless the ``signature`` argument is
+        explicitly specified), and converts the input value to the specified type before passing
+        it to the function. Currently, the following type annotations are supported:
+
+            - ``List[str]``
+            - ``List[Dict[str, str]]``
+
     :param artifacts: A dictionary containing ``<name, artifact_uri>`` entries. Remote artifact URIs
                       are resolved to absolute filesystem paths, producing a dictionary of
                       ``<name, absolute_path>`` entries. ``python_model`` can reference these
                       resolved entries as the ``artifacts`` property of the ``context`` parameter
                       in :func:`PythonModel.load_context() <mlflow.pyfunc.PythonModel.load_context>`
                       and :func:`PythonModel.predict() <mlflow.pyfunc.PythonModel.predict>`.
                       For example, consider the following ``artifacts`` dictionary::
```

## mlflow/recipes/cards/pandas_renderer.py

```diff
@@ -153,15 +153,17 @@
             if current_column_value.dtype == bool:
                 current_column_value = current_column_value.replace({True: "True", False: "False"})
                 is_current_column_boolean_type = True
             feat_stats = feat.string_stats
             strs = current_column_value.dropna()
 
             feat_stats.avg_length = (
-                np.mean(np.vectorize(len)(strs)) if not is_current_column_boolean_type else 0
+                np.mean(np.vectorize(len)(strs))
+                if not is_current_column_boolean_type and not current_column_value.isnull().all()
+                else 0
             )
             vals, counts = np.unique(strs, return_counts=True)
             feat_stats.unique = pandas_describe_key.get("unique", len(vals))
             sorted_vals = sorted(zip(counts, vals), reverse=True)
             sorted_vals = sorted_vals[:HISTOGRAM_CATEGORICAL_LEVELS_COUNT]
             for val_index, val in enumerate(sorted_vals):
                 try:
```

## mlflow/server/handlers.py

```diff
@@ -1,15 +1,15 @@
 # Define all the service endpoint handlers here.
 import json
 import os
-import re
 import tempfile
 import posixpath
 import urllib
 import pathlib
+import re
 
 import logging
 from functools import wraps
 
 from flask import Response, request, current_app, send_file
 from google.protobuf import descriptor
 from google.protobuf.json_format import ParseError
@@ -1319,14 +1319,44 @@
     )
     _get_model_registry_store().delete_registered_model_tag(
         name=request_message.name, key=request_message.key
     )
     return _wrap_response(DeleteRegisteredModelTag.Response())
 
 
+def _validate_non_local_source_contains_relative_paths(source: str):
+    """
+    Validation check to ensure that sources that are provided that conform to the schemes:
+    http, https, or mlflow-artifacts do not contain relative path designations that are intended
+    to access local file system paths on the tracking server.
+
+    Example paths that this validation function is intended to find and raise an Exception if
+    passed:
+    "mlflow-artifacts://host:port/../../../../"
+    "http://host:port/api/2.0/mlflow-artifacts/artifacts/../../../../"
+    "https://host:port/api/2.0/mlflow-artifacts/artifacts/../../../../"
+    "/models/artifacts/../../../"
+    "s3:/my_bucket/models/path/../../other/path"
+    "file://path/to/../../../../some/where/you/should/not/be"
+    """
+    source_path = re.sub(r"/+", "/", urllib.parse.urlparse(source).path.rstrip("/"))
+    resolved_source = pathlib.Path(source_path).resolve().as_posix()
+    # NB: drive split is specifically for Windows since WindowsPath.resolve() will append the
+    # drive path of the pwd to a given path. We don't care about the drive here, though.
+    _, resolved_path = os.path.splitdrive(resolved_source)
+
+    if resolved_path != source_path:
+        raise MlflowException(
+            f"Invalid model version source: '{source}'. If supplying a source as an http, https, "
+            "local file path, ftp, objectstore, or mlflow-artifacts uri, an absolute path must be "
+            "provided without relative path references present. Please provide an absolute path.",
+            INVALID_PARAMETER_VALUE,
+        )
+
+
 def _validate_source(source: str, run_id: str) -> None:
     if is_local_uri(source):
         if run_id:
             store = _get_tracking_store()
             run = store.get_run(run_id)
             source = pathlib.Path(local_file_uri_to_path(source)).resolve()
             run_artifact_dir = pathlib.Path(local_file_uri_to_path(run.info.artifact_uri)).resolve()
@@ -1348,14 +1378,18 @@
             f"Invalid model version source: '{source}'. MLflow tracking server doesn't allow using "
             "a file URI as a model version source for security reasons. To disable this check, set "
             f"the {MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE.name} environment variable to "
             "True.",
             INVALID_PARAMETER_VALUE,
         )
 
+    # Checks if relative paths are present in the source (a security threat). If any are present,
+    # raises an Exception.
+    _validate_non_local_source_contains_relative_paths(source)
+
 
 @catch_mlflow_exception
 @_disable_if_artifacts_only
 def _create_model_version():
     request_message = _get_request_message(
         CreateModelVersion(),
         schema={
```

## mlflow/store/_unity_catalog/registry/rest_store.py

```diff
@@ -26,14 +26,20 @@
     GetRegisteredModelResponse,
     GetModelVersionRequest,
     GetModelVersionResponse,
     SearchRegisteredModelsRequest,
     SearchRegisteredModelsResponse,
     GenerateTemporaryModelVersionCredentialsRequest,
     GenerateTemporaryModelVersionCredentialsResponse,
+    SetRegisteredModelAliasRequest,
+    SetRegisteredModelAliasResponse,
+    DeleteRegisteredModelAliasRequest,
+    DeleteRegisteredModelAliasResponse,
+    GetModelVersionByAliasRequest,
+    GetModelVersionByAliasResponse,
     TemporaryCredentials,
     MODEL_VERSION_OPERATION_READ_WRITE,
 )
 import mlflow
 from mlflow.exceptions import MlflowException
 from mlflow.protos.databricks_uc_registry_service_pb2 import UcModelRegistryService
 from mlflow.store.entities.paged_list import PagedList
@@ -48,15 +54,15 @@
 from mlflow.store._unity_catalog.registry.utils import get_artifact_repo_from_storage_info
 from mlflow.store.model_registry.rest_store import BaseRestStore
 from mlflow.store._unity_catalog.registry.utils import (
     model_version_from_uc_proto,
     registered_model_from_uc_proto,
 )
 from mlflow.utils.annotations import experimental
-from mlflow.utils.databricks_utils import get_databricks_host_creds
+from mlflow.utils.databricks_utils import get_databricks_host_creds, is_databricks_uri
 
 
 _DATABRICKS_ORG_ID_HEADER = "x-databricks-org-id"
 _TRACKING_METHOD_TO_INFO = extract_api_info_for_service(MlflowService, _REST_API_PATH_PREFIX)
 _METHOD_TO_INFO = extract_api_info_for_service(UcModelRegistryService, _REST_API_PATH_PREFIX)
 _METHOD_TO_ALL_INFO = extract_all_api_info_for_service(
     UcModelRegistryService, _REST_API_PATH_PREFIX
@@ -120,14 +126,17 @@
             SearchModelVersionsRequest: SearchModelVersionsResponse,
             GetRegisteredModelRequest: GetRegisteredModelResponse,
             GetModelVersionRequest: GetModelVersionResponse,
             SearchRegisteredModelsRequest: SearchRegisteredModelsResponse,
             # pylint: disable=line-too-long
             GenerateTemporaryModelVersionCredentialsRequest: GenerateTemporaryModelVersionCredentialsResponse,
             GetRun: GetRun.Response,
+            SetRegisteredModelAliasRequest: SetRegisteredModelAliasResponse,
+            DeleteRegisteredModelAliasRequest: DeleteRegisteredModelAliasResponse,
+            GetModelVersionByAliasRequest: GetModelVersionByAliasResponse,
         }
         return method_to_response[method]()
 
     def _get_endpoint_from_method(self, method):
         return _METHOD_TO_INFO[method]
 
     def _get_all_endpoints_from_method(self, method):
@@ -295,15 +304,15 @@
             )
         )
         return self._call_endpoint(
             GenerateTemporaryModelVersionCredentialsRequest, req_body
         ).credentials
 
     def _get_workspace_id(self, run_id):
-        if run_id is None:
+        if run_id is None or not is_databricks_uri(self.tracking_uri):
             return None
         host_creds = self.get_tracking_host_creds()
         endpoint, method = _TRACKING_METHOD_TO_INFO[GetRun]
         response = http_request(
             host_creds=host_creds, endpoint=endpoint, method=method, params={"run_id": run_id}
         )
         response = verify_rest_response(response, endpoint)
@@ -374,17 +383,25 @@
                 source=source,
                 run_id=run_id,
                 description=description,
                 run_tracking_server_id=source_workspace_id,
             )
         )
         with tempfile.TemporaryDirectory() as tmpdir:
-            local_model_dir = mlflow.artifacts.download_artifacts(
-                artifact_uri=source, dst_path=tmpdir, tracking_uri=self.tracking_uri
-            )
+            try:
+                local_model_dir = mlflow.artifacts.download_artifacts(
+                    artifact_uri=source, dst_path=tmpdir, tracking_uri=self.tracking_uri
+                )
+            except Exception as e:
+                raise MlflowException(
+                    f"Unable to download model artifacts from source artifact location "
+                    f"'{source}' in order to upload them to Unity Catalog. Please ensure "
+                    f"the source artifact location exists and that you can download from "
+                    f"it via mlflow.artifacts.download_artifacts()"
+                ) from e
             self._validate_model_signature(local_model_dir)
             model_version = self._call_endpoint(CreateModelVersionRequest, req_body).model_version
             version_number = model_version.version
             scoped_token = self._get_temporary_model_version_write_credentials(
                 name=name, version=version_number
             )
             store = get_artifact_repo_from_storage_info(
@@ -510,28 +527,34 @@
         Set a registered model alias pointing to a model version.
 
         :param name: Registered model name.
         :param alias: Name of the alias.
         :param version: Registered model version number.
         :return: None
         """
-        _raise_unsupported_method(method="set_registered_model_alias")
+        req_body = message_to_json(
+            SetRegisteredModelAliasRequest(name=name, alias=alias, version=str(version))
+        )
+        self._call_endpoint(SetRegisteredModelAliasRequest, req_body)
 
     def delete_registered_model_alias(self, name, alias):
         """
         Delete an alias associated with a registered model.
 
         :param name: Registered model name.
         :param alias: Name of the alias.
         :return: None
         """
-        _raise_unsupported_method(method="delete_registered_model_alias")
+        req_body = message_to_json(DeleteRegisteredModelAliasRequest(name=name, alias=alias))
+        self._call_endpoint(DeleteRegisteredModelAliasRequest, req_body)
 
     def get_model_version_by_alias(self, name, alias):
         """
         Get the model version instance by name and alias.
 
         :param name: Registered model name.
         :param alias: Name of the alias.
         :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.
         """
-        _raise_unsupported_method(method="get_model_version_by_alias")
+        req_body = message_to_json(GetModelVersionByAliasRequest(name=name, alias=alias))
+        response_proto = self._call_endpoint(GetModelVersionByAliasRequest, req_body)
+        return model_version_from_uc_proto(response_proto.model_version)
```

## mlflow/store/_unity_catalog/registry/utils.py

```diff
@@ -45,16 +45,34 @@
 ) -> ArtifactRepository:
     """
     Get an ArtifactRepository instance capable of reading/writing to a UC model version's
     file storage location
     :param storage_location: Storage location of the model version
     :param scoped_token: Protobuf scoped token to use to authenticate to blob storage
     """
+    try:
+        return _get_artifact_repo_from_storage_info(
+            storage_location=storage_location, scoped_token=scoped_token
+        )
+    except ImportError as e:
+        raise MlflowException(
+            "Unable to import necessary dependencies to access model version files in "
+            "Unity Catalog. Please ensure you have the necessary dependencies installed, "
+            "e.g. by running 'pip install mlflow[databricks]' or "
+            "'pip install mlflow-skinny[databricks]'"
+        ) from e
+
+
+def _get_artifact_repo_from_storage_info(
+    storage_location: str, scoped_token: TemporaryCredentials
+) -> ArtifactRepository:
     credential_type = scoped_token.WhichOneof("credentials")
     if credential_type == "aws_temp_credentials":
+        # Verify upfront that boto3 is importable
+        import boto3  # pylint: disable=unused-import
         from mlflow.store.artifact.s3_artifact_repo import S3ArtifactRepository
 
         aws_creds = scoped_token.aws_temp_credentials
         return S3ArtifactRepository(
             artifact_uri=storage_location,
             access_key_id=aws_creds.access_key_id,
             secret_access_key=aws_creds.secret_access_key,
```

## mlflow/store/artifact/artifact_repo.py

```diff
@@ -32,15 +32,18 @@
     __metaclass__ = ABCMeta
 
     def __init__(self, artifact_uri):
         self.artifact_uri = artifact_uri
         # Limit the number of threads used for artifact uploads/downloads. Use at most
         # constants._NUM_MAX_THREADS threads or 2 * the number of CPU cores available on the
         # system (whichever is smaller)
-        self.thread_pool = ThreadPoolExecutor(max_workers=self.max_workers)
+        self.thread_pool = self._create_thread_pool()
+
+    def _create_thread_pool(self):
+        return ThreadPoolExecutor(max_workers=self.max_workers)
 
     @abstractmethod
     def log_artifact(self, local_file, artifact_path=None):
         """
         Log a local file as an artifact, optionally taking an ``artifact_path`` to place it in
         within the run's artifacts. Run artifacts can be organized into directories, so you can
         place the artifact in a directory this way.
```

## mlflow/store/artifact/databricks_artifact_repo.py

```diff
@@ -36,18 +36,15 @@
 from mlflow.protos.service_pb2 import MlflowService, GetRun, ListArtifacts
 from mlflow.store.artifact.artifact_repo import ArtifactRepository
 from mlflow.utils import chunk_list
 from mlflow.utils.databricks_utils import get_databricks_host_creds
 from mlflow.utils.file_utils import (
     download_file_using_http_uri,
     relative_path_to_artifact_path,
-    parallelized_download_file_using_http_uri,
-    download_chunk,
 )
-from mlflow.utils.os import is_windows
 from mlflow.utils.proto_json_utils import message_to_json
 from mlflow.utils import rest_utils
 from mlflow.utils.file_utils import read_chunk
 from mlflow.utils.rest_utils import (
     call_endpoint,
     extract_api_info_for_service,
     _REST_API_PATH_PREFIX,
@@ -58,15 +55,15 @@
     get_databricks_profile_uri_from_artifact_uri,
     is_databricks_acled_artifacts_uri,
     is_valid_dbfs_uri,
     remove_databricks_profile_info_from_artifact_uri,
 )
 
 _logger = logging.getLogger(__name__)
-_DOWNLOAD_CHUNK_SIZE = 10_000_000
+_DOWNLOAD_CHUNK_SIZE = 100000000
 _MULTIPART_UPLOAD_CHUNK_SIZE = 10_000_000  # 10 MB
 _MAX_CREDENTIALS_REQUEST_SIZE = 2000  # Max number of artifact paths in a single credentials request
 _SERVICE_AND_METHOD_TO_INFO = {
     service: extract_api_info_for_service(service, _REST_API_PATH_PREFIX)
     for service in [MlflowService, DatabricksMlflowArtifactsService]
 }
 _ARTIFACT_UPLOAD_BATCH_SIZE = (
@@ -146,14 +143,19 @@
         run_relative_root_path = posixpath.relpath(
             path=artifact_repo_root_path, start=run_artifact_root_path
         )
         # If the paths are equal, then use empty string over "./" for ListArtifact compatibility.
         self.run_relative_artifact_repo_root_path = (
             "" if run_artifact_root_path == artifact_repo_root_path else run_relative_root_path
         )
+        # Use an isolated thread pool executor for chunk uploads to avoid a deadlock
+        # caused by waiting for a chunk-upload task within a file-upload task.
+        # See https://superfastpython.com/threadpoolexecutor-deadlock/#Deadlock_1_Submit_and_Wait_for_a_Task_Within_a_Task
+        # for more details
+        self.chunk_upload_thread_pool = self._create_thread_pool()
 
     @staticmethod
     def _extract_run_id(artifact_uri):
         """
         The artifact_uri is expected to be
         dbfs:/databricks/mlflow-tracking/<EXP_ID>/<RUN_ID>/artifacts/<path>
         Once the path from the input uri is extracted and normalized, it is
@@ -262,15 +264,15 @@
         """
         try:
             headers = self._extract_headers_from_credentials(credentials.headers)
             futures = {}
             num_chunks = _compute_num_chunks(local_file, _MULTIPART_UPLOAD_CHUNK_SIZE)
             for index in range(num_chunks):
                 start_byte = index * _MULTIPART_UPLOAD_CHUNK_SIZE
-                future = self.thread_pool.submit(
+                future = self.chunk_upload_thread_pool.submit(
                     self._azure_upload_chunk,
                     credentials=credentials,
                     headers=headers,
                     local_file=local_file,
                     artifact_path=artifact_path,
                     start_byte=start_byte,
                     size=_MULTIPART_UPLOAD_CHUNK_SIZE,
@@ -340,15 +342,15 @@
             # next try to append the file
             futures = {}
             file_size = os.path.getsize(local_file)
             num_chunks = _compute_num_chunks(local_file, _MULTIPART_UPLOAD_CHUNK_SIZE)
             use_single_part_upload = num_chunks == 1
             for index in range(num_chunks):
                 start_byte = index * _MULTIPART_UPLOAD_CHUNK_SIZE
-                future = self.thread_pool.submit(
+                future = self.chunk_upload_thread_pool.submit(
                     self._retryable_adls_function,
                     func=patch_adls_file_upload,
                     artifact_path=artifact_path,
                     sas_url=credentials.signed_uri,
                     local_file=local_file,
                     start_byte=start_byte,
                     size=_MULTIPART_UPLOAD_CHUNK_SIZE,
@@ -418,51 +420,14 @@
         elif cloud_credential_info.type == ArtifactCredentialType.GCP_SIGNED_URL:
             self._signed_url_upload_file(cloud_credential_info, src_file_path)
         else:
             raise MlflowException(
                 message="Cloud provider not supported.", error_code=INTERNAL_ERROR
             )
 
-    def _parallelized_download_from_cloud(
-        self, cloud_credential_info, file_size, dst_local_file_path, dst_run_relative_artifact_path
-    ):
-        try:
-            failed_downloads = parallelized_download_file_using_http_uri(
-                http_uri=cloud_credential_info.signed_uri,
-                download_path=dst_local_file_path,
-                file_size=file_size,
-                uri_type=cloud_credential_info.type,
-                chunk_size=_DOWNLOAD_CHUNK_SIZE,
-                headers=self._extract_headers_from_credentials(cloud_credential_info.headers),
-            )
-            download_errors = [
-                e for e in failed_downloads.values() if e.response.status_code not in (401, 403)
-            ]
-            if download_errors:
-                raise MlflowException(
-                    f"Failed to download artifact {dst_run_relative_artifact_path}: "
-                    f"{download_errors}"
-                )
-
-            if failed_downloads:
-                new_cloud_creds = self._get_read_credential_infos(
-                    self.run_id, dst_run_relative_artifact_path
-                )[0]
-                new_signed_uri = new_cloud_creds.signed_uri
-                new_headers = self._extract_headers_from_credentials(new_cloud_creds.headers)
-
-            for i in failed_downloads:
-                download_chunk(
-                    i, _DOWNLOAD_CHUNK_SIZE, new_headers, dst_local_file_path, new_signed_uri
-                )
-        except Exception as err:
-            if os.path.exists(dst_local_file_path):
-                os.remove(dst_local_file_path)
-            raise MlflowException(err)
-
     def _download_from_cloud(self, cloud_credential_info, dst_local_file_path):
         """
         Download a file from the input `cloud_credential_info` and save it to `dst_local_file_path`.
         """
         if cloud_credential_info.type not in [
             ArtifactCredentialType.AZURE_SAS_URI,
             ArtifactCredentialType.AZURE_ADLS_GEN2_SAS_URI,
@@ -554,15 +519,15 @@
             return self._upload_part(resp.upload_credential_info, data)
 
     def _upload_parts(self, local_file, create_mpu_resp):
         futures = {}
         for index, cred_info in enumerate(create_mpu_resp.upload_credential_infos):
             part_number = index + 1
             start_byte = index * _MULTIPART_UPLOAD_CHUNK_SIZE
-            future = self.thread_pool.submit(
+            future = self.chunk_upload_thread_pool.submit(
                 self._upload_part_retry,
                 cred_info=cred_info,
                 upload_id=create_mpu_resp.upload_id,
                 part_number=part_number,
                 local_file=local_file,
                 start_byte=start_byte,
                 size=_MULTIPART_UPLOAD_CHUNK_SIZE,
@@ -744,39 +709,22 @@
                 infos.append(FileInfo(file_rel_path, output_file.is_dir, artifact_size))
             if len(artifact_list) == 0 or not response.next_page_token:
                 break
             page_token = response.next_page_token
         return infos
 
     def _download_file(self, remote_file_path, local_path):
-        # list_artifacts API only returns a list of FileInfos at the specified path
-        # if it's a directory. To get file size, we need to iterate over FileInfos
-        # contained by the parent directory. A bad path could result in there being
-        # no matching FileInfos (by path), so fall back to None size to prevent
-        # parallelized download.
-        parent_dir, _ = posixpath.split(remote_file_path)
-        file_infos = self.list_artifacts(parent_dir)
-        file_info = [info for info in file_infos if info.path == remote_file_path]
-        file_size = file_info[0].file_size if len(file_info) == 1 else None
-
         run_relative_remote_file_path = posixpath.join(
             self.run_relative_artifact_repo_root_path, remote_file_path
         )
         read_credentials = self._get_read_credential_infos(
             run_id=self.run_id, paths=[run_relative_remote_file_path]
         )
         # Read credentials for only one file were requested. So we expected only one value in
         # the response.
         assert len(read_credentials) == 1
-        # Windows doesn't support the 'fork' multiprocessing context.
-        if file_size is None or file_size <= _DOWNLOAD_CHUNK_SIZE or is_windows():
-            self._download_from_cloud(
-                cloud_credential_info=read_credentials[0],
-                dst_local_file_path=local_path,
-            )
-        else:
-            self._parallelized_download_from_cloud(
-                read_credentials[0], file_size, local_path, remote_file_path
-            )
+        self._download_from_cloud(
+            cloud_credential_info=read_credentials[0], dst_local_file_path=local_path
+        )
 
     def delete_artifacts(self, artifact_path=None):
         raise MlflowException("Not implemented yet")
```

## mlflow/store/artifact/databricks_models_artifact_repo.py

```diff
@@ -1,33 +1,26 @@
 import logging
 import json
-import os
-import posixpath
 
 import mlflow.tracking
 from mlflow.entities import FileInfo
 from mlflow.exceptions import MlflowException
 from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE
 from mlflow.store.artifact.artifact_repo import ArtifactRepository
 from mlflow.utils.databricks_utils import get_databricks_host_creds
-from mlflow.utils.file_utils import (
-    download_file_using_http_uri,
-    parallelized_download_file_using_http_uri,
-    download_chunk,
-)
-from mlflow.utils.os import is_windows
+from mlflow.utils.file_utils import download_file_using_http_uri
 from mlflow.utils.rest_utils import http_request
 from mlflow.utils.uri import get_databricks_profile_uri_from_artifact_uri
 from mlflow.store.artifact.utils.models import (
     get_model_name_and_version,
     is_using_databricks_registry,
 )
 
 _logger = logging.getLogger(__name__)
-_DOWNLOAD_CHUNK_SIZE = 10_000_000
+_DOWNLOAD_CHUNK_SIZE = 100000000
 # The constant REGISTRY_LIST_ARTIFACT_ENDPOINT is defined as @developer_stable
 REGISTRY_LIST_ARTIFACTS_ENDPOINT = "/api/2.0/mlflow/model-versions/list-artifacts"
 # The constant REGISTRY_ARTIFACT_PRESIGNED_URI_ENDPOINT is defined as @developer_stable
 REGISTRY_ARTIFACT_PRESIGNED_URI_ENDPOINT = "/api/2.0/mlflow/model-versions/get-signed-download-uri"
 
 
 class DatabricksModelsArtifactRepository(ArtifactRepository):
@@ -122,75 +115,22 @@
             )
         return json_response.get("signed_uri", None), json_response.get("headers", None)
 
     def _extract_headers_from_signed_url(self, headers):
         filtered_headers = filter(lambda h: "name" in h and "value" in h, headers)
         return {header.get("name"): header.get("value") for header in filtered_headers}
 
-    def _parallelized_download_from_cloud(
-        self, signed_uri, headers, file_size, dst_local_file_path, dst_run_relative_artifact_path
-    ):
-        try:
-            failed_downloads = parallelized_download_file_using_http_uri(
-                http_uri=signed_uri,
-                download_path=dst_local_file_path,
-                file_size=file_size,
-                # URI type is not known in this context
-                uri_type=None,
-                chunk_size=_DOWNLOAD_CHUNK_SIZE,
-                headers=headers,
-            )
-            download_errors = [
-                e for e in failed_downloads.values() if e.response.status_code not in (401, 403)
-            ]
-            if download_errors:
-                raise MlflowException(
-                    f"Failed to download artifact {dst_run_relative_artifact_path}: "
-                    f"{download_errors}"
-                )
-            if failed_downloads:
-                new_signed_uri, new_headers = self._get_signed_download_uri(
-                    dst_run_relative_artifact_path
-                )
-            for i in failed_downloads:
-                download_chunk(
-                    i, _DOWNLOAD_CHUNK_SIZE, new_headers, dst_local_file_path, new_signed_uri
-                )
-        except Exception as err:
-            if os.path.exists(dst_local_file_path):
-                os.remove(dst_local_file_path)
-            raise MlflowException(err)
-
     def _download_file(self, remote_file_path, local_path):
-        parent_dir, _ = posixpath.split(remote_file_path)
-        file_infos = self.list_artifacts(parent_dir)
-        file_info = [info for info in file_infos if info.path == remote_file_path]
-        file_size = file_info[0].file_size if len(file_info) == 1 else None
         try:
             signed_uri, raw_headers = self._get_signed_download_uri(remote_file_path)
             headers = {}
             if raw_headers is not None:
                 # Don't send None to _extract_headers_from_signed_url
                 headers = self._extract_headers_from_signed_url(raw_headers)
-            # Windows doesn't support the 'fork' multiprocessing context.
-            if file_size is None or file_size <= _DOWNLOAD_CHUNK_SIZE or is_windows():
-                download_file_using_http_uri(
-                    signed_uri,
-                    local_path,
-                    _DOWNLOAD_CHUNK_SIZE,
-                    headers,
-                )
-            else:
-                self._parallelized_download_from_cloud(
-                    signed_uri,
-                    headers,
-                    file_size,
-                    local_path,
-                    remote_file_path,
-                )
+            download_file_using_http_uri(signed_uri, local_path, _DOWNLOAD_CHUNK_SIZE, headers)
         except Exception as err:
             raise MlflowException(err)
 
     def log_artifact(self, local_file, artifact_path=None):
         raise MlflowException("This repository does not support logging artifacts.")
 
     def log_artifacts(self, local_dir, artifact_path=None):
```

## mlflow/store/artifact/utils/models.py

```diff
@@ -1,23 +1,16 @@
-import re
 from typing import NamedTuple, Optional
 import urllib.parse
 
 import mlflow.tracking
 from mlflow.exceptions import MlflowException
 from mlflow.utils.uri import get_databricks_profile_uri_from_artifact_uri, is_databricks_uri
 
 _MODELS_URI_SUFFIX_LATEST = "latest"
 
-# This regex is used by _parse_model_uri and details for the regex match
-# can be found in _improper_model_uri_msg.
-_MODEL_URI_REGEX = re.compile(
-    r"^\/(?P<model_name>[\w \.\-]+)(\/(?P<suffix>[\w]+))?(@(?P<alias>[\w\-]+))?$"
-)
-
 
 def is_using_databricks_registry(uri):
     profile_uri = get_databricks_profile_uri_from_artifact_uri(uri) or mlflow.get_registry_uri()
     return is_databricks_uri(profile_uri)
 
 
 def _improper_model_uri_msg(uri):
@@ -55,40 +48,45 @@
     Returns a ParsedModelUri tuple. Since a models:/ URI can only have one of
     {version, stage, 'latest', alias}, it will return
         - (name, version, None, None) to look for a specific version,
         - (name, None, stage, None) to look for the latest version of a stage,
         - (name, None, None, None) to look for the latest of all versions.
         - (name, None, None, alias) to look for a registered model alias.
     """
-    parsed = urllib.parse.urlparse(uri)
+    parsed = urllib.parse.urlparse(uri, allow_fragments=False)
     if parsed.scheme != "models":
         raise MlflowException(_improper_model_uri_msg(uri))
     path = parsed.path
-    m = _MODEL_URI_REGEX.match(path)
-    if m is None:
+    if not path.startswith("/") or len(path) <= 1:
         raise MlflowException(_improper_model_uri_msg(uri))
-    gd = m.groupdict()
-    model_name = gd.get("model_name")
-    suffix = gd.get("suffix")
-    alias = gd.get("alias")
-    if (model_name.strip() == "") or (suffix and alias) or (suffix is None and alias is None):
+
+    parts = path.lstrip("/").split("/")
+    if len(parts) > 2 or parts[0].strip() == "":
         raise MlflowException(_improper_model_uri_msg(uri))
 
-    if alias:
-        # The URI is an alias URI, e.g. "models:/AdsModel1@Champion"
-        return ParsedModelUri(model_name, alias=alias)
-    elif suffix.isdigit():
-        # The suffix is a specific version, e.g. "models:/AdsModel1/123"
-        return ParsedModelUri(model_name, version=suffix)
-    elif suffix.lower() == _MODELS_URI_SUFFIX_LATEST.lower():
-        # The suffix is the 'latest' string (case insensitive), e.g. "models:/AdsModel1/latest"
-        return ParsedModelUri(model_name)
+    if len(parts) == 2:
+        name, suffix = parts
+        if suffix.strip() == "":
+            raise MlflowException(_improper_model_uri_msg(uri))
+        # The URI is in the suffix format
+        if suffix.isdigit():
+            # The suffix is a specific version, e.g. "models:/AdsModel1/123"
+            return ParsedModelUri(name, version=suffix)
+        elif suffix.lower() == _MODELS_URI_SUFFIX_LATEST.lower():
+            # The suffix is the 'latest' string (case insensitive), e.g. "models:/AdsModel1/latest"
+            return ParsedModelUri(name)
+        else:
+            # The suffix is a specific stage (case insensitive), e.g. "models:/AdsModel1/Production"
+            return ParsedModelUri(name, stage=suffix)
     else:
-        # The suffix is a specific stage (case insensitive), e.g. "models:/AdsModel1/Production"
-        return ParsedModelUri(model_name, stage=suffix)
+        # The URI is an alias URI, e.g. "models:/AdsModel1@Champion"
+        alias_parts = parts[0].rsplit("@", 1)
+        if len(alias_parts) != 2 or alias_parts[1].strip() == "":
+            raise MlflowException(_improper_model_uri_msg(uri))
+        return ParsedModelUri(alias_parts[0], alias=alias_parts[1])
 
 
 def get_model_name_and_version(client, models_uri):
     (model_name, model_version, model_stage, model_alias) = _parse_model_uri(models_uri)
     if model_version is not None:
         return model_name, model_version
     if model_alias is not None:
```

## mlflow/tracking/fluent.py

```diff
@@ -68,15 +68,16 @@
     """
     Set the given experiment as the active experiment. The experiment must either be specified by
     name via `experiment_name` or by ID via `experiment_id`. The experiment name and ID cannot
     both be specified.
 
     :param experiment_name: Case sensitive name of the experiment to be activated. If an experiment
                             with this name does not exist, a new experiment wth this name is
-                            created.
+                            created. On certain platforms such as Databricks, the experiment name
+                            must an absolute path, e.g. ``"/Users/<username>/my-experiment"``.
     :param experiment_id: ID of the experiment to be activated. If an experiment with this ID
                           does not exist, an exception is thrown.
     :return: An instance of :py:class:`mlflow.entities.Experiment` representing the new active
              experiment.
 
     .. test-code-block:: python
         :caption: Example
```

## mlflow/types/utils.py

```diff
@@ -321,23 +321,29 @@
     except ImportError:
         return False
 
 
 def _validate_input_dictionary_contains_only_strings_and_lists_of_strings(data) -> None:
     invalid_keys = []
     invalid_values = []
+    value_type = None
     for key, value in data.items():
+        if not value_type:
+            value_type = type(value)
         if isinstance(key, bool):
             invalid_keys.append(key)
         elif not isinstance(key, (str, int)):
             invalid_keys.append(key)
         if isinstance(value, list) and not all(isinstance(item, str) for item in value):
             invalid_values.append(key)
-        elif not isinstance(value, (list, str)):
+        elif not isinstance(value, (np.ndarray, list, str)):
             invalid_values.append(key)
+        elif isinstance(value, np.ndarray) or value_type == np.ndarray:
+            if not isinstance(value, value_type):
+                invalid_values.append(key)
     if invalid_values:
         raise MlflowException(
             "Invalid values in dictionary. If passing a dictionary containing strings, all "
             "values must be either strings or lists of strings. If passing a dictionary containing "
             "numeric values, the data must be enclosed in a numpy.ndarray. The following keys "
             f"in the input dictionary are invalid: {invalid_values}",
             error_code=INVALID_PARAMETER_VALUE,
```

## mlflow/utils/databricks_utils.py

```diff
@@ -36,14 +36,23 @@
             return f(*args, **kwargs)
 
         return wrapper
 
     return decorator
 
 
+def get_mlflow_credential_context_by_run_id(run_id):
+    from mlflow.tracking.artifact_utils import get_artifact_uri
+    from mlflow.utils.uri import get_databricks_profile_uri_from_artifact_uri
+
+    run_root_artifact_uri = get_artifact_uri(run_id=run_id)
+    profile = get_databricks_profile_uri_from_artifact_uri(run_root_artifact_uri)
+    return MlflowCredentialContext(profile)
+
+
 class MlflowCredentialContext:
     """Sets and clears credentials on a context using the provided profile URL."""
 
     def __init__(self, databricks_profile_url):
         self.databricks_profile_url = databricks_profile_url or "databricks"
         self.db_utils = _get_dbutils()
```

## mlflow/utils/file_utils.py

```diff
@@ -1,49 +1,43 @@
 import codecs
 import errno
 import gzip
-import math
-import multiprocessing
 import os
 import posixpath
 import shutil
 import sys
 import tarfile
 import tempfile
 import stat
 import pathlib
+from contextlib import contextmanager
 
 import urllib.parse
 import urllib.request
-from pathlib import Path
-from concurrent.futures import ProcessPoolExecutor
 from urllib.parse import unquote
 from urllib.request import pathname2url
 
 import atexit
 
-import requests
 import yaml
 
 try:
     from yaml import CSafeLoader as YamlSafeLoader, CSafeDumper as YamlSafeDumper
 except ImportError:
     from yaml import SafeLoader as YamlSafeLoader, SafeDumper as YamlSafeDumper
 
-from mlflow.protos.databricks_artifacts_pb2 import ArtifactCredentialType
 from mlflow.entities import FileInfo
 from mlflow.exceptions import MissingConfigException
 from mlflow.utils.rest_utils import cloud_storage_http_request, augmented_raise_for_status
 from mlflow.utils.process import cache_return_value_per_process
 from mlflow.utils import merge_dicts
 from mlflow.utils.databricks_utils import _get_dbutils
 from mlflow.utils.os import is_windows
 
 ENCODING = "utf-8"
-MAX_PARALLEL_DOWNLOAD_WORKERS = 32
 
 
 def is_directory(name):
     return os.path.isdir(name)
 
 
 def is_file(name):
@@ -591,85 +585,14 @@
         with open(download_path, "wb") as output_file:
             for chunk in response.iter_content(chunk_size=chunk_size):
                 if not chunk:
                     break
                 output_file.write(chunk)
 
 
-def download_chunk(request_index, chunk_size, headers, download_path, http_uri):
-    range_start = chunk_size * request_index
-    range_end = range_start + chunk_size - 1
-    combined_headers = {**headers, "Range": f"bytes={range_start}-{range_end}"}
-    with cloud_storage_http_request(
-        "get", http_uri, stream=False, headers=combined_headers, cached_session=False
-    ) as response:
-        # File will have been created upstream. Use r+b to ensure chunks
-        # don't overwrite the entire file.
-        with open(download_path, "r+b") as f:
-            f.seek(range_start)
-            f.write(response.content)
-
-
-def parallelized_download_file_using_http_uri(
-    http_uri, download_path, file_size, uri_type, chunk_size, headers=None
-):
-    """
-    Downloads a file specified using the `http_uri` to a local `download_path`. This function
-    sends multiple requests in parallel each specifying its own desired byte range as a header,
-    then reconstructs the file from the downloaded chunks. This allows for downloads of large files
-    without OOM risk.
-
-    Note : This function is meant to download files using presigned urls from various cloud
-            providers.
-    Returns a dict of chunk index : exception, if one was thrown for that index.
-    """
-    num_requests = int(math.ceil(file_size / float(chunk_size)))
-    # Create file if it doesn't exist. We should do this here before sending to the workers
-    # so they can each individually seek to their respective positions and write chunks
-    # without overwriting.
-    Path(download_path).touch()
-    futures = {}
-    starting_index = 0
-    if uri_type == ArtifactCredentialType.GCP_SIGNED_URL or uri_type is None:
-        # GCP files could be transcoded, in which case the range header is ignored.
-        # Test if this is the case by downloading one chunk and seeing if it's larger than the
-        # requested size. If yes, let that be the file; if not, continue downloading more chunks.
-        download_chunk(0, chunk_size, headers, download_path, http_uri)
-        downloaded_size = os.path.getsize(download_path)
-        # If downloaded size was equal to the chunk size it would have been downloaded serially,
-        # so we don't need to consider this here
-        if downloaded_size > chunk_size:
-            return
-        else:
-            starting_index = 1
-
-    failed_downloads = {}
-    with ProcessPoolExecutor(
-        max_workers=MAX_PARALLEL_DOWNLOAD_WORKERS, mp_context=multiprocessing.get_context("fork")
-    ) as executor:
-        for i in range(starting_index, num_requests):
-            fut = executor.submit(
-                download_chunk,
-                request_index=i,
-                chunk_size=chunk_size,
-                headers=headers,
-                download_path=download_path,
-                http_uri=http_uri,
-            )
-            futures[i] = fut
-
-    for i, fut in futures.items():
-        try:
-            fut.result()
-        except requests.HTTPError as e:
-            failed_downloads[i] = e
-
-    return failed_downloads
-
-
 def _handle_readonly_on_windows(func, path, exc_info):
     """
     This function should not be called directly but should be passed to `onerror` of
     `shutil.rmtree` in order to reattempt the removal of a read-only file after making
     it writable on Windows.
 
     References:
@@ -807,7 +730,30 @@
     :param start_byte: The start byte of the chunk.
     :return: The chunk of bytes.
     """
     with open(path, "rb") as f:
         if start_byte > 0:
             f.seek(start_byte)
         return f.read(size)
+
+
+@contextmanager
+def remove_on_error(path: os.PathLike, onerror=None):
+    """
+    A context manager that removes a file or directory if an exception is raised during execution.
+
+    :param path: Path to the file or directory.
+    :param onerror: A callback function that will be called with the captured exception before
+                    the file or directory is removed. For example, you can use this callback to
+                    log the exception.
+    """
+    try:
+        yield
+    except Exception as e:
+        if onerror:
+            onerror(e)
+        if os.path.exists(path):
+            if os.path.isfile(path):
+                os.remove(path)
+            elif os.path.isdir(path):
+                shutil.rmtree(path)
+        raise
```

## mlflow/utils/requirements_utils.py

```diff
@@ -152,51 +152,35 @@
     """
     Normalizes a package name using the rule defined in PEP 503:
     https://www.python.org/dev/peps/pep-0503/#normalized-names
     """
     return _NORMALIZE_REGEX.sub("-", pkg_name).lower()
 
 
-def _get_requires(pkg_name, top_pkg_name=None):
-    if top_pkg_name is None:
-        # Assume the top package
-        top_pkg_name = pkg_name
-
-    pkg_name = _normalize_package_name(pkg_name)
-    if pkg_name not in pkg_resources.working_set.by_key:
-        return
-
-    package = pkg_resources.working_set.by_key[pkg_name]
-    reqs = package.requires()
-    if len(reqs) == 0:
-        return
-
-    for req in reqs:
-        req_name = _normalize_package_name(req.name)
-        if req_name == top_pkg_name:
-            # If the top package ends up providing himself again through a
-            # recursive dependency, we don't want to consider it as a
-            # dependency
-            continue
-
-        yield req_name
+def _get_requires(pkg_name):
+    norm_pkg_name = _normalize_package_name(pkg_name)
+    if package := pkg_resources.working_set.by_key.get(norm_pkg_name):
+        for req in package.requires():
+            yield _normalize_package_name(req.name)
 
 
-def _get_requires_recursive(pkg_name, top_pkg_name=None) -> set:
+def _get_requires_recursive(pkg_name, seen_before=None):
     """
     Recursively yields both direct and transitive dependencies of the specified
     package.
-    The `top_pkg_name` argument will track what's the top-level dependency for
-    which we want to list all sub-dependencies.
-    This ensures that we don't fall into recursive loops for packages with are
-    dependant on each other.
     """
-    for req in _get_requires(pkg_name, top_pkg_name):
+    norm_pkg_name = _normalize_package_name(pkg_name)
+    seen_before = seen_before or {norm_pkg_name}
+    for req in _get_requires(pkg_name):
+        # Prevent infinite recursion due to cyclic dependencies
+        if req in seen_before:
+            continue
+        seen_before.add(req)
         yield req
-        yield from _get_requires_recursive(req, top_pkg_name)
+        yield from _get_requires_recursive(req, seen_before)
 
 
 def _prune_packages(packages):
     """
     Prunes packages required by other packages. For example, `["scikit-learn", "numpy"]` is pruned
     to `["scikit-learn"]`.
     """
@@ -382,15 +366,15 @@
     _init_modules_to_packages_map()
     global _PYPI_PACKAGE_INDEX
     if _PYPI_PACKAGE_INDEX is None:
         _PYPI_PACKAGE_INDEX = _load_pypi_package_index()
 
     modules = _capture_imported_modules(model_uri, flavor)
     packages = _flatten([_MODULES_TO_PACKAGES.get(module, []) for module in modules])
-    packages = map(_normalize_package_name, packages)
+    packages = set(map(_normalize_package_name, packages))
     packages = _prune_packages(packages)
     excluded_packages = [
         # Certain packages (e.g. scikit-learn 0.24.2) imports `setuptools` or `pkg_resources`
         # (a module provided by `setuptools`) to process or interact with package metadata.
         # It should be safe to exclude `setuptools` because it's rare to encounter a python
         # environment where `setuptools` is not pre-installed.
         "setuptools",
```

## mlflow/utils/rest_utils.py

```diff
@@ -1,9 +1,10 @@
 import base64
 import json
+import os
 
 import requests
 from requests.adapters import HTTPAdapter
 from requests.exceptions import HTTPError
 import urllib3
 from functools import lru_cache
 from packaging.version import Version
@@ -36,28 +37,25 @@
         503,  # Service Unavailable
         504,  # Gateway Timeout
     ]
 )
 
 
 @lru_cache(maxsize=64)
-def _get_request_session(max_retries, backoff_factor, retry_codes):
-    return _get_request_session_uncached(max_retries, backoff_factor, retry_codes)
-
-
-def _get_request_session_uncached(max_retries, backoff_factor, retry_codes):
+def _cached_get_request_session(
+    max_retries,
+    backoff_factor,
+    retry_codes,
+    # To create a new Session object for each process, we use the process id as the cache key.
+    # This is to avoid sharing the same Session object across processes, which can lead to issues
+    # such as https://stackoverflow.com/q/3724900.
+    _pid,
+):
     """
-    Returns a Requests.Session object for making HTTP request.
-
-    :param max_retries: Maximum total number of retries.
-    :param backoff_factor: a time factor for exponential backoff. e.g. value 5 means the HTTP
-      request will be retried with interval 5, 10, 20... seconds. A value of 0 turns off the
-      exponential backoff.
-    :param retry_codes: a list of HTTP response error codes that qualifies for retry.
-    :return: requests.Session object.
+    This function should not be called directly. Instead, use `_get_request_session` below.
     """
     assert 0 <= max_retries < 10
     assert 0 <= backoff_factor < 120
 
     retry_kwargs = {
         "total": max_retries,
         "connect": max_retries,
@@ -76,36 +74,51 @@
     adapter = HTTPAdapter(max_retries=retry)
     session = requests.Session()
     session.mount("https://", adapter)
     session.mount("http://", adapter)
     return session
 
 
+def _get_request_session(max_retries, backoff_factor, retry_codes):
+    """
+    Returns a `Requests.Session` object for making an HTTP request.
+
+    :param max_retries: Maximum total number of retries.
+    :param backoff_factor: a time factor for exponential backoff. e.g. value 5 means the HTTP
+      request will be retried with interval 5, 10, 20... seconds. A value of 0 turns off the
+      exponential backoff.
+    :param retry_codes: a list of HTTP response error codes that qualifies for retry.
+    :return: requests.Session object.
+    """
+    return _cached_get_request_session(
+        max_retries,
+        backoff_factor,
+        retry_codes,
+        _pid=os.getpid(),
+    )
+
+
 def _get_http_response_with_retries(
-    method, url, max_retries, backoff_factor, retry_codes, cached_session=True, **kwargs
+    method, url, max_retries, backoff_factor, retry_codes, **kwargs
 ):
     """
     Performs an HTTP request using Python's `requests` module with an automatic retry policy.
 
     :param method: a string indicating the method to use, e.g. "GET", "POST", "PUT".
     :param url: the target URL address for the HTTP request.
     :param max_retries: Maximum total number of retries.
     :param backoff_factor: a time factor for exponential backoff. e.g. value 5 means the HTTP
       request will be retried with interval 5, 10, 20... seconds. A value of 0 turns off the
       exponential backoff.
     :param retry_codes: a list of HTTP response error codes that qualifies for retry.
-    :param cached_session: Whether to cache session object. False used for multiprocessing contexts.
     :param kwargs: Additional keyword arguments to pass to `requests.Session.request()`
 
     :return: requests.Response object.
     """
-    if cached_session:
-        session = _get_request_session(max_retries, backoff_factor, retry_codes)
-    else:
-        session = _get_request_session_uncached(max_retries, backoff_factor, retry_codes)
+    session = _get_request_session(max_retries, backoff_factor, retry_codes)
     return session.request(method, url, **kwargs)
 
 
 def http_request(
     host_creds,
     endpoint,
     method,
@@ -307,44 +320,41 @@
 def cloud_storage_http_request(
     method,
     url,
     max_retries=5,
     backoff_factor=2,
     retry_codes=_TRANSIENT_FAILURE_RESPONSE_CODES,
     timeout=None,
-    cached_session=True,
     **kwargs,
 ):
     """
     Performs an HTTP PUT/GET/PATCH request using Python's `requests` module with automatic retry.
 
     :param method: string of 'PUT' or 'GET' or 'PATCH', specify to do http PUT or GET or PATCH
     :param url: the target URL address for the HTTP request.
     :param max_retries: maximum number of retries before throwing an exception.
     :param backoff_factor: a time factor for exponential backoff. e.g. value 5 means the HTTP
       request will be retried with interval 5, 10, 20... seconds. A value of 0 turns off the
       exponential backoff.
     :param retry_codes: a list of HTTP response error codes that qualifies for retry.
     :param timeout: wait for timeout seconds for response from remote server for connect and
       read request. Default to None owing to long duration operation in read / write.
-    :param cached_session: Whether to cache session object. False used for multiprocessing contexts.
     :param kwargs: Additional keyword arguments to pass to `requests.Session.request()`
 
     :return requests.Response object.
     """
     if method.lower() not in ("put", "get", "patch", "delete"):
         raise ValueError("Illegal http method: " + method)
     return _get_http_response_with_retries(
         method,
         url,
         max_retries,
         backoff_factor,
         retry_codes,
         timeout=timeout,
-        cached_session=cached_session,
         **kwargs,
     )
 
 
 class MlflowHostCreds:
     """
     Provides a hostname and optional authentication for talking to an MLflow tracking server.
```

## mlflow/utils/search_utils.py

```diff
@@ -41,44 +41,69 @@
 
 def _ilike(string, pattern):
     return _convert_like_pattern_to_regex(pattern, flags=re.IGNORECASE).match(string) is not None
 
 
 def _join_in_comparison_tokens(tokens):
     """
-    If a given list of tokens matches the pattern of an IN comparison or a NOT IN comparison,
+    Find a sequence of tokens that matches the pattern of an IN comparison or a NOT IN comparison,
     join the tokens into a single Comparison token. Otherwise, return the original list of tokens.
     """
     if Version(sqlparse.__version__) < Version("0.4.4"):
         # In sqlparse < 0.4.4, IN is treated as a comparison, we don't need to join tokens
         return tokens
 
-    tokens = [t for t in tokens if not t.is_whitespace]
-    num_tokens = len(tokens)
-    # IN
-    if num_tokens == 3:
-        first, second, third = tokens
+    non_whitespace_tokens = [t for t in tokens if not t.is_whitespace]
+    joined_tokens = []
+    num_tokens = len(non_whitespace_tokens)
+    iterator = enumerate(non_whitespace_tokens)
+    while elem := next(iterator, None):
+        index, first = elem
+        # We need at least 3 tokens to form an IN comparison or a NOT IN comparison
+        if num_tokens - index < 3:
+            joined_tokens.extend(non_whitespace_tokens[index:])
+            break
+
+        # Wait until we encounter an identifier token
+        if not isinstance(first, Identifier):
+            joined_tokens.append(first)
+            continue
+
+        (_, second) = next(iterator)
+        (_, third) = next(iterator)
+
+        # IN
         if (
             isinstance(first, Identifier)
             and second.match(ttype=TokenType.Keyword, values=["IN"])
             and isinstance(third, Parenthesis)
         ):
-            return [Comparison(TokenList(tokens))]
-    # NOT IN
-    elif num_tokens == 4:
-        first, second, third, fourth = tokens
+            joined_tokens.append(Comparison(TokenList([first, second, third])))
+            continue
+
+        (_, fourth) = next(iterator, (None, None))
+        if fourth is None:
+            joined_tokens.extend([first, second, third])
+            break
+
+        # NOT IN
         if (
             isinstance(first, Identifier)
             and second.match(ttype=TokenType.Keyword, values=["NOT"])
             and third.match(ttype=TokenType.Keyword, values=["IN"])
             and isinstance(fourth, Parenthesis)
         ):
-            return [Comparison(TokenList([first, Token(TokenType.Keyword, "NOT IN"), fourth]))]
+            joined_tokens.append(
+                Comparison(TokenList([first, Token(TokenType.Keyword, "NOT IN"), fourth]))
+            )
+            continue
+
+        joined_tokens.extend([first, second, third, fourth])
 
-    return tokens
+    return joined_tokens
 
 
 class SearchUtils:
     LIKE_OPERATOR = "LIKE"
     ILIKE_OPERATOR = "ILIKE"
     ASC_OPERATOR = "asc"
     DESC_OPERATOR = "desc"
```

## mlflow/utils/virtualenv.py

```diff
@@ -1,19 +1,20 @@
 import os
 import logging
 import shutil
 import uuid
 import re
+import sys
 from pathlib import Path
 from packaging.version import Version
 
 import mlflow
 from mlflow.exceptions import MlflowException
 from mlflow.models.model import Model, MLMODEL_FILE_NAME
-from mlflow.utils.file_utils import TempDir
+from mlflow.utils.file_utils import TempDir, remove_on_error
 from mlflow.utils.process import _exec_cmd, _join_commands, _IS_UNIX
 from mlflow.utils.requirements_utils import _parse_requirements
 from mlflow.utils.environment import (
     _PythonEnv,
     _PYTHON_ENV_FILE_NAME,
     _CONDA_ENV_FILE_NAME,
     _REQUIREMENTS_FILE_NAME,
@@ -216,15 +217,15 @@
 def _get_virtualenv_name(python_env, work_dir_path, env_id=None):
     requirements = _parse_requirements(
         python_env.dependencies,
         is_constraint=False,
         base_dir=work_dir_path,
     )
     return _get_mlflow_env_name(
-        str(python_env) + "".join(x.req_str for x in requirements) + (env_id or "")
+        str(python_env) + "".join(map(str, sorted(requirements))) + (env_id or "")
     )
 
 
 def _create_virtualenv(
     local_model_path, python_bin_path, env_dir, python_env, extra_env=None, capture_output=False
 ):
     # Created a command to activate the environment
@@ -232,45 +233,61 @@
     activate_cmd = env_dir.joinpath(*paths)
     activate_cmd = f"source {activate_cmd}" if _IS_UNIX else activate_cmd
 
     if env_dir.exists():
         _logger.info("Environment %s already exists", env_dir)
         return activate_cmd
 
-    _logger.info("Creating a new environment in %s with %s", env_dir, python_bin_path)
-    _exec_cmd(["virtualenv", "--python", python_bin_path, env_dir], capture_output=capture_output)
+    with remove_on_error(
+        env_dir,
+        onerror=lambda e: _logger.warning(
+            "Encountered an unexpected error: %s while creating a virtualenv environment in %s, "
+            "removing the environment directory...",
+            repr(e),
+            env_dir,
+        ),
+    ):
+        _logger.info("Creating a new environment in %s with %s", env_dir, python_bin_path)
+        _exec_cmd(
+            [sys.executable, "-m", "virtualenv", "--python", python_bin_path, env_dir],
+            capture_output=capture_output,
+        )
 
-    _logger.info("Installing dependencies")
-    for deps in filter(None, [python_env.build_dependencies, python_env.dependencies]):
-        with TempDir() as t:
-            # Create a temporary requirements file in the model directory to resolve the references
-            # in it correctly. To do this, we must first symlink or copy the model directory's
-            # contents to a temporary location for compatibility with deployment tools that store
-            # models in a read-only mount
-            tmp_model_dir = t.path("model")
-            os.makedirs(tmp_model_dir)
-            try:
-                for model_item in os.listdir(local_model_path):
-                    os.symlink(
-                        src=os.path.join(local_model_path, model_item),
-                        dst=os.path.join(tmp_model_dir, model_item),
+        _logger.info("Installing dependencies")
+        for deps in filter(None, [python_env.build_dependencies, python_env.dependencies]):
+            with TempDir() as t:
+                # Create a temporary requirements file in the model directory to resolve the
+                # references in it correctly. To do this, we must first symlink or copy the model
+                # directory's contents to a temporary location for compatibility with deployment
+                # tools that store models in a read-only mount
+                tmp_model_dir = t.path("model")
+                os.makedirs(tmp_model_dir)
+                try:
+                    for model_item in os.listdir(local_model_path):
+                        os.symlink(
+                            src=os.path.join(local_model_path, model_item),
+                            dst=os.path.join(tmp_model_dir, model_item),
+                        )
+                except Exception as e:
+                    _logger.warning(
+                        "Failed to symlink model directory during dependency installation"
+                        " Copying instead. Exception: %s",
+                        e,
                     )
-            except Exception as e:
-                _logger.warning(
-                    "Failed to symlink model directory during dependency installation"
-                    " Copying instead. Exception: %s",
-                    e,
-                )
-                shutil.rmtree(tmp_model_dir)
-                _copy_model_to_writeable_destination(local_model_path, tmp_model_dir)
+                    shutil.rmtree(tmp_model_dir)
+                    _copy_model_to_writeable_destination(local_model_path, tmp_model_dir)
 
-            tmp_req_file = f"requirements.{uuid.uuid4().hex}.txt"
-            Path(tmp_model_dir).joinpath(tmp_req_file).write_text("\n".join(deps))
-            cmd = _join_commands(activate_cmd, f"python -m pip install --quiet -r {tmp_req_file}")
-            _exec_cmd(cmd, capture_output=capture_output, cwd=tmp_model_dir, extra_env=extra_env)
+                tmp_req_file = f"requirements.{uuid.uuid4().hex}.txt"
+                Path(tmp_model_dir).joinpath(tmp_req_file).write_text("\n".join(deps))
+                cmd = _join_commands(
+                    activate_cmd, f"python -m pip install --quiet -r {tmp_req_file}"
+                )
+                _exec_cmd(
+                    cmd, capture_output=capture_output, cwd=tmp_model_dir, extra_env=extra_env
+                )
 
     return activate_cmd
 
 
 def _copy_model_to_writeable_destination(model_src, dst):
     """
     Copies the specified `model_src` directory, which may be read-only, to the writeable `dst`
```

## Comparing `mlflow_skinny-2.3.0.dist-info/LICENSE.txt` & `mlflow_skinny-2.3.1.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `mlflow_skinny-2.3.0.dist-info/METADATA` & `mlflow_skinny-2.3.1.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mlflow-skinny
-Version: 2.3.0
+Version: 2.3.1
 Summary: MLflow: A Platform for ML Development and Productionization
 Home-page: https://mlflow.org/
 Author: Databricks
 License: Apache License 2.0
 Project-URL: Bug Tracker, https://github.com/mlflow/mlflow/issues
 Project-URL: Documentation, https://mlflow.org/docs/latest/index.html
 Project-URL: Source Code, https://github.com/mlflow/mlflow
@@ -36,16 +36,16 @@
 Requires-Dist: pyarrow ; extra == 'extras'
 Requires-Dist: requests-auth-aws-sigv4 ; extra == 'extras'
 Requires-Dist: boto3 ; extra == 'extras'
 Requires-Dist: google-cloud-storage (>=1.30.0) ; extra == 'extras'
 Requires-Dist: azureml-core (>=1.2.0) ; extra == 'extras'
 Requires-Dist: pysftp ; extra == 'extras'
 Requires-Dist: kubernetes ; extra == 'extras'
-Requires-Dist: mlserver (<1.3,>=1.2.0) ; extra == 'extras'
-Requires-Dist: mlserver-mlflow (<1.3,>=1.2.0) ; extra == 'extras'
+Requires-Dist: mlserver (!=1.3.1,>=1.2.0) ; extra == 'extras'
+Requires-Dist: mlserver-mlflow (!=1.3.1,>=1.2.0) ; extra == 'extras'
 Requires-Dist: virtualenv ; extra == 'extras'
 Requires-Dist: prometheus-flask-exporter ; extra == 'extras'
 Provides-Extra: sqlserver
 Requires-Dist: mlflow-dbstore ; extra == 'sqlserver'
 
 =======================================================================
 MLflow Skinny: A Lightweight Machine Learning Lifecycle Platform Client
```

## Comparing `mlflow_skinny-2.3.0.dist-info/RECORD` & `mlflow_skinny-2.3.1.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -21,17 +21,17 @@
 mlflow/prophet.py,sha256=ky-BS3l3Wzuu9hQt_Zjj-_TKgrT-MLSNQbI48td_JrU,14024
 mlflow/pypi_package_index.json,sha256=m8hqgBvkDklIKN96nTB1L1Iv6tmXERj4tTF1rw1ATYI,7197781
 mlflow/runs.py,sha256=Cq5zpln9gsgBn28ZfqZFdDcztB5heOOwLd4vFtNaVn8,2519
 mlflow/shap.py,sha256=kUXkHNWPOXxtMFnJbmGBqOX6CZNfP_LEL72kjmr0yFE,26647
 mlflow/spacy.py,sha256=_mwaaEmsBA3vmb0j0nqn6-cpLzrtB45RMXBpMskteDU,14259
 mlflow/spark.py,sha256=vpoS66wJMh1nzHrEzsKyzoc11GRymgCFHa_GFIVFQ9M,44813
 mlflow/statsmodels.py,sha256=hY361425k4A41yhMk8LINeHeALHgJpHOKDAXPX6qt2E,24596
-mlflow/transformers.py,sha256=Kg71aLLon7Hq6ChZoNPTxxe9XG21j3mX8X1kTjhj24g,84167
-mlflow/version.py,sha256=Hzb6qTUU7HpbDirei5xJBGfIBNgs37ia9X-5upKv7nE,147
-mlflow/artifacts/__init__.py,sha256=3w4QqluikzBFcDoFcNBgDBuFDN1IKdd1AP_MO4U7-zY,6350
+mlflow/transformers.py,sha256=cTFi2CBcnTaSQRbVIU5YQclIhgXU8sQnad_dTp689nk,89127
+mlflow/version.py,sha256=paS2HJMvrkTocV_KMVjw_1V4diIfVjPz5Vh6sW9prks,147
+mlflow/artifacts/__init__.py,sha256=W2xDlKsxSvEORf1PZcAD66eKXdZVpTFYelG5vAq-kc4,6485
 mlflow/azure/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/azure/client.py,sha256=SjMkSbTz7-tjBwu7hsFF7t8hlGCk3iuDVtaBUO6y1rA,11647
 mlflow/deployments/__init__.py,sha256=bgGe2fP-vIlN5JBwnE0XiEq4nAZwgOX-O1S5CcxyAcE,3797
 mlflow/deployments/base.py,sha256=HW8SzV88XJvax8U1gyCwGwNUnoXtSbxgEF-NtEQGcDs,15572
 mlflow/deployments/cli.py,sha256=NC583nod0ZHXeaNOyqK2fgRx7lfP8mjqjMW5G-smZV4,15078
 mlflow/deployments/interface.py,sha256=nqJtP5eNKW3_we-IGFMfFwE0Rv-ew0HxXz61mZ141Og,3825
 mlflow/deployments/plugin_manager.py,sha256=0M-aHMtBjeqdtlfdzMZ-LXX2iWsnkZnsf2055vaO0eE,5512
@@ -60,40 +60,40 @@
 mlflow/entities/model_registry/registered_model.py,sha256=tujJutEpg0P1yZjeJpfkwgTZ6FCiTOVwUo2o9zJp4bE,4933
 mlflow/entities/model_registry/registered_model_alias.py,sha256=zDTE-1HDh5j3mmBa2eOIqPE3qUWaJ3-gwzbHGPBtDfE,1053
 mlflow/entities/model_registry/registered_model_tag.py,sha256=9rh0zbxvcPE8KJFWBe_zONF7wiZ7gJjr8AoIEY9jqSQ,948
 mlflow/fastai/__init__.py,sha256=E_UFBE3kKJLe6prmjRx8lx6fF8oEao78VLNl17XgzPQ,25354
 mlflow/fastai/callback.py,sha256=RLK4TWHMnRXzvTsaJa09nXJQd67cs8Vqfztk_QmRDE8,5757
 mlflow/gluon/__init__.py,sha256=rbMdOEnNIH9fgmiIX8I9vYGhZ06ZVKVoABYuiRAZMKU,19063
 mlflow/gluon/_autolog.py,sha256=VyS3mtXdg7_XzgRw936dzbfD5Vb3tzQiWNmUs6UZ3JQ,2020
-mlflow/langchain/__init__.py,sha256=f2JyzXaFOcNg5KflhCZjkXq4y6AT0Exy4ciYGGpQLfQ,16643
-mlflow/langchain/api_request_parallel_processor.py,sha256=qOy1u5uLDKhiuAfyIsutZO4DgBg7aCm2Tnn6XEAe2VM,4781
-mlflow/models/__init__.py,sha256=-8vwoDZ4WPn_lvCnMfxaDXKcLq1yyGDFk_a4IC7mfMo,3326
+mlflow/langchain/__init__.py,sha256=v4DcE8X4fISfifZTA7-ruSbr1wI3QrcDeZYMnrIeB5s,16643
+mlflow/langchain/api_request_parallel_processor.py,sha256=9ZGfJF6jLLPj2i-LFzD_5fYbETdFEwu0JWp3cJT5QC0,4846
+mlflow/models/__init__.py,sha256=lRhJ7uI2mX2xYYiFJ6LS_4J795Vq36vC9ZDTdhluc_Y,3627
 mlflow/models/cli.py,sha256=R4-Jg5RuHYG6wdD4xUMBpWVZh0T-FwmAHu1Ng_VUvBs,9803
 mlflow/models/docker_utils.py,sha256=sE3wheLGR67zn-7Po4HeyRWXQz2bI92-fJRY2idX43g,9853
 mlflow/models/flavor_backend.py,sha256=saS7_-atraIHizYeBMesKuytwtUe_TAVpleDMKUhV_E,3420
 mlflow/models/flavor_backend_registry.py,sha256=2z5S2jxaxL0hBiIhyKaMwb0JzYogh7qemoqp1xhkeU8,2354
 mlflow/models/model.py,sha256=gzISxCps9iHo9eFVrhGYCVecevFvaTdwvb7lXqZA780,23802
 mlflow/models/signature.py,sha256=iKyhOPeTSzL9zRTyOL2cg5yuzudABe5JHHHE6jid5KA,8634
-mlflow/models/utils.py,sha256=M5IfFU-trViJ3FDDc6JSU3JqvIQEVj32vXzpr0Hmwp0,36823
+mlflow/models/utils.py,sha256=J6jxz2q4vm4C4PY2j21XlG72BS9b4-O9vUGRqNlgxPs,38033
 mlflow/models/wheeled_model.py,sha256=aQT2LUntdd6hOVbKUD5ylU15_4-ofmIz2wjjCbJG8MY,11707
-mlflow/models/container/__init__.py,sha256=-GSSWCQ9zhIA4efTlhjma2AIhqWzKOndWKjb3MULC5g,9383
+mlflow/models/container/__init__.py,sha256=EqQ-YlPEpJfuutN-ggE3ATNr-CIVu-KT4-p4kHU9olE,9387
 mlflow/models/container/scoring_server/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/models/container/scoring_server/wsgi.py,sha256=lKHH1eNI2BR24UznnPlhIcUdFbUBxMSwJVoFXaBw7Lo,131
 mlflow/models/evaluation/__init__.py,sha256=cYGpHa-yh7Z7vpD48A_G5jFuvoLu2raHcezyA_GnIGk,491
 mlflow/models/evaluation/_shap_patch.py,sha256=oS3ym9uuTbb5g7s3rhCvl4vJFeB3ROK67wm1Rw_OmV4,3105
 mlflow/models/evaluation/artifacts.py,sha256=ZpQEbhLtsewUEfx5jT4Dz29UwbBGoXAGIOcLTZlOmD0,6769
 mlflow/models/evaluation/base.py,sha256=CaAi9auv-hJ7VlBzr670CO9NEFakLNbkOsRJO14SDf0,59205
 mlflow/models/evaluation/default_evaluator.py,sha256=ZiYTE3HNWuDBU2he3CERd2DNNiu17kF4cU-J8uEIqhg,50976
 mlflow/models/evaluation/evaluator_registry.py,sha256=_0BtXeHdXP0SpgEjpHbIzPqPzbydkXVpw7KMM10ldRg,2036
 mlflow/models/evaluation/lift_curve.py,sha256=8Ik5enKivwzg4IgUYW68TIEwJdrTc-lsDtPfdgtOOVM,6223
 mlflow/models/evaluation/validation.py,sha256=rS0DYVyiraGNAwgtp7lSbruIxzhhZe-RzCjNrtQj2ds,10946
-mlflow/openai/__init__.py,sha256=Z19MuC5X069bJSUkiCSWemaozp8EJAie0z55hcsuf5w,20642
-mlflow/openai/api_request_parallel_processor.py,sha256=LedT4z8kwpsPre5fpkXhGbI85sRHJ_l-eFsd-068SkE,12150
+mlflow/openai/__init__.py,sha256=wr-a3uWEkv7Z8tkYt-Uf7UYw1m1EkdQHsi9iLc_ZXP4,23159
+mlflow/openai/api_request_parallel_processor.py,sha256=55dyFj_wgF46qt_CbNfF6Vy1oj1Pi23xpx7g1yBlU_E,12309
 mlflow/openai/retry.py,sha256=LTybicz35wnwqWI82TyEtfA42K_LIIGIAQkg_tECfOQ,2936
-mlflow/openai/utils.py,sha256=8dv9TMgQdyr8ftx9sJ1LUYjMwldQzjX2YheGRzsO3K4,1862
+mlflow/openai/utils.py,sha256=7qxqw-MMKNAKZtyZ_PLrLDMvzJ99_F2Ti7UJlt8jpyc,2040
 mlflow/paddle/__init__.py,sha256=3GDLeJPh1SE7VNbMDT5PkETvolvI5DGq4PFnuAIrO2U,23859
 mlflow/paddle/_paddle_autolog.py,sha256=320HLsBXVehs1ipElTT1M2h6AaxhmPnCp37ViWKnzN4,4792
 mlflow/projects/__init__.py,sha256=bbjwU6ZguNNdUnt64bGEqYDCrhJnhCnMKzrfIebnAzw,17396
 mlflow/projects/_project_spec.py,sha256=f1vXIPtrGkiopD9CHmJ1suziVs-n2eKf7Dv__xaqidE,11532
 mlflow/projects/databricks.py,sha256=vnZu3_lCx5-g6WVyRRnA2dbOY5_JfsjoLA22KLy-61o,20270
 mlflow/projects/docker.py,sha256=GFYSpkXJUeYYDX1dn2az_aGRugIByEc69haisFE2jsk,6394
 mlflow/projects/env_type.py,sha256=bFyfa0G6xJv-N6B0jYruHuS6emHDOzbrNcsJkCzWTDQ,94
@@ -103,23 +103,23 @@
 mlflow/projects/backend/__init__.py,sha256=aEVrYLweP_wBxJEHJ9hJ8ZbFaFmbJot_z44wO61swck,271
 mlflow/projects/backend/abstract_backend.py,sha256=0EDJucLNKn1BZG-eUTlXhdKw5Uj9zT_VFb-ZR0-zCdk,2210
 mlflow/projects/backend/loader.py,sha256=d-2g2jFdvXkivDTSL7jYe61aPgfr1r_S2vEgVtJKGoQ,1079
 mlflow/projects/backend/local.py,sha256=4NfYiJsCjCJueM0vzsQUq58SoNEAB4Q4wjvmPS6YAnQ,17240
 mlflow/protos/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/protos/databricks_artifacts_pb2.py,sha256=VWImBxApMcc9YBCG1TNkNvLXf4PXl4kjb4UZGzKaosc,17261
 mlflow/protos/databricks_pb2.py,sha256=zIkESpGJ18X6xJTzpQ2GKCdjw88v2TtmCkBkZ9TnTxk,14095
-mlflow/protos/databricks_uc_registry_messages_pb2.py,sha256=U-wk_IkGR4qQLjOU8g6Mum6y05wlpu2qSQvoEE9wfiI,32279
-mlflow/protos/databricks_uc_registry_service_pb2.py,sha256=kDiW-GUCr_ssJpvgCCMgxsI6luS5O_ApWxgkhQIZmUw,10491
+mlflow/protos/databricks_uc_registry_messages_pb2.py,sha256=fpkbLkDC-dyKJRI6nQF_t8c_YRGPS2x3jN7g0HU7xTk,38674
+mlflow/protos/databricks_uc_registry_service_pb2.py,sha256=uc5lgb7HHaf9lbx60yLdzuRkyMqPd4Hai2l0QRcdtsY,12471
 mlflow/protos/facet_feature_statistics_pb2.py,sha256=1PV53cuL1c8Gq_jWT812Ofber3r_i0MYtcgPR_Zgggc,16146
 mlflow/protos/mlflow_artifacts_pb2.py,sha256=8zpiVKh77RSVpuRS9YG7Z4hczOEvvyCyGAGWKIibxW8,8552
 mlflow/protos/model_registry_pb2.py,sha256=1SuViyljo-k4Gftvx5mp2lkCTw9OQezkUZFVONjIaD4,54475
 mlflow/protos/service_pb2.py,sha256=AxxG8Dg8BaqO_hMaRiX55zP0XADfC4mCV0THIQsxkOI,48593
 mlflow/protos/scalapb/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/protos/scalapb/scalapb_pb2.py,sha256=G1jfOHJ01ckKPQUGz63GM6LH5fCDPOsuGaihtHeWIeo,3307
-mlflow/pyfunc/__init__.py,sha256=W0f1nM7mtuwecbxGBAWgd5Ic2nnVhobLwyzWSgipUbQ,79843
+mlflow/pyfunc/__init__.py,sha256=uytUy7aqh0l4gy-4K7zF5g8rFQBocsmrkojynxkxL_Q,81392
 mlflow/pyfunc/backend.py,sha256=yTXTjnwThmj6QDEs9Cg8lX1IzXuD_AM9yknwnd5jFXc,16640
 mlflow/pyfunc/mlserver.py,sha256=FXo7UL1NiQEUKOoeKwnqfb-x0cCHcYRIczzQqPdq2Dk,901
 mlflow/pyfunc/model.py,sha256=GJRCyouKLKt-m-PV0L665dhZTYF9DcbRiR_YDirottM,15392
 mlflow/pyfunc/spark_model_cache.py,sha256=WRo9JllyFWyHs1XCA_kKMSCXjOKkk5aJWIWAuyi55Xo,2124
 mlflow/pyfunc/stdin_server.py,sha256=IqsCVUQoFAnEeAW79jEUad07bsKf5IC1lQSbTWLTtjw,1001
 mlflow/pyfunc/scoring_server/__init__.py,sha256=Ro7vCpIM4YDrPOPLLxti4KKf2rioBP8XYYKw6xvCO34,13910
 mlflow/pyfunc/scoring_server/client.py,sha256=nyLWhvNtbGdHX15BYLpkVdbGfwp30qU5HkCSlbpBr8s,4222
@@ -136,15 +136,15 @@
 mlflow/recipes/artifacts.py,sha256=lookDwTqTogrTwN9gWYpOrvz1evczyaPT0PLGpx3Y_8,6092
 mlflow/recipes/cli.py,sha256=Gfp7h6p5lfrhvbml-zOa6PaAmmsg7L3eFeN-qQeT2OM,2917
 mlflow/recipes/dag_help_strings.py,sha256=_bCnPO1U48BLyZKjJxFbkWD63ETMbfAGzYlmy8_98EU,18431
 mlflow/recipes/recipe.py,sha256=k0tWk2fUt0NEdkQ5J2NW75RqQAEpxmhI1dyAghCrxTc,17933
 mlflow/recipes/step.py,sha256=pgyOTJECcGtfmlL_2aMCA9FAWVx-ECGNHOCH9rfMQGQ,14988
 mlflow/recipes/cards/__init__.py,sha256=QCKgDj_MsFtLMJXkAksMmTZX83wR-MSSBEyPtQ-pnxk,10229
 mlflow/recipes/cards/histogram_generator.py,sha256=jpkYAEguqj__rVc6x8GiBScg2CYntFYB1eoxhlSFnFw,4780
-mlflow/recipes/cards/pandas_renderer.py,sha256=35rrlDlxu8cW0_3p6EYtOu4J_bfMA5jNnuAdf6Od0W0,12472
+mlflow/recipes/cards/pandas_renderer.py,sha256=uE78bIqzcATVv1Sv-OEE5VXx-xa5S725g23LaRcBMbg,12548
 mlflow/recipes/cards/templates/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/recipes/classification/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/recipes/classification/v1/__init__.py,sha256=hAM4dOFlY7lxK0id-o8nMEU5T-bS61HX-Dg_lM-DAV8,122
 mlflow/recipes/classification/v1/recipe.py,sha256=uLcCMK9Lk0Yy95H-BNyoyY6C3w72meU7rKWWEfS6Erk,20462
 mlflow/recipes/regression/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/recipes/regression/v1/__init__.py,sha256=2EBP02c-XBelnFtygfk4fzKGLVM-j8Zj1G7J1MA53nA,114
 mlflow/recipes/regression/v1/recipe.py,sha256=YwSRNitJ2lgP9fj5NpwYSb9pzhOXLi85On6fEKAWJ6Y,22495
@@ -166,49 +166,49 @@
 mlflow/recipes/utils/tracking.py,sha256=RbwkaLYXxbr2qroKuRX3_WD_S8_7SNF-OIuZnWW4Dbk,12375
 mlflow/recipes/utils/wrapped_recipe_model.py,sha256=pxIzmFFrhnG8vxORiks8gCNzpOKD7cUinS56bN48uJE,1748
 mlflow/rfunc/__init__.py,sha256=KoOBWfS067bdWVE_Oik9CcydcByDqgJ8kR_3lWMvj9Q,1115
 mlflow/rfunc/backend.py,sha256=uEh6v4F_YwDprZxqMhMIhFekXXXG5LL0mWsoqq2ZdlM,3643
 mlflow/sagemaker/__init__.py,sha256=VE_6UT4pWqIWs9U8hyq7g361BKP9KB4x0S29GNj5e88,135097
 mlflow/sagemaker/cli.py,sha256=mRnNue9iZ4wdY_NX1zCxCLmgK0OR3gX2iKscfvYWZR0,12986
 mlflow/server/__init__.py,sha256=bD5aB3XiNJeqbcs69FgYBKJYNETUYk7tdSBMhN1Nq90,6460
-mlflow/server/handlers.py,sha256=zEVzOYfbWirVqWaSM0sUVtxikSklWgKyyW3Z14Ldhto,66811
+mlflow/server/handlers.py,sha256=9rPLAeWgjcOJLsGlPJvXpPQ7UP4C97Dipnn-cGzu5YE,68590
 mlflow/server/prometheus_exporter.py,sha256=iRXEy5vl4rs7LxzxTxw41BZbunqVlN5Oj1P-EEVynDA,481
 mlflow/server/auth/__init__.py,sha256=tJKsrMx24jV-gtv48BD83h4Y70AxhIMsq0L6O9CFxos,4551
 mlflow/server/auth/config.py,sha256=uArzDei2s4ezVIwsLoAQeT3GksU-KUXleXlGpfK0ldU,409
 mlflow/server/auth/entities.py,sha256=SXHghWADzS8v3QxC2iJHLOoxoJHZw-ro0TDY1H959YY,2384
 mlflow/server/auth/sqlalchemy_store.py,sha256=5HQWaNaq6dZO0G8gx5wk9T9OyJYXRB6Lc-y9f_jNQ5M,5303
 mlflow/sklearn/__init__.py,sha256=08ec0z1JL6Ll9tILsF7TAV4IpjtlYJLd5At3Tfv86Ds,82134
 mlflow/sklearn/utils.py,sha256=Ia8p5A6xpun4bxwJ92uA4zaQ3daMDpeWvdctBnkjbdY,37485
 mlflow/store/__init__.py,sha256=Yr-KM9CsOUALInyZdgvizb8eCXysBU8UZdkABruVd8A,227
 mlflow/store/_unity_catalog/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/store/_unity_catalog/registry/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-mlflow/store/_unity_catalog/registry/rest_store.py,sha256=WkH4UxANHIg9kMunlX7CiiMG-9ddcHOztJ9aQdZBiao,24217
-mlflow/store/_unity_catalog/registry/utils.py,sha256=Uw_SWq_pb3Jij5_dO3JYBF-3O9ZaKvnfmIrFf4-oT0Q,3519
+mlflow/store/_unity_catalog/registry/rest_store.py,sha256=k6TX6vfj1cDRPLg8OZxUHZ9IFNly7wK6BZXF4BNP1Sk,25610
+mlflow/store/_unity_catalog/registry/utils.py,sha256=V8hciFJhGhxlRwXdA7BsBimdoHWDh3ozw0QcIE5RO6U,4276
 mlflow/store/artifact/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-mlflow/store/artifact/artifact_repo.py,sha256=JfAAoz8HbydwfH_A9rI0ovUEwC2bklcxkKn0ogibHRM,14956
+mlflow/store/artifact/artifact_repo.py,sha256=OA4iMT86dgdOyuJytQGC-Ku5aVroxnQRszk7flzFwyE,15034
 mlflow/store/artifact/artifact_repository_registry.py,sha256=PVev-PTreMx3yne9uMipBU2nkIIS_CTIKYgkW5NvJn0,5309
 mlflow/store/artifact/azure_blob_artifact_repo.py,sha256=n2csaNEtAIw0LCwR6W8oJ3nhoP9uI9CgEnOsLiYxhMk,8136
 mlflow/store/artifact/azure_data_lake_artifact_repo.py,sha256=nO7SnzF5pXtwSjK8lT1OyyADOaJZc1zMn7fQ6V9NsPw,5829
 mlflow/store/artifact/cli.py,sha256=q8FUy7m6TFDRXneh2W0aQ-PRLfkl1HzSvkFvE8Q7Rss,5378
-mlflow/store/artifact/databricks_artifact_repo.py,sha256=rvXjxIzpkh6iBpS4R6h6-aM8Lwn8pzJr6FUC3pUz9Fo,34084
-mlflow/store/artifact/databricks_models_artifact_repo.py,sha256=A8NKUfkYgK_sF_7XK7Na7_zt5xMkgVVbLgJacZfDYhA,9021
+mlflow/store/artifact/databricks_artifact_repo.py,sha256=GiRs3aIy1mBlx9PlscY1EVLPkuLHDs3CxzgbkfSbPUE,31773
+mlflow/store/artifact/databricks_models_artifact_repo.py,sha256=Aa5Pym-bsUVL8y9tZIlUK_bWtuw1a1HX9M9v-bwJqt8,6654
 mlflow/store/artifact/dbfs_artifact_repo.py,sha256=S4LMiHwQxFOyu9spPopH367Ck2-Ykiss-BTuva1QfEk,10247
 mlflow/store/artifact/ftp_artifact_repo.py,sha256=zWOWJg_Mj9AKqPp9koTOMde1mfxfuP6KQBT4SNafZC8,5234
 mlflow/store/artifact/gcs_artifact_repo.py,sha256=XVN8Wx4K7gAeSivadYgz8N5bwKe8a9gEWdq8JqaFRIw,5873
 mlflow/store/artifact/hdfs_artifact_repo.py,sha256=AGk9Rr61g_k-7NEmFpy_mA7CsiuB6tyIB-SkNoqDA9w,9684
 mlflow/store/artifact/http_artifact_repo.py,sha256=Zq2ImiBkiWUoO3NN6bnzwx9GSB-s6uZnYwrAxlvSpHs,3377
 mlflow/store/artifact/local_artifact_repo.py,sha256=48nJsxzAJPNYYNoeo8gahRQ41X-LXo3IaDb0j-JjsAw,5085
 mlflow/store/artifact/mlflow_artifacts_repo.py,sha256=WsWgB_J7N4wIzB2HmvOHoernRFzDjOGpfarZ38eCrxQ,3001
 mlflow/store/artifact/models_artifact_repo.py,sha256=U0H6o7GFqEjeN6mCTXEDVKIMNlUkzA5DIPhTq7HiCGQ,6757
 mlflow/store/artifact/runs_artifact_repo.py,sha256=RChPNUB1zC0tLFEVXDi2ionsHyOqeCr6sM8UxtcoAqc,6016
 mlflow/store/artifact/s3_artifact_repo.py,sha256=tfunXtzbes9ofdV25Ue39AITBjgrnSIKj86zjsUyqN8,9442
 mlflow/store/artifact/sftp_artifact_repo.py,sha256=RVI1mdfFHdzeXPfHKBZDU-wcbvzh9_L2o5yEWGjwl9E,5455
 mlflow/store/artifact/unity_catalog_models_artifact_repo.py,sha256=gOpMwD2xSd4v51OMHxkvcsvymjIfLu2xmQ7Dt7ZRpUY,5326
 mlflow/store/artifact/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-mlflow/store/artifact/utils/models.py,sha256=HySl_j5KfDzDT2QyA9qCl99LZrzgQN1AMmjUKEEvU_o,3888
+mlflow/store/artifact/utils/models.py,sha256=XcILBvEEULupgHmYVAekQ8xqzfeey6Xr-6fm3nV3qjo,3934
 mlflow/store/db/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/store/db/base_sql_model.py,sha256=kha9xmklzhuQAK8QEkNBn-mAHq8dUKbOM-3abaBpWmQ,71
 mlflow/store/db/db_types.py,sha256=bGoaqGlCgjrQ5PB119DE4b_t1hysxyHkObYHe5IMPss,221
 mlflow/store/db/utils.py,sha256=48zYlVF1yMjpaFpnilNWv6B3JBu4nCua3YNzu45BE-A,10592
 mlflow/store/db_migrations/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/store/db_migrations/alembic.ini,sha256=6u_4gBGbzSjo5ewUYTPuFKpOsbTP_ZT2pizQQy9gDPc,1634
 mlflow/store/db_migrations/env.py,sha256=4ahmxNCOcniH2UlWpE13EX7IfdC2t0R4sOp6toonKrE,2768
@@ -252,15 +252,15 @@
 mlflow/store/tracking/dbmodels/initial_models.py,sha256=8T-NRIaHQw3Es37kIuBS7EXkJe20jTJXPU193mjeoHQ,8315
 mlflow/store/tracking/dbmodels/models.py,sha256=PPT0XC6F4foBLfQs_KcngxL8EoLIi59QXZiuse3Tbjo,15674
 mlflow/tensorflow/__init__.py,sha256=btZindFA5NV2FRlxwGmuhKgFud7xVuUK93H8SVpTgUk,57261
 mlflow/tensorflow/_autolog.py,sha256=Wss_IDfnQzbG0qEUpAr2DZZRmGay8A4X4atFbx0qU8c,8442
 mlflow/tracking/__init__.py,sha256=XFq7V_eudhTz3o_pdEyyQxb5o7jMuL_2qtEE5VygjzE,995
 mlflow/tracking/artifact_utils.py,sha256=65aU24U9qacsHnF6wM3c_r98s_XVHzEFmv2B1w0gR9Q,7155
 mlflow/tracking/client.py,sha256=uTJJr07hv60FioszbVq6oxvcMXcGn-Qrp6zdQ0VeOlg,126036
-mlflow/tracking/fluent.py,sha256=J0FpHC9w8FEbj8H7XbybNd2s1895K01NvPEd1GtD9y0,70818
+mlflow/tracking/fluent.py,sha256=3LsyIkmMJ9i3HvJ6fd_1_ewjsB2ttk0GNgb6IBIjT_k,70974
 mlflow/tracking/llm_utils.py,sha256=GT3CLqNSovBKLf6t3l6jmeI3vwmw8qMwk21Y5gmkBW8,3404
 mlflow/tracking/metric_value_conversion_utils.py,sha256=qSqG_eEShP69DS5d7MkrkhYyz-kQ9ZT9y73Lc7AKz8c,2248
 mlflow/tracking/registry.py,sha256=hsZg1uVSz95lypiPgKD8t7KVKtLRW8VGi3YLICFwwHo,3515
 mlflow/tracking/_model_registry/__init__.py,sha256=_HtGwD9WY1x2-02TgEftcWrKKqBnJNjB9YdRc6sqLe4,41
 mlflow/tracking/_model_registry/client.py,sha256=GwZO4Jzuxe2eWjv9q47tR3I-E_mHpiKdRewuzvHQum0,15534
 mlflow/tracking/_model_registry/fluent.py,sha256=bG2VH5BxikL16nVVjD5S3X8px-nwkAbJ2STab0QKI4c,9364
 mlflow/tracking/_model_registry/registry.py,sha256=qsuCwqPadP3PWvhMwBXJOubT_j4oaoNDc1aEN05MNb8,3152
@@ -288,50 +288,50 @@
 mlflow/tracking/request_header/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mlflow/tracking/request_header/abstract_request_header_provider.py,sha256=n2wzyt8JTRFqFiY5iIskuxJrMszAd9sdZMfLKcccBWY,1077
 mlflow/tracking/request_header/databricks_request_header_provider.py,sha256=IX4yVOVK5quGjgMxkEENHrg8OLx8Xm_4NbOj5x5WkK8,1336
 mlflow/tracking/request_header/default_request_header_provider.py,sha256=ywddaWplSv3Qv0DMd62NObNggD0is8awgxFDN1kbhJg,486
 mlflow/tracking/request_header/registry.py,sha256=EiBNOwc_G04nCSOK4PyJPZo42rvVB6RnODlhrOy0XOg,2867
 mlflow/types/__init__.py,sha256=N0CRRZ0ajWtbNV1jOkZTJcMtUvwAaSRfy7f21YaOdFM,299
 mlflow/types/schema.py,sha256=uUuXJjShB6c06J-XY0qwGJdOTOxQpMAiqLxKqf_06X0,13334
-mlflow/types/utils.py,sha256=uwY-pGQgOfnw8BaziPGTX5Yi07WRTZ9wD1ystPPSueE,17636
+mlflow/types/utils.py,sha256=ttRVfm7fs09fxYMR7nF62sIrudhhjBlWhAynMbLrQDo,17899
 mlflow/utils/__init__.py,sha256=wCpt9d3G_e0hyArdrzkFhrUvjtDOCcdJSgy5oWNPe6E,9389
 mlflow/utils/_capture_modules.py,sha256=d5bMqg7wSf6UQ4JRrk1Ab0y_kxhQMPR8LMTUvKZ6rcw,6270
 mlflow/utils/_spark_utils.py,sha256=AVdnCDzjOjBa8ZhLQsqYbpV1b_GGS_MCO5cVfKiumLc,6395
 mlflow/utils/annotations.py,sha256=WUt63FPWd1xeqATyMbF5wHRGp68KvkS72lqXOMnKbsg,4906
 mlflow/utils/arguments_utils.py,sha256=B8KUnf59cpg6ML3fjjxJ_FrHfIxMnWcsNZcq8KNILQk,400
 mlflow/utils/class_utils.py,sha256=1GjsGesJgRXu3omxcGzvwruh1fsCN1GvsbeEUvmtkW0,215
 mlflow/utils/cli_args.py,sha256=1WgpFFQdteAFNcEhdmYO2SqhSeNKZ7itPWaVZtD8rx0,6431
 mlflow/utils/conda.py,sha256=cOpyLtcBJg1-7c8OqmCPB8-8Cp5VSDyKGTzOdBmGqpQ,13002
 mlflow/utils/data_utils.py,sha256=XXTjNkegciD8AhWR569p5W_BsPluxO2FOaRZOYxGnRY,432
-mlflow/utils/databricks_utils.py,sha256=l13C45ePonbmuiLTrz7IZQj9Mnu8v5X9UjCDDfR5VqQ,21450
+mlflow/utils/databricks_utils.py,sha256=rP1U3RYfbDSFvU4jAdS9IWn4jS0lJhgIOKop3WQF33U,21834
 mlflow/utils/docstring_utils.py,sha256=saU5MsKF5yYA12xsBg7jijnoC3yF1z88yM8LzMKzQls,9138
 mlflow/utils/env.py,sha256=YH1Rr7i6-s09PWOUyL2j-0SvR5YeZmc1hA-hKyvgEt8,192
 mlflow/utils/env_manager.py,sha256=pM-V8KW2IwZr2BDx1aZjKmliv-nM3akkEYHhLVAgaqc,474
 mlflow/utils/environment.py,sha256=RwaRzzQLZJNxl1-XIATVGeZp1XhaIk67p9KYsGcc7Go,21930
-mlflow/utils/file_utils.py,sha256=WGoUGdWZbKBc8aK-9eBUzW2ZIl-Odwlq70URds4US3s,28476
+mlflow/utils/file_utils.py,sha256=f48QFjnqfzVXfO2_sBHiemJuawCFDcM9BeoG7Nijhvc,25967
 mlflow/utils/git_utils.py,sha256=LVLjkRJpj06-ndAVB-Pzw5YV7PaDlp2DtJhDZAqAPhs,2306
 mlflow/utils/gorilla.py,sha256=9LDEOjCoSLbq0W7kNqxyKJA3HjZZXMniIS0N4koQCTc,24166
 mlflow/utils/logging_utils.py,sha256=Ey1So5UXLREwoxHfguiAJIaylDwFnzHYzEsPMnqVlew,2597
 mlflow/utils/mime_type_utils.py,sha256=ALg_KnRUI9VPxm7OjCPX-fqzOMj-qiAmYFlJMT21fDI,1298
 mlflow/utils/mlflow_tags.py,sha256=i0jOmNT923tmpRHGjTR0SL9vnQZG5QtGhkmEK1vN9DA,3839
 mlflow/utils/model_utils.py,sha256=ezqfQURsanWBIPOwMaz-JgKGGHRJe4VlynE4ugrejTY,6208
 mlflow/utils/name_utils.py,sha256=Jp9WEiI226mTrfKdrRr6EkhabY1Iv4BZR0CIJUdnf80,5873
 mlflow/utils/nfs_on_spark.py,sha256=L6M79OCuUck72yY3ltIOd7KNSVPiJScVKjbXSnJVx3s,2412
 mlflow/utils/os.py,sha256=yxxLhVF1BlS6CR--jBx6Y2_zCuBiqr7XAakazzgkKcY,139
 mlflow/utils/process.py,sha256=WedrqYAUvZGXucoQ0VxdGJ76PP15Mhwi3I696MJNhWc,5799
 mlflow/utils/proto_json_utils.py,sha256=d6Nk6xJGTqo8KHe2p_75XbXUOmhFOBUQ6eKCZvF6EDo,19923
-mlflow/utils/requirements_utils.py,sha256=Iy3y6LMi_H3dfB_pm_euhghkTXQ5WNyWXAeWxQmUVYM,18947
-mlflow/utils/rest_utils.py,sha256=XHlI9mM-nW15WJ_7mJoguPNxBfgcY8TW0pokgROozaM,16849
-mlflow/utils/search_utils.py,sha256=dL_CG3KgPPjzjCPBetzYMNqzpgaa15CqvM30wONhxys,55945
+mlflow/utils/requirements_utils.py,sha256=2xN_acZAJImqxizX0M6unLAQKQSlZENCK37PCrobF2s,18470
+mlflow/utils/rest_utils.py,sha256=CNIu0svaY8ZTc1XXqISnpWWEzb4TiE5I_WF2CBCMYdY,16880
+mlflow/utils/search_utils.py,sha256=vq3ME21AZLBrFomDEGy_yxK2kAGD3H4QXjWy3-1BIgM,56769
 mlflow/utils/server_cli_utils.py,sha256=RUy0tgl0f2NNC-b9gunt2tgALfeUJeLGjQUEwCzicuY,2368
 mlflow/utils/string_utils.py,sha256=OFq1Yqxzkr4fangUqMwCw-V_LT25EtPUZvCGMpg2K-c,3805
 mlflow/utils/time_utils.py,sha256=vsxzbrVJiCyjqhS16mgXqtCwr7XMHgKcV-C1LKqMI0A,512
 mlflow/utils/uri.py,sha256=BIilN9tjRKLJif9QqphJRHZ5qVlcUaZmTSVftNqOuGo,13915
 mlflow/utils/validation.py,sha256=7jOdkD08gU0ClF5YPBvFPstBC7KFVV6z4L1BBA_jWqY,16024
-mlflow/utils/virtualenv.py,sha256=Wbw90iPFLteBFuCUjMPuQsI9zmfarDBUX7fzXe2a7jw,15879
+mlflow/utils/virtualenv.py,sha256=ASdP5ZfgyLEc1rkTRZB488tmsTaKY1_qaVX-jgLv6BU,16452
 mlflow/utils/autologging_utils/__init__.py,sha256=ewsostxygslzpFOu2JqQlT57bGFRyT3a0V77NhqRug8,25551
 mlflow/utils/autologging_utils/client.py,sha256=y6X_QdWk1oJSZITw7-jbGVwIqFQ2u5I4-jMgPvkN3o4,15731
 mlflow/utils/autologging_utils/events.py,sha256=CXnCIFMTNuvARerF_wsW5AXq7-A7fcg6djuH5jt_Ou0,10937
 mlflow/utils/autologging_utils/logging_and_warnings.py,sha256=0XG5BA4cNcX1Ezd8in7bjCjqFd3PXAD_VxjmyUu7EYQ,13381
 mlflow/utils/autologging_utils/safety.py,sha256=vaYUNEj4iCWk2RbUz3cP4rdy7NVkIzJt3bQQzWuV75Q,47266
 mlflow/utils/autologging_utils/versioning.py,sha256=7mERL6JWFEmPazbGM8bbY7Y252tIqrGuWfipYRIzMmE,3489
 mlflow/utils/import_hooks/__init__.py,sha256=YjsZtqhGnxKEBDc_GVsGdG_W2ZrJlu4FaqNSG2xduZo,13489
@@ -340,13 +340,13 @@
 pylint_plugins/__init__.py,sha256=P5u2tXPOMEfyIWUfKSUd4-7lN9ZMLHIusJ403Ez70xM,521
 pylint_plugins/errors.py,sha256=vFHxRPChPKZNGQyPMip6YTwjEmooWM7hbW1sRxcTfCk,2006
 pylint_plugins/print_function.py,sha256=6MPDFzEelH_lJQTlbBIj03wBSzLtSNMvZhL0gIyacU0,856
 pylint_plugins/set_checker.py,sha256=7RklQvldMi4a_E09lzY7QMsZ7Pum9Kd-vlgq1cHYoNQ,571
 pylint_plugins/string_checker.py,sha256=Lvu8GNYn-T5t5ixy3JxoUxtaGqv2H-rOgaRzhDuewDY,878
 pylint_plugins/unittest_assert_raises.py,sha256=3Jrw4uNIXyvOWYPtDBT1PokQvvHn6zsWu6yC6IQvctM,692
 pylint_plugins/pytest_raises_checker/__init__.py,sha256=LEHPlk-aFdwgHY9dk_DAil41IU-BB1Ds9_CLq2RQISc,1546
-mlflow_skinny-2.3.0.dist-info/LICENSE.txt,sha256=Y5U1Xebzka__NZlqMPtBsYm0mRpMtUmTrONatpoL-ig,11382
-mlflow_skinny-2.3.0.dist-info/METADATA,sha256=0zVQpsy3iOdNeMfj6edQfzwubaCvxYNFMV_qMs8ck_M,12386
-mlflow_skinny-2.3.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-mlflow_skinny-2.3.0.dist-info/entry_points.txt,sha256=brdXR55SgMBSluzZ5H20Cj8-yN2n2LRFiy5Yw25JTps,92
-mlflow_skinny-2.3.0.dist-info/top_level.txt,sha256=2q15FEJ-On4TrBIP3hc6d4rDq2l4-i2mQJUq9aRdcq0,22
-mlflow_skinny-2.3.0.dist-info/RECORD,,
+mlflow_skinny-2.3.1.dist-info/LICENSE.txt,sha256=Y5U1Xebzka__NZlqMPtBsYm0mRpMtUmTrONatpoL-ig,11382
+mlflow_skinny-2.3.1.dist-info/METADATA,sha256=BtTk9oA8bbEEJVbKjC_zuDJvEHeYh3gOyrD05Vwsa3E,12392
+mlflow_skinny-2.3.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+mlflow_skinny-2.3.1.dist-info/entry_points.txt,sha256=brdXR55SgMBSluzZ5H20Cj8-yN2n2LRFiy5Yw25JTps,92
+mlflow_skinny-2.3.1.dist-info/top_level.txt,sha256=2q15FEJ-On4TrBIP3hc6d4rDq2l4-i2mQJUq9aRdcq0,22
+mlflow_skinny-2.3.1.dist-info/RECORD,,
```

