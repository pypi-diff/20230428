# Comparing `tmp/csvcubed-0.4.0-py3-none-any.whl.zip` & `tmp/csvcubed-0.4.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,8 +1,8 @@
-Zip file size: 216823 bytes, number of entries: 184
+Zip file size: 217787 bytes, number of entries: 184
 -rw-r--r--  2.0 unx     1515 b- defN 80-Jan-01 00:00 csvcubed/README.md
 -rw-r--r--  2.0 unx      218 b- defN 80-Jan-01 00:00 csvcubed/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/cli/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/cli/buildcsvw/__init__.py
 -rw-r--r--  2.0 unx     2881 b- defN 80-Jan-01 00:00 csvcubed/cli/buildcsvw/build.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/cli/codelist/__init__.py
 -rw-r--r--  2.0 unx     1414 b- defN 80-Jan-01 00:00 csvcubed/cli/codelist/build_code_list.py
@@ -137,15 +137,15 @@
 -rw-r--r--  2.0 unx     1945 b- defN 80-Jan-01 00:00 csvcubed/utils/rdf.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/utils/skos/__init__.py
 -rw-r--r--  2.0 unx     3017 b- defN 80-Jan-01 00:00 csvcubed/utils/skos/codelist.py
 -rw-r--r--  2.0 unx       89 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/__init__.py
 -rw-r--r--  2.0 unx     6289 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/code_list_inspector.py
 -rw-r--r--  2.0 unx      955 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/column_component_info.py
 -rw-r--r--  2.0 unx     4583 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/csvw_inspector.py
--rw-r--r--  2.0 unx    18992 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/data_cube_inspector.py
+-rw-r--r--  2.0 unx    24662 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/data_cube_inspector.py
 -rw-r--r--  2.0 unx     3889 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql.py
 -rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/ask_is_codelist.sparql
 -rw-r--r--  2.0 unx       75 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/ask_is_qb_dataset.sparql
 -rw-r--r--  2.0 unx     2298 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_catalog_metadata.sparql
 -rw-r--r--  2.0 unx     1006 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_codelist_csv_url.sparql
 -rw-r--r--  2.0 unx      482 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_codelist_primary_key_by_csv_url.sparql
 -rw-r--r--  2.0 unx      969 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_codelists_and_cols.sparql
@@ -174,13 +174,13 @@
 -rw-r--r--  2.0 unx    27378 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/qbwriter/urihelper.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/skoscodelistwriter/__init__.py
 -rw-r--r--  2.0 unx      157 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/skoscodelistwriter/constants.py
 -rw-r--r--  2.0 unx     2437 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/skoscodelistwriter/newresourceurigenerator.py
 -rw-r--r--  2.0 unx    20804 b- defN 80-Jan-01 00:00 csvcubed/writers/qbwriter.py
 -rw-r--r--  2.0 unx     9470 b- defN 80-Jan-01 00:00 csvcubed/writers/skoscodelistwriter.py
 -rw-r--r--  2.0 unx      283 b- defN 80-Jan-01 00:00 csvcubed/writers/writerbase.py
--rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 csvcubed-0.4.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     3925 b- defN 80-Jan-01 00:00 csvcubed-0.4.0.dist-info/METADATA
--rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 csvcubed-0.4.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       64 b- defN 80-Jan-01 00:00 csvcubed-0.4.0.dist-info/entry_points.txt
-?rw-r--r--  2.0 unx    18495 b- defN 16-Jan-01 00:00 csvcubed-0.4.0.dist-info/RECORD
-184 files, 782117 bytes uncompressed, 186481 bytes compressed:  76.2%
+-rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 csvcubed-0.4.1.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3925 b- defN 80-Jan-01 00:00 csvcubed-0.4.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 csvcubed-0.4.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       64 b- defN 80-Jan-01 00:00 csvcubed-0.4.1.dist-info/entry_points.txt
+?rw-r--r--  2.0 unx    18495 b- defN 16-Jan-01 00:00 csvcubed-0.4.1.dist-info/RECORD
+184 files, 787787 bytes uncompressed, 187445 bytes compressed:  76.2%
```

## zipnote {}

```diff
@@ -531,23 +531,23 @@
 
 Filename: csvcubed/writers/skoscodelistwriter.py
 Comment: 
 
 Filename: csvcubed/writers/writerbase.py
 Comment: 
 
-Filename: csvcubed-0.4.0.dist-info/LICENSE
+Filename: csvcubed-0.4.1.dist-info/LICENSE
 Comment: 
 
-Filename: csvcubed-0.4.0.dist-info/METADATA
+Filename: csvcubed-0.4.1.dist-info/METADATA
 Comment: 
 
-Filename: csvcubed-0.4.0.dist-info/WHEEL
+Filename: csvcubed-0.4.1.dist-info/WHEEL
 Comment: 
 
-Filename: csvcubed-0.4.0.dist-info/entry_points.txt
+Filename: csvcubed-0.4.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: csvcubed-0.4.0.dist-info/RECORD
+Filename: csvcubed-0.4.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## csvcubed/utils/sparql_handler/data_cube_inspector.py

```diff
@@ -2,42 +2,45 @@
 Data Cube Inspector
 -------------------
 
 Provides access to inspect the contents of an rdflib graph containing
 one of more data cubes.
 """
 
-from dataclasses import dataclass
+from dataclasses import InitVar, dataclass, field
 from functools import cache, cached_property
 from typing import Dict, List, Optional, Set, Tuple
 from urllib.parse import urljoin
 
 import pandas as pd
 import uritemplate
 from csvcubedmodels.rdf.namespaces import XSD
+from pandas.core.arrays.categorical import Categorical
 
 from csvcubed.definitions import QB_MEASURE_TYPE_DIMENSION_URI, SDMX_ATTRIBUTE_UNIT_URI
 from csvcubed.inputs import pandas_input_to_columnar_str
 from csvcubed.models.csvcubedexception import UnsupportedComponentPropertyTypeException
 from csvcubed.models.cube.cube_shape import CubeShape
 from csvcubed.models.cube.qb.components.constants import ACCEPTED_DATATYPE_MAPPING
 from csvcubed.models.sparqlresults import (
+    CodelistResult,
     CodelistsResult,
     ColumnDefinition,
     CubeTableIdentifiers,
     IsPivotedShapeMeasureResult,
     QubeComponentResult,
     QubeComponentsResult,
     UnitResult,
 )
 from csvcubed.models.validationerror import ValidationError
 from csvcubed.utils.dict import get_from_dict_ensure_exists
-from csvcubed.utils.iterables import first, group_by
+from csvcubed.utils.iterables import first, group_by, single
 from csvcubed.utils.pandas import read_csv
 from csvcubed.utils.qb.components import ComponentPropertyType, EndUserColumnType
+from csvcubed.utils.sparql_handler.code_list_inspector import CodeListInspector
 from csvcubed.utils.sparql_handler.column_component_info import ColumnComponentInfo
 from csvcubed.utils.sparql_handler.csvw_inspector import CsvWInspector
 from csvcubed.utils.sparql_handler.sparqlquerymanager import (
     select_csvw_dsd_qube_components,
     select_data_set_dsd_and_csv_url,
     select_dsd_code_list_and_cols,
     select_is_pivoted_shape_for_measures_in_data_set,
@@ -50,14 +53,21 @@
 
 
 @dataclass
 class DataCubeInspector:
     """Provides access to inspect the data cubes contained in an rdflib graph."""
 
     csvw_inspector: CsvWInspector
+    code_list_inspector_in: InitVar[Optional[CodeListInspector]] = None
+    _code_list_inspector: CodeListInspector = field(init=False)
+
+    def __post_init__(self, code_list_inspector_in: Optional[CodeListInspector]):
+        self._code_list_inspector = code_list_inspector_in or CodeListInspector(
+            self.csvw_inspector
+        )
 
     def __hash__(self):
         """
         Necessary for `@cache` attributes above function definitions within this class.
 
         We *don't* want to make use of the dataclass hashing functionality, since it may end up evaluating all of
         our cached properties which would mean they're no longer lazy-loading.
@@ -311,26 +321,155 @@
         data cube.
         """
         primary_catalog_metadata = self.csvw_inspector.get_primary_catalog_metadata()
         return self.get_cube_identifiers_for_data_set(
             primary_catalog_metadata.dataset_uri
         ).csv_url
 
-    def get_dataframe(self, csv_url: str) -> Tuple[pd.DataFrame, List[ValidationError]]:
+    def get_dataframe(
+        self, csv_url: str, dereference_uris: bool = True
+    ) -> Tuple[pd.DataFrame, List[ValidationError]]:
         """
         Get the pandas dataframe for the csv url of the cube wishing to be loaded.
         Returns DuplicateColumnTitleError in the event of two instances of the
         same columns being defined.
+        dereference_uris=True means URIs of column values are converted to their human readable labels.
         """
         cols = self.get_column_component_info(csv_url)
         dict_of_types = _get_data_types_of_all_cols(cols)
         absolute_csv_url = file_uri_to_path(
             urljoin(self.csvw_inspector.csvw_json_path.as_uri(), csv_url)
         )
-        return read_csv(absolute_csv_url, dtype=dict_of_types)
+        (df, _errors) = read_csv(absolute_csv_url, dtype=dict_of_types)
+
+        if dereference_uris:
+            code_lists = self.get_code_lists_and_cols(csv_url).codelists
+            for col in cols:
+                col_values = df[col.column_definition.title].values
+                if isinstance(col_values, Categorical):
+                    df[col.column_definition.title] = col_values.rename_categories(
+                        self._get_new_category_labels_for_col(
+                            csv_url, col, col_values.categories, code_lists
+                        )
+                    )
+        return df, _errors
+
+    def _get_new_category_labels_for_col(
+        self,
+        csv_url: str,
+        col: ColumnComponentInfo,
+        col_categories: pd.Index,
+        code_lists: List[CodelistResult],
+    ) -> List[str]:
+        """
+        Identifies the type of column being used and applies the appropriate dereferencing function.
+        """
+        value_url = col.column_definition.value_url
+
+        if col.column_type.value == "Attribute" and value_url is not None:
+            return self._dereference_uris_for_attributes(
+                col, value_url, csv_url, col_categories
+            )
+        elif col.column_type.value == "Measures" and value_url is not None:
+            return self._dereference_uris_for_measures(
+                col, value_url, csv_url, col_categories
+            )
+        elif col.column_type.value == "Units" and value_url is not None:
+            return self._dereference_uris_for_units(col, value_url, col_categories)
+        elif col.column_type.value == "Dimension":
+            return self._dereference_uris_for_dimensions(code_lists, col)
+        # Column is either an Attribute Literal or Observations
+        raise ValueError(
+            f"Unhandled column type/configuration - {col.column_type.value}, {col.column_definition}"
+        )
+
+    def _dereference_uris_for_attributes(
+        self,
+        col: ColumnComponentInfo,
+        value_url: str,
+        csv_url: str,
+        col_categories: pd.Index,
+    ) -> List[str]:
+        """
+        Returns the list of dereferenced URIs for Attribute Resource-type column values.
+        """
+        if col.column_definition.name is None:
+            raise ValueError(f"Column name is not defined - {col.column_definition}")
+        if col.column_definition.title is None:
+            raise ValueError(f"Column title is not defined - {col.column_definition}")
+
+        col_uris = [
+            uritemplate.expand(value_url, {col.column_definition.name: cat})
+            for cat in col_categories
+        ]
+        attribute_vals = self.get_attribute_value_uris_and_labels(csv_url)
+        return [attribute_vals[col.column_definition.title][uri] for uri in col_uris]
+
+    def _dereference_uris_for_measures(
+        self,
+        col: ColumnComponentInfo,
+        value_url: str,
+        csv_url: str,
+        col_categories: pd.Index,
+    ) -> List[str]:
+        """
+        Returns the list of dereferenced URIs for Measures-type column values.
+        """
+        if col.column_definition.name is None:
+            raise ValueError(f"Column name is not defined - {col.column_definition}")
+
+        col_uris = [
+            uritemplate.expand(value_url, {col.column_definition.name: cat})
+            for cat in col_categories
+        ]
+        measure_uris_and_labels = self.get_measure_uris_and_labels(csv_url)
+        return [measure_uris_and_labels[uri] for uri in col_uris]
+
+    def _dereference_uris_for_units(
+        self,
+        col: ColumnComponentInfo,
+        value_url: str,
+        col_categories: pd.Index,
+    ) -> List[str]:
+        """
+        Returns the list of dereferenced URIs for Units-type column values.
+        """
+        if col.column_definition.name is None:
+            raise ValueError(f"Column name is not defined - {col.column_definition}")
+
+        col_uris = [
+            uritemplate.expand(value_url, {col.column_definition.name: cat})
+            for cat in col_categories
+        ]
+        unit_labels = []
+        for col_uri in col_uris:
+            maybe_unit = self.get_unit_for_uri(col_uri)
+            if maybe_unit is None:
+                raise ValueError(f"Unit {col_uri} could not be retrieved.")
+            unit_labels.append(maybe_unit.unit_label)
+        return unit_labels
+
+    def _dereference_uris_for_dimensions(
+        self, code_lists: List[CodelistResult], col: ColumnComponentInfo
+    ) -> List[str]:
+        """
+        Returns the list of dereferenced URIs for Dimension-type column values.
+        """
+        if col.column_definition.title is None:
+            raise ValueError(f"Column title is not defined - {col.column_definition}")
+
+        code_list = single(
+            code_lists, lambda c: col.column_definition.title in c.cols_used_in
+        )
+        concept_scheme_uri = code_list.code_list
+        uri_labels_dict = self._code_list_inspector.get_map_code_list_uri_to_label(
+            concept_scheme_uri
+        )
+
+        return list(uri_labels_dict.values())
 
     def _map_column_name_to_title_to_attribute_value_url(
         self, csv_url: str
     ) -> Tuple[Dict[str, str], Dict[str, str]]:
         """
         Returns dictionaries of column name to column title and resource attribute column name to value url
         """
@@ -500,10 +639,10 @@
                     col_data_type
                 ]
             else:
                 raise ValueError(
                     f"Unhandled data type '{col.column_definition.data_type}' in column '{col.column_definition.title}'."
                 )
         else:
-            dict_of_types[col.column_definition.title] = "string"
+            dict_of_types[col.column_definition.title] = "category"
 
     return dict_of_types
```

## Comparing `csvcubed-0.4.0.dist-info/LICENSE` & `csvcubed-0.4.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `csvcubed-0.4.0.dist-info/METADATA` & `csvcubed-0.4.1.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: csvcubed
-Version: 0.4.0
+Version: 0.4.1
 Summary: A tool to generate RDF Data Cube style CSV-W cubes from tidy CSV files. Part of the csvcubed family.
 License: Apache-2.0
 Author: Integrated Data Service - Dissemination
 Author-email: csvcubed@gsscogs.uk
 Requires-Python: >=3.9,<3.12
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python :: 3
```

## Comparing `csvcubed-0.4.0.dist-info/RECORD` & `csvcubed-0.4.1.dist-info/RECORD`

 * *Files 0% similar despite different names*

```diff
@@ -136,15 +136,15 @@
 csvcubed/utils/rdf.py,sha256=Ki0Sqh0FWB6atz4q2xtbDcgQVDLcb00PuRkWuo5WJnk,1945
 csvcubed/utils/skos/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/utils/skos/codelist.py,sha256=nIENnG8nm-jEBnO05Ge-rWEItXLYDVmUey2qIvhe0bI,3017
 csvcubed/utils/sparql_handler/__init__.py,sha256=IUbRkPhSFfbFNEt0Jsht80tOyjmuWfEAlpCDHH6mUp8,89
 csvcubed/utils/sparql_handler/code_list_inspector.py,sha256=SF_cQlkPLkBN27bJ7rOE9D14gf7-HKGGo9W8qG8KBvI,6289
 csvcubed/utils/sparql_handler/column_component_info.py,sha256=E5OrqZcxppALLqTMDyC8tEtA_4s0D3XyncMKIT3x18E,955
 csvcubed/utils/sparql_handler/csvw_inspector.py,sha256=rGJY6k4AzGWrz_7EiJquHbmhFdLRYNfx3l7qLKtnSrM,4583
-csvcubed/utils/sparql_handler/data_cube_inspector.py,sha256=THramrYQtlAVvmiDd6L4Xxlvo-Yzrq10Ne4EL6t_mms,18992
+csvcubed/utils/sparql_handler/data_cube_inspector.py,sha256=D6rCaEd-mUsEJV9sr5voX4hugLJBvBq5896cqDXPTWo,24662
 csvcubed/utils/sparql_handler/sparql.py,sha256=t2rK3MztIy0JTbASmpxNfKBMCa0lZ-EAUn4CnLVxsWA,3889
 csvcubed/utils/sparql_handler/sparql_queries/ask_is_codelist.sparql,sha256=9_qf61Mn1b4H2huNFvhxDD78jTqWw7W2Zrk0g6msino,88
 csvcubed/utils/sparql_handler/sparql_queries/ask_is_qb_dataset.sparql,sha256=eYgoKHTGTaex3xizQ9lx5t9kEPu6ejvXC7El8M2aXSk,75
 csvcubed/utils/sparql_handler/sparql_queries/select_catalog_metadata.sparql,sha256=HSF4DAB79RvFMU6zWHXvQjEcvfZ8ivtUolMxUyFIsCo,2298
 csvcubed/utils/sparql_handler/sparql_queries/select_codelist_csv_url.sparql,sha256=LEFLJBati_-bGkBnnJEG7XgA5VYhiMm9kdB9gW7e3H8,1006
 csvcubed/utils/sparql_handler/sparql_queries/select_codelist_primary_key_by_csv_url.sparql,sha256=JLs1SHwPrTBsV45COO9gOk2hj4Z4vjSi4uBE2GFrsis,482
 csvcubed/utils/sparql_handler/sparql_queries/select_codelists_and_cols.sparql,sha256=oGxWovWaoGcyB-Ez8eM7oECscpaP1BiDbLWeSJxb-vw,969
@@ -173,12 +173,12 @@
 csvcubed/writers/helpers/qbwriter/urihelper.py,sha256=BzVnUueyoE1DBncTByKnigeLozePdfFRfxzaguwCtxY,27378
 csvcubed/writers/helpers/skoscodelistwriter/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/writers/helpers/skoscodelistwriter/constants.py,sha256=FjVa2JsAc7uIxzQOJgNg3zf8Ha-YZvMzF75sqq_e93g,157
 csvcubed/writers/helpers/skoscodelistwriter/newresourceurigenerator.py,sha256=DWkL2zO4QsLV8Oo-nVXxS4cxA1ic4stSBp7NZpClbps,2437
 csvcubed/writers/qbwriter.py,sha256=fDesUmhWU1211z_wDQi8xFdfpB0CqdSHG7pM-YlsJQc,20804
 csvcubed/writers/skoscodelistwriter.py,sha256=dCK3RaOrv4jeD6l4SZ2PT9tr8zqZwR2x8kbRTsASIMc,9470
 csvcubed/writers/writerbase.py,sha256=lzEHMgqdWBIFbxthYjf5JuE3i5gp5Vbb1Xw359TY3to,283
-csvcubed-0.4.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-csvcubed-0.4.0.dist-info/METADATA,sha256=pB9NW-rb3JIvC-186G8MrnLMvOmJ9trP9xt_V-yV5Xc,3925
-csvcubed-0.4.0.dist-info/WHEEL,sha256=7Z8_27uaHI_UZAc4Uox4PpBhQ9Y5_modZXWMxtUi4NU,88
-csvcubed-0.4.0.dist-info/entry_points.txt,sha256=sGis93BsSIrPNIht5YkyuYCvefbri5nvVdOyI9ImAFs,64
-csvcubed-0.4.0.dist-info/RECORD,,
+csvcubed-0.4.1.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+csvcubed-0.4.1.dist-info/METADATA,sha256=GaSNyyTY9XL66EbewEipZGCLRlMWIk-hQHYwe6JWHOo,3925
+csvcubed-0.4.1.dist-info/WHEEL,sha256=7Z8_27uaHI_UZAc4Uox4PpBhQ9Y5_modZXWMxtUi4NU,88
+csvcubed-0.4.1.dist-info/entry_points.txt,sha256=sGis93BsSIrPNIht5YkyuYCvefbri5nvVdOyI9ImAFs,64
+csvcubed-0.4.1.dist-info/RECORD,,
```

